./awk.memo
./io.memo
./locate-2-updatedb.memo
./my.cnf
./network.memo
./openssl.memo
./vsftpd.memo
./windows-ftp-2-linux-use-powershell.memo
./redis.memo
./mongod.memo
./vim.memo
./mysql.memo
./zabbix.memo
./git.memo
./docker.memo
./lsyncd.memo
./ansible.memo
./parellel-ping.py
./postfix.memo
./sftp-server.memo
./rabbitmq-server.memo
./linux.memo
./azure.memo
./bash-script.memo
./temp.memo
./IIS.memo
./QA.memo
./powershell.memo
./pythondemo.py
./screen.memo
./tmux.memo
./favourite.memo
./all.memo
./autoInstallMysql57.sh
./readfilelinebyline.py
./sniffer.memo
./nfs.memo
######Startmemoof awk.memo #######
######Start awk.memo #######

##############awk vlookup replace by array#############
$> cat array-replace.awk

NR==FNR{
        temp[$1]=$2
        }

NR!=FNR{
        for(j=1;j<=NF;j++){           ###this do working where j>=10
              if($j~/^var/)           ###start with var field
                   $j = temp[$j]      ###vlookup replace
              s=$0                    ###result write back
        }
              print s
    }        


$> cat array-replace-keys
var-wildcode 0.0.0.7
var-network 192.168.20.0
var-mask 255.255.255.0
var-public-ip 1.2.3.4
var-privity-ip 192.168.20.100


$> cat array-replace-templete 
my pub-int var-public-ip var-mask var-wildcode 
my  privity-ip var-privity-ip var-mask  
privity-ip var-privity-ip var-wildcode

$> awk -f array-replace.awk array-replace-keys array-replace-templete 
my pub-int 1.2.3.4 255.255.255.0 0.0.0.7
my privity-ip 192.168.20.100 255.255.255.0
privity-ip 192.168.20.100 0.0.0.7

##############awk vlookup replace by array#############


####debug
--10 centos 7 not work

--20 operation
$>awk -D -f some-file.awk operation-fiel
gawk> watch s
Watchpoint 1: s
gawk> run
Starting program: 
Stopping in Rule ...
Watchpoint 1: s
  Old value: untyped variable
  New value: " rule 10 permit ip source #4 #5 destination #10"
main() at `replace.awk':7
7                          for (j = 1; j <= NF; j++){
gawk> n
8                                  gsub("#"j, $j, s)
gawk> 
Watchpoint 1: s
  Old value: " rule 10 permit ip source #4 #5 destination #10"
  New value: " rule 10 permit ip source #4 #5 destination -R10"
main() at `replace.awk':7
7                          for (j = 1; j <= NF; j++){
gawk> 
8                                  gsub("#"j, $j, s)
gawk> quit
The program is running. Exit anyway (y/n)? y


####debug


######vlookup#################
--10 link
https://unix.stackexchange.com/questions/257002/vlookup-work-in-awk-on-linux

--20 requirement
file1:
4,abc
3,xyz
5,fut
6,gfd

file2:
gfd,2.3
xyz,4.5
abc,6.7
fut,3.2

fil3:(result)
4,6.7
3,4.5
5,3.2
6,2.3

--30 way 1
With join:

join -t, -1 2 -2 1 -o 1.1,2.2 <(sort -t, -k2 file1) <(sort -t, -k1 file2)

    -t, set delimiter to ,.
    -1 2 the first files join field is the second one.
    -2 1 the second files join field is the first one.
    -o 1.1,2.2 the output format
    <(sort ...) join need input files, which are sorted on the join field.

--30 way 2

FNR==NR{
    var[$2]=$1
}
FNR!=NR{
    print(var[$1]","$2)
}

call:
awk -F, -f script.awk file1 file2
######vlookup#################


####warp awk in shell########
--10 $1 is shell argv1,$2 is shell argv2
$> cat segw.sh 
awk 'BEGIN {RS = ""} /'$1'/' $2 

--20 seperate is space line 
$> cat templete.bak 
Interface:g0/0
IP:192.168.1.1

Mask:255.255.255.0
GW:172.16.1.2

--30 call and result,$1 is IP,$2 is templete.bak
$> ./segw.sh IP templete.bak 
Interface:g0/0
IP:192.168.1.1

####warp awk in shell########



###replace newline enter to space####
link:
https://stackoverflow.com/questions/1251999/how-can-i-replace-a-newline-n-using-sed

#10 initial
$>cat templete.bak 
Interface:g0/0
IP:192.168.1.1
Mask:255.255.255.0
GW:172.16.1.2

#20 way 1 the best
$> awk -F ":" '{print $1}' templete.bak |sed -e ':a' -e 'N' -e '$!ba' -e 's/\n/ /g'
Interface IP Mask GW

--or--
#20 way 2
$> awk -F ":" '{print $1}' templete.bak |sed ':a;N;$!ba;s/\n/ /g'
Interface IP Mask GW

Explanation:

    Create a label via :a.
    Append the current and next line to the pattern space via N.
    If we are before the last line, branch to the created label $!ba ($! means not to do it on the last line as there should be one final newline).
    Finally the substitution replaces every newline with a space on the pattern space (which is the whole file).


###replace newline enter to space####


#####awk form-letter with given value####

User~/> cat replace.value 

Fld1|Fld2|Fld3
Alice|Bob|Cindy
Zoo|Yard|Xeon

User~/> cat replace.cmd 
 BEGIN {FS = "|"
                   while (getline <"form.letter")
                   line[++n] = $0
   }
 NR<2{next}{for (i = 1; i <= n; i++) {   //skip first line 
                   s = line[i]          //read line of form.letter to s
                   for (j = NF; j >= 1; j--)  //read field from replace.value in order,reverse order Must.
                              gsub("\\$"j, $j, s)
                   print s
           }
   }

User~/> cat form.letter 
This is a form letter.
The first field is $1, the second $2, the third $3.
The third is $3, second is $2, and first is $1.

User~/> awk -f replace.cmd replace.value 

This is a form letter.
The first field is Alice, the second Bob, the third Cindy.
The third is Cindy, second is Bob, and first is Alice.

This is a form letter.
The first field is Zoo, the second Yard, the third Xeon.
The third is Xeon, second is Yard, and first is Zoo.


#####awk form-letter with given value####


{
if($0 ~"Directory\ of")  #根据是否含“Directory of”判断是否是包含目录的那一行
        {
f=""         
for(i=3;i<=NF;i++) 
f=f " " $i    
        }#以上为把完整的路径赋给变量f
else
        {
printf("%s\\",f) #打印完整路径，并跟一个\
for(i=5;i<=NF;i++)printf("%s ",$i) #打印完整文件名称,注意%s后的空格,用于输出文件名中的空格.
                {
                printf("|") #打印界定符，方便EXCEL导入
                printf("%s",$4)  #打印所有者
                printf("|") #打印界定符，方便EXCEL导入
                print $3 #打印文件大小
                }
        }
}






awk输出全路径文件及文件大小.txt
dir  c: /s |grep -v "<DIR>|字节$|^$"| awk -v f="" -f 1.txt #-v必须紧随在AWK后，不然会错


下面是1.txt 的内容
{
if($0 ~".*的目录$")         #~是包含的操作方法

        #自定义变量f不需要加前缀$;""""(也可以是空格如$1 " " $2)是字符串之间的连接操作符
        {
f=""         #变量f赋初值，一定要在写在这里
for(i=1;i<NF;i++) #路径的值赋给变量f
f=f " " $i    #路径的值赋给变量f
        }
else
        {
printf("%s\\",f) #输出文件完整路径（包括空格） 
for(i=4;i<=NF;i++)printf("%s ",$i) #接着上面的输出文件完整名称（包括空格） 
print $3  #输出字节数
printf("\n")  #换行
        }
}


结果象这样（注意路径和文件名内部的空格都保留的哦^_^）
 C:\Documents and Settings\All Users\Application Data\Microsoft\OFFICE\DATAOPA11.BAK 8,200

 C:\Documents and Settings\All Users\Application Data\Microsoft\OFFICE\DATAopa11.dat 8,206

 C:\Documents and Settings\All Users\Application Data\Microsoft\USMTiconlib.dll 2,560

 C:\Documents and Settings\All Users\Application Data\Windows Genuine Advantage\Datadata.dat 3,104

 C:\Documents and Settings\All Users\桌面Google Chrome.lnk 1,723

 C:\Documents and Settings\All Users\「开始」菜单Windows Update.lnk 1,411

 C:\Documents and Settings\All Users\「开始」菜单Windows Catalog.lnk 398

######End awk.memo #######
######Endmemoof awk.memo #######
######Startmemoof io.memo #######
######Start io.memo #######
==========windows=================
during 60s random write 99% file 1G block 8k threads 8 on t1.dat-to-8.dat
.\diskspd.exe -d60 -r -w99 -c1G -b 8k -t8 t1.dat t2.dat t3.dat t4.dat 5.dat 6.dat 7.dat 8.dat





Usage: diskspd [options] target1 [ target2 [ target3 ...] ]
version 2.0.17a (2016/5/01)

Available targets:
       file_path
       #<physical drive number>
       <partition_drive_letter>:

Available options:
  -?                    display usage information
  -ag                   group affinity - affinitize threads round-robin to cores in Processor Groups 0 - n.
                          Group 0 is filled before Group 1, and so forth.
                          [default; use -n to disable default affinity]
  -ag#,#[,#,...]>       advanced CPU affinity - affinitize threads round-robin to the CPUs provided. The g# notation
                          specifies Processor Groups for the following CPU core #s. Multiple Processor Groups
                          may be specified, and groups/cores may be repeated. If no group is specified, 0 is assumed.
                          Additional groups/processors may be added, comma separated, or on separate parameters.
                          Examples: -a0,1,2 and -ag0,0,1,2 are equivalent.
                                    -ag0,0,1,2,g1,0,1,2 specifies the first three cores in groups 0 and 1.
                                    -ag0,0,1,2 -ag1,0,1,2 is equivalent.
  -b<size>[K|M|G]       block size in bytes or KiB/MiB/GiB [default=64K]
  -B<offs>[K|M|G|b]     base target offset in bytes or KiB/MiB/GiB/blocks [default=0]
                          (offset from the beginning of the file)
  -c<size>[K|M|G|b]     create files of the given size.
                          Size can be stated in bytes or KiB/MiB/GiB/blocks
  -C<seconds>           cool down time - duration of the test after measurements finished [default=0s].
  -D<milliseconds>      Capture IOPs statistics in intervals of <milliseconds>; these are per-thread
                          per-target: text output provides IOPs standard deviation, XML provides the full
                          IOPs time series in addition. [default=1000, 1 second].
  -d<seconds>           duration (in seconds) to run test [default=10s]
  -f<size>[K|M|G|b]     target size - use only the first <size> bytes or KiB/MiB/GiB/blocks of the file/disk/partition,
                          for example to test only the first sectors of a disk
  -f<rst>               open file with one or more additional access hints
                          r : the FILE_FLAG_RANDOM_ACCESS hint
                          s : the FILE_FLAG_SEQUENTIAL_SCAN hint
                          t : the FILE_ATTRIBUTE_TEMPORARY hint
                          [default: none]
  -F<count>             total number of threads (conflicts with -t)
  -g<bytes per ms>      throughput per-thread per-target throttled to given bytes per millisecond
                          note that this can not be specified when using completion routines
                          [default inactive]
  -h                    deprecated, see -Sh
  -i<count>             number of IOs per burst; see -j [default: inactive]
  -j<milliseconds>      interval in <milliseconds> between issuing IO bursts; see -i [default: inactive]
  -I<priority>          Set IO priority to <priority>. Available values are: 1-very low, 2-low, 3-normal (default)
  -l                    Use large pages for IO buffers
  -L                    measure latency statistics
  -n                    disable default affinity (-a)
  -o<count>             number of outstanding I/O requests per target per thread
                          (1=synchronous I/O, unless more than 1 thread is specified with -F)
                          [default=2]
  -p                    start parallel sequential I/O operations with the same offset
                          (ignored if -r is specified, makes sense only with -o2 or greater)
  -P<count>             enable printing a progress dot after each <count> [default=65536]
                          completed I/O operations, counted separately by each thread 
  -r<align>[K|M|G|b]    random I/O aligned to <align> in bytes/KiB/MiB/GiB/blocks (overrides -s)
  -R<text|xml>          output format. Default is text.
  -s[i]<size>[K|M|G|b]  sequential stride size, offset between subsequent I/O operations
                          [default access=non-interlocked sequential, default stride=block size]
                          In non-interlocked mode, threads do not coordinate, so the pattern of offsets
                          as seen by the target will not be truly sequential.  Under -si the threads
                          manipulate a shared offset with InterlockedIncrement, which may reduce throughput,
                          but promotes a more sequential pattern.
                          (ignored if -r specified, -si conflicts with -T and -p)
  -S[bhruw]             control caching behavior [default: caching is enabled, no writethrough]
                          non-conflicting flags may be combined in any order; ex: -Sbw, -Suw, -Swu
  -S                    equivalent to -Su
  -Sb                   enable caching (default, explicitly stated)
  -Sh                   equivalent -Suw
  -Su                   disable software caching, equivalent to FILE_FLAG_NO_BUFFERING
  -Sr                   disable local caching, with remote sw caching enabled; only valid for remote filesystems
  -Sw                   enable writethrough (no hardware write caching), equivalent to FILE_FLAG_WRITE_THROUGH
  -t<count>             number of threads per target (conflicts with -F)
  -T<offs>[K|M|G|b]     starting stride between I/O operations performed on the same target by different threads
                          [default=0] (starting offset = base file offset + (thread number * <offs>)
                          makes sense only with #threads > 1
  -v                    verbose mode
  -w<percentage>        percentage of write requests (-w and -w0 are equivalent and result in a read-only workload).
                        absence of this switch indicates 100% reads
                          IMPORTANT: a write test will destroy existing data without a warning
  -W<seconds>           warm up time - duration of the test before measurements start [default=5s]
  -x                    use completion routines instead of I/O Completion Ports
  -X<filepath>          use an XML file for configuring the workload. Cannot be used with other parameters.
  -z[seed]              set random seed [with no -z, seed=0; with plain -z, seed is based on system run time]

Write buffers:
  -Z                        zero buffers used for write tests
  -Z<size>[K|M|G|b]         use a <size> buffer filled with random data as a source for write operations.
  -Z<size>[K|M|G|b],<file>  use a <size> buffer filled with data from <file> as a source for write operations.

  By default, the write buffers are filled with a repeating pattern (0, 1, 2, ..., 255, 0, 1, ...)

Synchronization:
  -ys<eventname>     signals event <eventname> before starting the actual run (no warmup)
                       (creates a notification event if <eventname> does not exist)
  -yf<eventname>     signals event <eventname> after the actual run finishes (no cooldown)
                       (creates a notification event if <eventname> does not exist)
  -yr<eventname>     waits on event <eventname> before starting the run (including warmup)
                       (creates a notification event if <eventname> does not exist)
  -yp<eventname>     stops the run when event <eventname> is set; CTRL+C is bound to this event
                       (creates a notification event if <eventname> does not exist)
  -ye<eventname>     sets event <eventname> and quits

Event Tracing:
  -e<q|c|s>             Use query perf timer (qpc), cycle count, or system timer respectively.
                          [default = q, query perf timer (qpc)]
  -ep                   use paged memory for the NT Kernel Logger [default=non-paged memory]
  -ePROCESS             process start & end
  -eTHREAD              thread start & end
  -eIMAGE_LOAD          image load
  -eDISK_IO             physical disk IO
  -eMEMORY_PAGE_FAULTS  all page faults
  -eMEMORY_HARD_FAULTS  hard faults only
  -eNETWORK             TCP/IP, UDP/IP send & receive
  -eREGISTRY            registry calls


Examples:

Create 8192KB file and run read test on it for 1 second:

  diskspd -c8192K -d1 testfile.dat
Set block size to 4KB, create 2 threads per file, 32 overlapped (outstanding)
I/O operations per thread, disable all caching mechanisms and run block-aligned random
access read test lasting 10 seconds:

  diskspd -b4K -t2 -r -o32 -d10 -h testfile.dat

Create two 1GB files, set block size to 4KB, create 2 threads per file, affinitize threads
to CPUs 0 and 1 (each file will have threads affinitized to both CPUs) and run read test
lasting 10 seconds:

  diskspd -c1G -b4K -t2 -d10 -a0,1 testfile1.dat testfile2.dat

==========windows=================
######End io.memo #######
######Endmemoof io.memo #######
######Startmemoof locate-2-updatedb.memo #######
######Start locate-2-updatedb.memo #######
# /etc/updatedb.conf: config file for mlocate

# This file sets variables that are used by updatedb.
# For more info, see the updatedb.conf(5) manpage.

# Filesystems that are pruned from updatedb database
#PRUNEFS="afs anon_inodefs auto autofs bdev binfmt binfmt_misc cgroup cifs coda configfs cramfs cpuset debugfs devfs devpts devtmps ecryptfs eventpollfs exofs futexfs ftpfs fuse fusectl gfs gfs2 hostfs hugetlbfs inotifyfs iso9660 jffs2 lustre misc mqueue ncpfs nfs NFS nfs4 nfsd nnpfs ocfs ocfs2 pipefs proc ramfs rpc_pipefs securityfs selinuxfs sfs shfs smbfs sockfs spufs sshfs subfs supermount sysfs tmpfs ubifs udf usbfs vboxsf vperfctrfs"

# Paths which are pruned from updatedb database
#PRUNEPATHS="/tmp /var/tmp /var/cache /var/lock /var/run /var/spool /mnt /cdrom /usr/tmp /proc /media /sys /.snapshots /var/run/media /.snapshots"

# Folder names that are pruned from updatedb database
#PRUNENAMES=".hg .svn CVS"
PRUNENAMES=".git .hg .svn CVS .snapshots"  #####very import ,or many junk files

# Skip bind mounts.
#PRUNE_BIND_MOUNTS="yes"  ####very important ,or cannot search in user home directory


####on opensuse
sudo updatedb
locate /somepath somefile 
######End locate-2-updatedb.memo #######
######Endmemoof locate-2-updatedb.memo #######
######Startmemoof my.cnf #######
######Start my.cnf #######
#########need update basedir/datadir/server-id##########
##########Must do it before start mysql###############
[mysqld]
basedir = /usr/local/mysql
datadir = /data/mysql
server-id = 10 
symbolic-links=0
event_scheduler=ON
log-bin = mysql-bin
binlog_format=MIXED
relay-log = relay-bin
gtid-mode = on
enforce-gtid-consistency = true
log-slave-updates = true
character-set-server=utf8
collation-server=utf8_general_ci
lower_case_table_names = 1
max_connect_errors = 1000
max_connections = 1000
skip-name-resolve = 1
skip_ssl
sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES 
innodb_buffer_pool_size=1024M

######End my.cnf #######
######Endmemoof my.cnf #######
######Startmemoof network.memo #######
######Start network.memo #######
====================================================
====================================================
====================================================


                    cisco enterprise network top example

*****************************************************************************************************
*+------------------+                                                                               *
*|pc11->192.168.1.11|--------------+            Enterprise LAN Area                                 *
*|gw 192.168.1.1    |              |                                                                *
*+------------------+              |                                                                *
*                                  |   F0/1                                                         *
*                                  +---->+----------+ F0/3                                          *
*                                        |L2 SWITCH1|---------------------+                         *
*                                 +----->+----------+                     |                         *
*                                 |   F0/2                                |                         *
*+------------------+             |                                       |                         *
*|pc21->192.168.2.11|-------------+                                       |                         *
*|gw 192.168.2.1    |                                                     |                         *
*+------------------+                                                     |                         *
*                                                                     F0/1|L2port                   *
*                                                                     +----------+                  *
*                                            +----------------------->|L3SWITCH1 |F0/3 L3port       *
*                                            |            F0/2 L2port +----------+192.168.3.1       *
*                                            |                                   |                  *
*                                            |                                   |                  *
*                                            |                                   |                  *
*+------------------+                        |                                   |                  *
*|pc12->192.168.1.12|                        |                      F0/0         |                  *
*|gw 192.168.1.1    |+ ------+               |                     192.168.3.2   |                  *
*+------------------+        |               |                          +--------+                  *
*                            |F0/1       F0/3|                          |Router1 |                  *
*                            +--->+----------+                     F0/1 +--------+                  *
*                                 |L2 SWITCH2|                    1.1.1.1 |                         *
*                         +------>+----------+                            |                         *
*                         |   F0/2                                        |                         *
*                         |                   ****************************|**************************                         
*                         |                   *                   +--+----+-----++-----+
*                         |                   *                   |       |            |
*                         |                   *                   |  F0/0 |1.1.1.2     |
*+------------------+     |                   *                   |  +---------+       |
*|pc22->192.168.2.12|-----+                   *                   +  | Router2 |       +
*|gw 192.168.2.1    |                         *                   |  +---------+       |
*+------------------+                         *                   |  lo0 2.2.2.2       |     
***********************************************                   | INTERNET AREA      |
                                                                  +--+--------+--------+     




###########################################
L2SWITCH1 #SHOW RUN
Building configuration...

Current configuration : 1137 bytes
!
version 12.2
!
hostname L2SWITCH1
!
no ip domain-lookup
!
interface FastEthernet0/1

 switchport access vlan 11
!
interface FastEthernet0/2
 switchport access vlan 12
!
interface FastEthernet0/3
 switchport mode trunk
!
L2SWITCH1#SHOW VTP STATUS
VTP Version                     : 2
Configuration Revision          : 1
Maximum VLANs supported locally : 255
Number of existing VLANs        : 8
VTP Operating Mode              : Client
VTP Domain Name                 : myvtp
VTP Pruning Mode                : Disabled
VTP V2 Mode                     : Disabled
VTP Traps Generation            : Disabled
MD5 digest                      : 0xD1 0x5F 0xD6 0xBC 0x44 0x9A 0x4A 0xFF 
Configuration last modified by 192.168.3.1 at 3-1-93 01:11:33


L2SWITCH1#SHOW VLAN 

VLAN Name                             Status    Ports
---- -------------------------------- --------- -------------------------------
1    default                          active    Fa0/4, Fa0/5, Fa0/6, Fa0/7
			                        ....
11   IT11                             active    Fa0/1
12   HR12                             active    Fa0/2
13   OUT13                            active    

====================================================================






====================================================================
L2SWITCH2#SHOW RUN
Building configuration...

Current configuration : 1117 bytes
!
hostname L2SWITCH2
!
interface FastEthernet0/1
 switchport access vlan 11
!
interface FastEthernet0/2
 switchport access vlan 12
!
interface FastEthernet0/3
 switchport mode trunk


L2SWITCH2#SHOW VLAN

VLAN Name                             Status    Ports
---- -------------------------------- --------- -------------------------------
1    default                          active    Fa0/4, Fa0/5, Fa0/6, Fa0/7
                                                ......
11   IT11                             active    Fa0/1
12   HR12                             active    Fa0/2
13   OUT13                            active  


L2SWITCH2#SHOW VTP STAtus 
VTP Version                     : 2
Configuration Revision          : 1
Maximum VLANs supported locally : 255
Number of existing VLANs        : 8
VTP Operating Mode              : Client
VTP Domain Name                 : myvtp
VTP Pruning Mode                : Disabled
VTP V2 Mode                     : Disabled
VTP Traps Generation            : Disabled
MD5 digest                      : 0xD1 0x5F 0xD6 0xBC 0x44 0x9A 0x4A 0xFF 
Configuration last modified by 192.168.3.1 at 3-1-93 01:11:33

====================================================================






====================================================================
L3SW1#SHOW RUN         ####INTRANET EDGE
Building configuration...

Current configuration : 1330 bytes
!
hostname L3SW1
!
interface Vlan1
 no ip address
 shutdown
!
interface Vlan11
 ip address 192.168.1.1 255.255.255.0
!
interface Vlan12
 ip address 192.168.2.1 255.255.255.0
!
interface Vlan13
 ip address 192.168.3.1 255.255.255.0
!
ip classless
ip route 0.0.0.0 0.0.0.0 192.168.3.2 
!
ip routing ############enable ip route function,PATT

L3SW1#SHOW VLAN

VLAN Name                             Status    Ports
---- -------------------------------- --------- -------------------------------
1    default                          active    Fa0/4, Fa0/5, Fa0/6, Fa0/7
                                                ......
11   IT11                             active    
12   HR12                             active    
13   OUT13                            active    Fa0/3


L3SW1#SHOW VTP STatus 
VTP Version                     : 2
Configuration Revision          : 1
Maximum VLANs supported locally : 1005
Number of existing VLANs        : 8
VTP Operating Mode              : Server
VTP Domain Name                 : myvtp
VTP Pruning Mode                : Disabled
VTP V2 Mode                     : Disabled
VTP Traps Generation            : Disabled
MD5 digest                      : 0xD1 0x5F 0xD6 0xBC 0x44 0x9A 0x4A 0xFF 
Configuration last modified by 192.168.3.1 at 3-1-93 01:11:33
Local updater ID is 192.168.1.1 on interface Vl11 (lowest numbered VLAN interfa


L3SW1#SHOW IP ROUTE
Codes: C - connected, S - static, I - IGRP, R - RIP, M - mobile, B - BGP
        ............
Gateway of last resort is 192.168.3.2 to network 0.0.0.0

C    192.168.1.0/24 is directly connected, Vlan11
C    192.168.2.0/24 is directly connected, Vlan12
C    192.168.3.0/24 is directly connected, Vlan13
S*   0.0.0.0/0 [1/0] via 192.168.3.2


L3SW1#SHOW IP INTER BRIEF
Vlan11                 192.168.1.1     YES manual up                    up
 
Vlan12                 192.168.2.1     YES manual up                    up
 
Vlan13                 192.168.3.1     YES manual up                    up
====================================================================










====================================================================
Router1#SHOW RUN             ##########EDGE ROUTER
Building configuration...

Current configuration : 916 bytes
!
version 12.4

interface FastEthernet0/0
 ip address 192.168.3.2 255.255.255.0
 ip nat inside     ####nat staff 1 of 4
 duplex auto
 speed auto
!
interface FastEthernet0/1
 ip address 1.1.1.1 255.255.255.0
 ip access-group 101 in
 ip nat outside      #####nat staff 2 of 4
 duplex auto
 speed auto
!
interface Vlan1
 no ip address
 shutdown

!         #########nat staff 4 of 4
ip nat pool nat-pool 1.1.1.1 1.1.1.1 netmask 255.255.255.0
ip nat inside source list 1 pool nat-pool overload

ip classless
ip route 0.0.0.0 0.0.0.0 1.1.1.2 
ip route 192.168.0.0 255.255.0.0 192.168.3.1 
!
!          #########nat staff 3 of 4 
access-list 1 permit 192.168.0.0 0.0.255.255

access-list 101 deny ip any 192.168.0.0 0.0.255.255
access-list 101 permit ip any any
!

Router1#SHOW IP INT BRIE
Interface              IP-Address      OK? Method Status                Protocol
 
FastEthernet0/0        192.168.3.2     YES manual up                    up
 
FastEthernet0/1        1.1.1.1         YES manual up                    up
 
Vlan1                  unassigned      YES unset  administratively down down

Router1#SHOW IP ROUTE
Codes: C - connected, S - static, I - IGRP, R - RIP, M - mobile, B - BGP
         ...................
         P - periodic downloaded static route

Gateway of last resort is 1.1.1.2 to network 0.0.0.0

     1.0.0.0/24 is subnetted, 1 subnets
C       1.1.1.0 is directly connected, FastEthernet0/1
S    192.168.0.0/16 [1/0] via 192.168.3.1
C    192.168.3.0/24 is directly connected, FastEthernet0/0
S*   0.0.0.0/0 [1/0] via 1.1.1.2

Router1#show ip nat translations 
Pro  Inside global     Inside local       Outside local      Outside global
icmp 1.1.1.1:93        192.168.1.11:93    2.2.2.2:93         2.2.2.2:93
icmp 1.1.1.1:94        192.168.1.11:94    2.2.2.2:94         2.2.2.2:94
icmp 1.1.1.1:95        192.168.1.11:95    2.2.2.2:95         2.2.2.2:95
icmp 1.1.1.1:96        192.168.1.11:96    2.2.2.2:96         2.2.2.2:96



====================================================================
Router2#show run                #########INTERNET AREA
Building configuration...

Current configuration : 599 bytes
!
hostname Router2

interface Loopback0
 ip address 2.2.2.2 255.255.255.255
!
interface FastEthernet0/0
 ip address 1.1.1.2 255.255.255.0

!
ip route 0.0.0.0 0.0.0.0 1.1.1.1 
end
====================================================================



=======================================
pc
PC>ipconfig 192.168.1.11 255.255.255.0 192.168.1.1
PC>ping 192.168.1.1

Pinging 192.168.1.1 with 32 bytes of data:

Reply from 192.168.1.1: bytes=32 time=1ms TTL=255

Ping statistics for 192.168.1.1:
    Packets: Sent = 1, Received = 1, Lost = 0 (0% loss),
Approximate round trip times in milli-seconds:
    Minimum = 1ms, Maximum = 1ms, Average = 1ms

Control-C
^C
PC>ping 192.168.3.1

Pinging 192.168.3.1 with 32 bytes of data:

Reply from 192.168.3.1: bytes=32 time=0ms TTL=255

Ping statistics for 192.168.3.1:
    Packets: Sent = 1, Received = 1, Lost = 0 (0% loss),
Approximate round trip times in milli-seconds:
    Minimum = 0ms, Maximum = 0ms, Average = 0ms

Pinging 1.1.1.1 with 32 bytes of data:

Reply from 1.1.1.1: bytes=32 time=1ms TTL=254
Reply from 1.1.1.1: bytes=32 time=0ms TTL=254

Ping statistics for 1.1.1.1:
    Packets: Sent = 2, Received = 2, Lost = 0 (0% loss),
Approximate round trip times in milli-seconds:
    Minimum = 0ms, Maximum = 1ms, Average = 0ms

Control-C
^C
PC>ping 2.2.2.2

Pinging 2.2.2.2 with 32 bytes of data:

Reply from 2.2.2.2: bytes=32 time=0ms TTL=253

Ping statistics for 2.2.2.2:
    Packets: Sent = 1, Received = 1, Lost = 0 (0% loss),
Approximate round trip times in milli-seconds:
    Minimum = 0ms, Maximum = 0ms, Average = 0ms

=======================================



====================================================
====================================================
====================================================




http://mobaxterm.mobatek.net/

http://blog.sina.com.cn/s/blog_4d2ec36d01010q9l.html
http://blog.sina.com.cn/s/blog_85eca8730101k27j.html

H3C路由器的SSH设置 (2013-11-05 12:39:23)转载▼
标签： 路由器 h3c ssh 设置 it   分类： H3C
  配置SSH 
# 生成RSA 密钥对。
system-view
[Router] public-key local create rsa
The range of public key size is (512 ~ 2048).
NOTES: If the key modulus is greater than 512,
1-13
It will take a few minutes.
Press CTRL+C to abort.
Input the bits of the modulus[default = 1024]:
Generating Keys...
++++++++
++++++++++++++
+++++
++++++++
# 生成DSA 密钥对。
[Router] public-key local create dsa
The range of public key size is (512 ~ 2048).
NOTES: If the key modulus is greater than 512,
It will take a few minutes.
Press CTRL+C to abort.
Input the bits of the modulus[default = 1024]:
Generating Keys...
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++
# 启动SSH 服务器。
[Router] ssh server enable

# 设置SSH 客户端登录用户界面的认证方式为AAA 认证。
[Router] %user-interface vty 0 4
[Router-ui-vty0-4] authentication-mode scheme
# 设置Router 上远程用户登录协议为SSH。
[Router-ui-vty0-4] protocol inbound ssh
[Router-ui-vty0-4] quit
# 创建本地用户client001，并设置用户访问的命令级别为3。
[Router] local-user client001
[Router-l%user-client001] password simple aabbcc
[Router-l%user-client001] service-type ssh
[Router-l%user-client001] authorization-attribute level 3
[Router-l%user-client001] quit

# 配置SSH 用户client001 的服务务器类型为Stelnet，认证方式为password 认证。（此步骤可以不
配置）
[Router] ssh user client001 service-type stelnet authentication-type password

H3C设备的权限默认分为0-3这四种级别
数值越小，用户的级别越低
(1)访问权限0 级 : ping、tracert、telnet 等网络诊断小程序，不可以dis current
(2)监控权限 1级: dis current、reset、可开debug这种高级系统诊断工具，不能进入system视图进行配置，命令不能保存
(3)系统权限2级 :可以配置除升级版本外的几乎所有业务配置命令，包括创建用户等，可以保存
(4)管理权限3级:关系到系统的基本运行、系统支撑模块功能的命令，这些命令对业务提供支撑作用。包括文件系统、FTP、TFTP、XModem
 
可以使用user privilege level命令来设置用户帐号登陆时的级别



# 配置SSH服务的端口号为1025。
###如果没有该命令，注意升级ios
<Sysname> system-view
[Sysname] ssh server port 1025



###########debug mode###########
<h3c> debugging ike sa    //debug something
<H3C>terminal debugging   //display debug message on screen

<H3C>terminal monitor     //dispay dbug message on screen

<h3c>undo debug all  //revoke all debug on other session
###########debug mode###########

=====================NAT=====================
============example==========================
#
 sysname H3C-router-NAME
#
 nat address-group 0  ####NAT ITEM####
  address %your--public-ip  %your--public-ip
#
 domain default enable system 
#
 dns proxy enable 
#
 dar p2p signature-file flash:/p2p_default.mtd
#
 port-security enable 
#
 password-recovery enable
#  
acl number 2000  ####NAT ITEM####
 rule 0 permit source %your--local-subnet.1.0 0.0.0.255 
#
vlan 1
#
vlan 10
#
domain system 
 access-limit disable
 state active 
 idle-cut disable 
 self-service-url disable 
#
%user-group system
 group-attribute allow-guest
%user-group -in
#
local-user admin
 password cipher %your--encryed-password-here 
 authorization-attribute level 3
 service-type web
local-user ssh-user   ####SSH ITEM####
 password cipher %your--encryed-password-here 
 authorization-attribute level 3
 service-type ssh

#
interface Vlan-interface10
 ip address %your--local-subnet.1.254 255.255.255.0 
#
interface GigabitEthernet0/0 ####NAT ITEM####
 port link-mode route
 nat outbound 2000 address-group 0   ####NAT ITEM####
 nat server 1 protocol tcp global current-interface 58833 inside %your--local-subnet.1.100 8833 ####NAT MAP ITEM####
 nat server 2 protocol tcp global current-interface 58330 inside %your--local-subnet.1.101 8833 ####NAT MAP ITEM####
 ip address %your--public-ip 255.255.255.0 
 dns server %your--dns-ip 
#
interface GigabitEthernet0/9
 port link-mode route
 ip address %your--local-subnet.1 255.255.255.0 
#
interface GigabitEthernet0/8
 port link-mode bridge
 port access vlan 10
#
 ip route-static 0.0.0.0 0.0.0.0 GigabitEthernet0/0 %your--public-ip-gateway
#
 ssh server enable  ####SSH ITEM####
 ssh user ssh-user service-type stelnet authentication-type password
#
 ip https enable 
#
 nms primary monitor-interface GigabitEthernet0/0
#
 load xml-configuration 
#
 load tr069-configuration
#
%user-interface tty 12
%user-interface aux 0
%user-interface vty 0 ####SSH ITEM####
 authentication-mode scheme
 protocol inbound ssh
%user-interface vty 1 4 
 authentication-mode scheme
#
return




######display h3c sn ####
display device manuinfo
slot 0
DEVICE_NAME          : MSR 26-00

######display h3c sn ####







#########h3c site2site vpn##############
#########h3c site2site vpn##############
#########h3c site2site vpn##############
===from 172.31.20/27/28/200 to 172.31.2.96 subnet
===local public ip  2.3.4.5
===remote public ip 1.2.3.4
acl number 3002   ##########define vpn vlan                                                                                                                                                                                                                                                                                                         
 rule 0 permit ip source 172.31.20.0 0.0.0.255 destination 172.31.2.96 0.0.0.7
 rule 5 permit ip source 172.31.27.0 0.0.0.255 destination 172.31.2.96 0.0.0.7
 rule 10 permit ip source 172.31.28.0 0.0.0.255 destination 172.31.2.96 0.0.0.7
 rule 15 permit ip source 172.31.200.0 0.0.0.255 destination 172.31.2.96 0.0.0.7
#
ike proposal 3002   ############phase 1 encryption method
 encryption-algorithm aes-cbc 128
#                 
ike peer name-prefix01-phase1-ike  #####phase 1 parameters,include encryption method,pre-share key,remote public ip,local public ip,nat-t feature
 proposal 3002
 pre-shared-key vpn-key
 remote-address 1.2.3.4
 local-address 2.3.4.5
 nat traversal
#
ipsec transform-set name-prefix01-phase2-ipsec       #####phase2 parameter,include encapsulation model,encrytion and hash method
 encapsulation-mode tunnel
 transform esp
 esp authentication-algorithm sha1 
 esp encryption-algorithm aes-cbc-128
#
ipsec policy 3002 1 isakmp                           ####sa config ,call before phase1 and phase 2 ,acl config,addtional to sa reconnection policy
 connection-name ipsec-2-name-prefix01
 security acl 3002 
 ike-peer name-prefix01-phase1-ike
 transform-set name-prefix01-phase2-ipsec
 sa duration traffic-based 1843200
 sa duration time-based 3600 
#
ip route-static 172.31.2.96 255.255.255.248 GigabitEthernet 0/0 2.3.4.1   #####local gateway public ip address
#
interface GigabitEthernet0/0
 ip address 2.3.4.5 255.255.255.0
 ipsec policy 3002               #####??doing this not enter gui operation

#####After before,enter GUI ,SELECT PUBLIC IP INTERFACE ASGATEWAY interface
=========================================
=======below is reverse config===========

===from 172.31.2.96 to 172.31.20/27/28/28 subnet
===local public ip  1.2.3.4
===remote public ip 2.3.4.5

acl number 3002 
 rule 0 permit ip source 172.31.2.96 0.0.0.7 destination 172.31.20.0 0.0.0.255
 rule 5 permit ip source 172.31.2.96 0.0.0.7 destination 172.31.27.0 0.0.0.255
 rule 10 permit ip source 172.31.2.96 0.0.0.7 destination 172.31.28.0 0.0.0.255
 rule 15 permit ip source 172.31.2.96 0.0.0.7 destination 172.31.200.0 0.0.0.255
#
ike proposal 3002 
 encryption-algorithm aes-cbc 128
#
ike peer name-prefix01-phase1-ike
 proposal 3002 
 pre-shared-key vpn-key
 remote-address 2.3.4.5
 local-address 1.2.3.4
 nat traversal
#
ipsec transform-set name-prefix01-phase2-ipsec
 encapsulation-mode tunnel
 transform esp
 esp authentication-algorithm sha1 
 esp encryption-algorithm aes-cbc-128
#
ipsec policy %your-policy-name 1 isakmp
 connection-name ipsec-2-chengdus-office
 security acl 3002 
 ike-peer name-prefix01-phase1-ike
 transform-set name-prefix01-phase2-ipsec
 sa duration traffic-based 1843200
 sa duration time-based 3600 
#
ip route-static 172.31.20.0 255.255.255.0 GigabitEthernet 0/0 1.2.3.1
ip route-static 172.31.27.0 255.255.255.0 GigabitEthernet 0/0 1.2.3.1
ip route-static 172.31.28.0 255.255.255.0 GigabitEthernet 0/0 1.2.3.1
ip route-static 172.31.200.0 255.255.255.0 GigabitEthernet 0/0 1.2.3.1

#########h3c site2site vpn##############
#########h3c site2site vpn##############
#########h3c site2site vpn##############


########h3c site2sitevpn 2600 v7######
#
interface GigabitEthernet0/0                                                      //60 if set ipsec apply,nat outbound
 port link-mode route
 ip address public-ip 255.255.255.252
 dns server 8.8.8.8 
 nat outbound nat-acl-number
 nat static enable
 ipsec apply policy to-center
#
 ip route-static 0.0.0.0 0 GigabitEthernet0/0 gate-way                                   //70 route must define vpn flow
 ip route-static %peer-lan-seg 24 GigabitEthernet0/0 gate-way
#
acl advanced nat-acl-number                                                             //40 nat acl,PATT DENY VPN
 rule 10 deny ip source %your--lan-seg 0.0.0.7 destination %peer-lan-seg 0.0.0.255
 rule 20 permit ip source %your--lan-seg 0.0.0.7
#
acl advanced some-id-number                                                            //50 VPN ACL,PERMIT NAT
 rule 10 permit ip source %your--lan-seg 0.0.0.7 destination %peer-lan-seg 0.0.0.255
#
ipsec transform-set %your-phase2-ipsec                                                 //35 phase2-ipsec
 esp encryption-algorithm aes-cbc-128
 esp authentication-algorithm sha1
#
ipsec policy to-center 1 isakmp
 transform-set %your-phase2-ipsec 
 security acl some-id-number 
 remote-address %peer-public-ip
 ike-profile %your--profile1
 sa duration time-based 3600
 sa duration traffic-based 1843200
#
ike profile %your--profile1                                                            //30 phase1-ike-3
 keychain %your-phase1-ike
 local-identity address public-ip
 match remote identity address %peer-public-ip 255.255.255.0
#
ike proposal some-id-number                                                           //10  phase1-ike-1
 encryption-algorithm aes-cbc-128
#
ike keychain your-phase-ike                                                          //20  phase1-ike-2
 pre-shared-key address %peer-public-ip 255.255.255.255 key simple %your--key-here

########h3c site2sitevpn 2600 v7######


####h3c site2site vpn with adsl#########
1 adsl end
a deny nat currence on vpn current in nat acl 
b define vpn currence in vpn acl
c1 set ike local-name adsl-end
c2 set id-type name in ike peer segment
c3 set remote-name in ike peer segment
c3-1 set nat traversal in ike peer segment
c4 set remote-address in ike peer segment(remote public fixed ip)
c5 set ipsec no-nat-process enable in public interface
d config other setting like site to site fixed ip
e on vpn pc set a script ping fixed ip end lan address

--example of adsl end with privite lan
#--10 define ike local name 
 ike local-name your-adsl-end

#--20 deny vpn currence in nat acl（nat-acl-number） and permit vpn currence in vpn acl(vpn-acl-number）
acl number nat-acl-number
 rule 3 deny ip source LOCAL-LAN 0.0.0.7 destination HUB-LAN 0.0.0.255
acl number vpn-acl-number
 rule 10 permit ip source LOCAL-LAN 0.0.0.7 destination HUB-LAN 0.0.0.255

#--30
ike proposal vpn-acl-number
 encryption-algorithm aes-cbc 128

#--40 phase1
ike peer your-adsl-end-phase1-ike
 exchange-mode aggressive           ###important
 proposal vpn-acl-number
 pre-shared-key your-pre-share-key 
 id-type name                       ###must exist
 remote-name center01               ###remote name
 remote-address 12.4.1.42           ##HUB end fixed public IP
 nat traversal                      ###needed if cross privite lan 

#--50 phase2
ipsec transform-set your-adsl-end-phase2-ipsec
 encapsulation-mode tunnel
 transform esp
 esp authentication-algorithm sha1
 esp encryption-algorithm aes-cbc-128

#--60 integration
ipsec policy tocenter vpn-acl-number isakmp
 connection-name to-center
 security acl vpn-acl-number
 ike-peer your-adsl-end-phase1-ike
 transform-set your-adsl-end-phase2-ipsec
#

#--70 outboud interface call
interface GigabitEthernet0/0
 port link-mode route
 firewall packet-filter nat-acl-number inbound  ####not need ????
 nat outbound nat-acl-number
 ip address 10.0.1.1 255.255.255.0
 ipsec no-nat-process enable          ####Must present,prevent vpn currence from nat 
 ipsec policy tocenter                ####call policy

#--80 route
 ip route-static HUB-LAN 255.255.255.0 GigabitEthernet0/0 10.1.1.1

2 fixed ip end
a define vpn currence in vpn acl 
b set ike local-name fixed-end
c set id-type name in ike peer segment
d set remote-name in ike peer segment
e set local-address in ike peer segment(local public fixed ip)
f config other setting like site to site fixed ip
####h3c site2site vpn with adsl#########


3 PATT
if outboud interface set some DNAT server entry,
MUST set ipsec no-nat-process enable in outboud interface segment,
the DNAT port only access in the vpn lan segment.
####h3c pppoe#####
interface Dialer2

 bandwidth 102400

 ppp chap password cipher %user-password 

 ppp chap user %user-name 

 ppp pap local-user %user-name password cipher %user-password 

 dialer bundle enable

 dialer-group 2

 dialer timer idle 0

 dialer timer autodial 1

 ip address ppp-negotiate

 nat outbound




interface GigabitEthernet0/0
 port link-mode route
 pppoe-client dial-bundle-number 2

####h3c pppoe#####



#####tftp backup file###
1 install tftp on windows or linux
windows use tftpd32
linux use tftpd server

2 backup on network device

<swith>save
The current configuration will be written to the device. Are you sure? [Y/N]:y
Please input the file name(*.cfg)[flash:/startup.cfg]
(To leave the existing filename unchanged, press the enter key):Your-switch1.cfg
Validating file. Please wait...
Saved the current configuration to mainboard device successfully.

<swith>tftp 192.168.1.1 put Your-switch1.cfg
Press CTRL+C to abort.
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  6720    0     0  100  6720      0   310k --:--:-- --:--:-- --:--:--  386k

<swith>

3 Your can install tftp server in another subnet,
then use NAT way(ie pfsense) map  UDP/69 to Internal Tftp server.
then correctly set firewall on server. 
#####tftp backup file###



#######SCP backup file to remote public ip###
Tips:operation on router or switch
example.com is %your- target storage server address.
Backup file stored in %user-name's home directory.

router1>dir
dir
Directory of flash:
   0 -rw-        5662 Jan 01 2011 08:18:15   startup.cfg 
   ......
   ......

router1>scp example.com ssh-port(ie.22) put startup.cfg start-zs.cfg
Username: %user-name
Press CTRL+C to abort.
Connecting to 1.2.3.4 port ssh-port(ie.22).
The server is not authenticated. Continue? [Y/N]:y
Do you want to save the server public key? [Y/N]:y
%user-name@1.2.3.4's password:
******

startup.cfg                     100% 5421     5.3KB/s   00:00           

#######SCP backup file to remote public ip###



##########modify MTU#############
1 windows 10
PS C:\WINDOWS\system32> netsh interface ipv4 show subinterfaces

   MTU  MediaSenseState   传入字节  传出字节      接口
------  ---------------  ---------  ---------  -------------
  1500                1  26450591265  4335320272  以太网
4294967295                1          0     375863  Loopback Pseudo-Interface 1


PS C:\WINDOWS\system32> netsh interface ipv4 set subinterface "以太网" mtu=1492 store=persistent
确定。


PS C:\WINDOWS\system32> netsh interface ipv4 show subinterfaces

   MTU  MediaSenseState   传入字节  传出字节      接口
------  ---------------  ---------  ---------  -------------
  1492                1  26450845265  4335383496  以太网
4294967295                1          0     375863  Loopback Pseudo-Interface 1


2 linux 
https://www.cyberciti.biz/faq/centos-rhel-redhat-fedora-debian-linux-mtu-size/


Edit /etc/sysconfig/network-scripts/ifcfg-eth0, enter
# vi /etc/sysconfig/network-scripts/ifcfg-eth0

Add MTU, settings:
MTU="9000"

Save and close the file. Restart networking:
# service network restart


3 find out MTU
At the DOS prompt, type in ping www.yahoo.com -f -l 1492 and hit the Enter key:
The results above indicate that the packet needs to be fragmented. Repeat this test, lowering the size the packet in increments of +/-10 (e.g. 1472, 1462, 1440, 1400) until you have a packet size that does not fragment:

######End network.memo #######
######Endmemoof network.memo #######
######Startmemoof openssl.memo #######
######Start openssl.memo #######
####verify csr
$>openssl req -in abc.csr -noout -text
Certificate Request:
    Data:
        Version: 0 (0x0)
        Subject: C=CN, ST=SiChuan, L=Chengdu, O=Your-org, OU=some-ou, CN=*.abc.com
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (2048 bit)
              Modulus:
######verify csr


1. view openssl CA's path
$ openssl version -d
OPENSSLDIR: "/etc/pki/tls"

2. self singnature CA                     ####run on CA server
$ openssl genrsa -out ca.key 2048 && ll   ####generate private key

Generating RSA private key, 2048 bit long modulus
...........................+++
...........+++
e is 65537 (0x10001)
total 4
-rw-r--r--. 1 root root 1675 Apr  1 15:53 ca.key

$ openssl req -x509 -new -nodes -key ca.key -sha256 -days 1024 -out ca.pem && ll ####use private key generate CA

You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:cn
State or Province Name (full name) []:sc
Locality Name (eg, city) [Default City]:cd
Organization Name (eg, company) [Default Company Ltd]:abc
Organizational Unit Name (eg, section) []:op
Common Name (eg, your name or your server's hostname) []:adan
Email Address []:
total 8
-rw-r--r--. 1 root root 1261 Apr  1 15:55 ca.pem

3. singnature other certifacate from CA 
$ openssl req -newkey rsa:2048 -days 1000 -nodes \         ####run on client
-keyout server.key -subj /CN=common-name/OU=ou-name/O=org-name/DC=2nd-dc-name/DC=1st-dc-name > server.csr
Generating a 2048 bit RSA private key
.....+++
..........+++
writing new private key to 'server.key'
-----
$ ls
server.csr  server.key


$ openssl x509 -req -in server.csr -CA ca.pem -CAkey ca.key \  ####run on CA server
 -CAcreateserial -out server.crt -days 500 -sha256 && ls server.crt
Signature ok
subject=/CN=server/OU=Development group/O=Zabbix SIA/DC=zabbix/DC=com
Getting CA Private Key
server.crt


######End openssl.memo #######
######Endmemoof openssl.memo #######
######Startmemoof vsftpd.memo #######
######Start vsftpd.memo #######
########vsftpd.conf
anonymous_enable=NO
local_enable=YES
write_enable=YES
local_umask=022
dirmessage_enable=YES
xferlog_enable=YES
connect_from_port_20=NO
xferlog_std_format=YES
ascii_upload_enable=YES
ascii_download_enable=YES
chroot_local_user=YES
listen_port=port_number
listen=YES
listen_ipv6=NO
allow_writeable_chroot=YES
tcp_wrappers=YES
use_localtime=YES
pam_service_name=vsftpd
userlist_enable=YES
tcp_wrappers=YES
use_localtime=YES
pasv_enable=Yes
pasv_address=public_ip
pasv_min_port=min_port
pasv_max_port=max_port
port_enable=YES
xferlog_enable=YES
xferlog_file=/var/log/xferlog
pasv_promiscuous=YES                     #####访问出现425 bad ip connection 需要添加这行
vsftpd_log_file=/var/log/vsftpd.log


####selinux需要配置这个？
###setsebool -P ftpd_use_passive_mode  on
#另外，端口映射的路由器，或者Azure的Endpoint，AWS的Security Group一定要开启listen_port和pasv_min_port。


# cat ftpusers
# Users that are not allowed to login via ftp
root
bin
daemon
adm
lp
sync
shutdown
halt
mail
news
uucp
operator
games
nobody




# cat user_list
# vsftpd userlist
# If userlist_deny=NO, only allow users in this file
# If userlist_deny=YES (default), never allow users in this file, and
# do not even prompt for a password.
# Note that the default vsftpd pam config also checks /etc/vsftpd/ftpusers
# for users that are denied.
root
bin
daemon
adm
lp
sync
shutdown
halt
mail
news
uucp
operator
games
nobody



# ls
ftpusers  user_list  vsftpd.conf  vsftpd.conf.bak  vsftpd_conf_migrate.sh


# cat /etc/pam.d/vsftpd
#%PAM-1.0
session    optional     pam_keyinit.so    force revoke
auth       required     pam_listfile.so item=user sense=deny file=/etc/vsftpd/ftpusers onerr=succeed


####analize selinux troble
## sealert -a /var/log/audit/audit.log



#setsebool -P ftpd_full_access 1




==========ENCRPTION text for WAN CENTOS6.5 VSFTP START===========
#密文对外网使用的配置
生成证书
shell>openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout /etc/ssl/private/vsftpd.pem -out /etc/ssl/private/vsftpd.pem

cat /etc/vsftpd/vsftpd.conf
[root@WLYD-MGMT vsftpd]# cat /etc/vsftpd/vsftpd.conf
anonymous_enable=NO
local_enable=YES
write_enable=YES
local_umask=022
dirmessage_enable=YES
xferlog_enable=YES
connect_from_port_20=YES
listen_port=21 #自定义端口
xferlog_std_format=YES
chroot_list_enable=YES
chroot_list_file=/etc/vsftpd/chroot_list
listen=YES
pam_service_name=vsftpd
userlist_enable=YES
tcp_wrappers=YES
#pasv_address=ip #服务器MAP PUBLIC IP 可以不要？
pasv_enable=Yes
pasv_min_port=min_number
pasv_max_port=max_number
port_enable=YES
syslog_enable=YES
rsa_cert_file=/etc/ssl/private/vsftpd.pem
rsa_private_key_file=/etc/ssl/private/vsftpd.pem
ssl_enable=YES
allow_anon_ssl=NO
force_local_data_ssl=YES
force_local_logins_ssl=YES
ssl_tlsv1=YES
ssl_sslv2=NO
ssl_sslv3=NO
require_ssl_reuse=NO
ssl_ciphers=HIGH

#启动 #启动 vsftpd /etc/vsftpd/vsftpd.conf &

==========ENCRPTION text for WAN CENTOS6.5 VSFTP END===========


https://unix.stackexchange.com/questions/94603/limit-ftp-access-only-to-the-var-www-with-vsftpd
修改ftp目录

Limit FTP access only to the /var/www with vsftpd

Method 1#
By changing User's Home directory
Make sure following line exists
chroot_local_user=YES

Set User HOME Directory to /var/www/ , if you want to change for existing user then you can use :
usermod --home /var/www/ username

then set required permission on /var/www/





tips 启动出错时，可以直接运行vsftpd查看出错信息；
可以查看/var/log/secure和/var/log/messages日志

######End vsftpd.memo #######
######Endmemoof vsftpd.memo #######
######Startmemoof windows-ftp-2-linux-use-powershell.memo #######
######Start windows-ftp-2-linux-use-powershell.memo #######
# FTP Server Variables
$FTPHost = 'ftp://host:port/'
$FTPUser = 'user'
$FTPPass = 'mimamima'
 
 
 
####first copy folders exclude some dirs to ftp use  
foreach ($op_src in "local-source-directory")
{
   $op_dst="local-dest-directory"
   robocopy $op_src $op_dst /XD  local-exclude-dirs1 local-exclude-dir2  /copy:dt /e  /purge /r:5 /w:5
}

#####then upload local-dest-directory to ftp server
foreach ($UploadFolder in "local-dest-directory")
{
		$webclient = New-Object System.Net.WebClient
		$webclient.Credentials = New-Object System.Net.NetworkCredential($FTPUser,$FTPPass) 
		  
		$SrcEntries = Get-ChildItem $UploadFolder -Recurse 
		$Srcfolders = $SrcEntries | Where-Object{$_.PSIsContainer}
		$SrcFiles = $SrcEntries | Where-Object{!$_.PSIsContainer}


# Create FTP Directory/SubDirectory If Needed - Start
		foreach($folder in $Srcfolders)
		{   
			$SrcFolderPath = $UploadFolder  -replace "\\","\\" -replace "\:","\:"  
			$DesFolder = $folder.Fullname -replace $SrcFolderPath,$FTPHost
			$DesFolder = $DesFolder -replace "\\", "/"
			# Write-Output $DesFolder
		  
			try
				{
					$makeDirectory = [System.Net.WebRequest]::Create($DesFolder);
					$makeDirectory.Credentials = New-Object System.Net.NetworkCredential($FTPUser,$FTPPass);
					$makeDirectory.Method = [System.Net.WebRequestMethods+FTP]::MakeDirectory;
					$makeDirectory.GetResponse();
					#folder created successfully
				}
			catch [Net.WebException]
				{
					try {
						#if there was an error returned, check if folder already existed on server
						$checkDirectory = [System.Net.WebRequest]::Create($DesFolder);
						$checkDirectory.Credentials = New-Object System.Net.NetworkCredential($FTPUser,$FTPPass);
						$checkDirectory.Method = [System.Net.WebRequestMethods+FTP]::PrintWorkingDirectory;
						$response = $checkDirectory.GetResponse();
						#folder already exists!
					}
					catch [Net.WebException] {
						#if the folder didn't exist
					}
				}
		}
# Create FTP Directory/SubDirectory If Needed - Stop
		  
# Upload Files - Start
		foreach($entry in $SrcFiles)
		{
			$SrcFullname = $entry.fullname
			$SrcName = $entry.Name
			$SrcFilePath = $UploadFolder -replace "\\","\\" -replace "\:","\:"
			$DesFile = $SrcFullname -replace $SrcFilePath,$FTPHost
			$DesFile = $DesFile -replace "\\", "/"
			# Write-Output $DesFile
		  
			$uri = New-Object System.Uri($DesFile)
			$webclient.UploadFile($uri, $SrcFullname)

	}
}  

######End windows-ftp-2-linux-use-powershell.memo #######
######Endmemoof windows-ftp-2-linux-use-powershell.memo #######
######Startmemoof redis.memo #######
######Start redis.memo #######
Redis下载安装

0:insatll dependent
yum install gcc-c++ tcl wget

1:官方站点: redis.io 下载最新版或者最新stable版
2:解压源码并进入目录
3: 不用configure
4: 直接make
(如果是32位机器make 32bit)


注:易碰到的问题,时间错误.
原因: 源码是官方configure过的,但官方configure时,生成的文件有时间戳信息,
Make只能发生在configure之后,
如果你的虚拟机的时间不对,比如说是2012年
解决: date -s ‘yyyy-mm-dd hh:mm:ss’ 重写时间
再clock -w 写入cmos




5: 可选步骤: make test 测试编译情况
(可能出现: need tcl >8.4这种情况, yum install tcl)


6: 安装到指定的目录,比如/usr/local/redis
make PREFIX=/usr/local/redis install
注: PREFIX要大写


7: make install之后,得到如下几个文件
redis-benchmark 性能测试工具
redis-check-aof 日志文件检测工(比如断电造成日志损坏,可以检测并修复)
redis-check-dump 快照文件检测工具,效果类上
redis-cli 客户端
redis-server服务端


8: 启动与连接
/path/to/redis/bin/redis-server ./path/to/conf-file
例:[root@localhost redis]# ./bin/redis-server ./redis.conf


连接: 用redis-cli
#/path/to/redis/bin/redis-cli [-h localhost -p 6379 ]


9: 让redis以后台进程的形式运行
编辑conf配置文件,修改如下内容;
daemonize yes

10: use blank password(not recommand)

protected-mode yes
requirepass "your-password"

login path/to/redis/bin/redis-cli [-h localhost -p 6379 ]
>auth your-password

11:  
redis-cli
 >set name david 
OK
 >get name
 "david"

12: on boot 
Centos 6:
echo "/path/2/redis-server /path/2/redis-conf" >>/etc/rc.local
or
echo "@reboot    root     /path/2/redis-server /path/2/redis-conf" >>/etc/crontab

Centos7
$> cat /usr/lib/systemd/system/redis.service 
[Unit]
Description=redis
After=network.target
[Service]
WorkingDirectory=/usr/local/redis
ExecStart=/usr/local/redis/src/redis-server    
User=root                                                                                                                                                                                 
[Install]
WantedBy=multi-user.target

$> systemctl daemon-reload && systemctl enable redis && systemctl start redis

13: security
redis.conf
a: bind some-specfic ip and port
b: set protected-mode 
c: rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
d: or disable command rename-command CONFIG ""

######End redis.memo #######
######Endmemoof redis.memo #######
######Startmemoof mongod.memo #######
######Start mongod.memo #######
--05 install with tar
a> sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config

b> useradd mongod -s /bin/false

c> mkdir -p /var/log/mongodb && chown -R mongod.mongod /var/log/mongodb

d> tar zxf /tmp/mongodb-linux-x86_64-3.6.5.tgz && mv mongodb-linux-x86_64-3.6.5 /usr/local/mongod

e> ln -s /usr/local/mongod/bin/* /bin

f> setup mongod.conf                ##see below

g> setup mongo.service              ##see below

h> set daemon and firewall 
 systemctl daemon-reload &&  firewall-cmd --add-port 27017/tcp --permanent && firewall-cmd --reload

i> dd delay_start_mongod to crontab

@reboot    root    /etc/delay_start_mongod.sh

j> start mongod
/bin/sh /etc/delay_start_mongod.sh

--10 add repo
$> sudo vi /etc/yum.repos.d/mongodb-org.repo
/etc/yum.repos.d/mongodb-org.repo

[mongodb-org-3.4]
name=MongoDB Repository
baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/
gpgcheck=1
enabled=1
gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc

$ > yum repolist

--20 install mongo
sudo yum -y install mongodb-org

sudo systemctl start mongod

sudo systemctl enable mongod

--30 setup cfg ##PATT DBPATH, LOGPATH, PIDPATH, LISTEN INTERFACE
$>sudo  cat /etc/mongod.conf |grep -v '#'
# mongod.conf                                                                                                                                                                                                 

# for documentation of all options, see:
#   http://docs.mongodb.org/manual/reference/configuration-options/

# where to write logging data.
systemLog:
  destination: file
  logAppend: true
  path: /var/log/mongodb/mongod.log

# Where and how to store data.
storage:
  dbPath: /data/mongo
  journal:
    enabled: true
#  engine:
#  mmapv1:
#  wiredTiger:

# how the process runs
processManagement:
  fork: true  # fork and run in background
  pidFilePath: /data/mongo/mongod.pid  # location of pidfile

# network interfaces
net:
  port: 27017
  bindIp: 172.18.8.9  # Listen to local interface only, comment to listen on all interfaces.


#security:

#operationProfiling:

#replication:

#sharding:

## Enterprise-Only Options

#auditLog:

#snmp:




$>sudo systemctl cat mongod.service
# /usr/lib/systemd/system/mongod.service
[Unit]
Description=High-performance, schema-free document-oriented database
After=network.target
Documentation=https://docs.mongodb.org/manual

[Service]
CPUShares=2048            ####default is 1024
MemoryLimit=1G
BlockIOWeight=500        ####valid from 10 to 1000?
User=mongod
Group=mongod
Environment="OPTIONS=-f /etc/mongod.conf"
ExecStart=/usr/bin/mongod $OPTIONS
ExecStartPre=/usr/bin/mkdir -p /data/mongo
ExecStartPre=/usr/bin/chown mongod:mongod /data/mongo
ExecStartPre=/usr/bin/chmod 0755 /data/mongo
PermissionsStartOnly=true
PIDFile=/data/mongo/mongod.pid
Type=forking
# file size
LimitFSIZE=infinity
# cpu time
LimitCPU=infinity
# virtual memory size
LimitAS=infinity
# open files
LimitNOFILE=64000
# processes/threads
LimitNPROC=64000
# locked memory
LimitMEMLOCK=infinity
# total threads (user+kernel)
TasksMax=infinity
TasksAccounting=false
# Recommended limits for for mongod as specified in
# http://docs.mongodb.org/manual/reference/ulimit/#recommended-settings

[Install]
WantedBy=multi-user.target

$ >sudo systemctl daemon-reload && systemctl restart mongod

$>sudo echo never >/sys/kernel/mm/transparent_hugepage/enabled

--35 delay_start_mongod After disable THB
$>grep never -A 1 -B 1 /var/log/mongodb/mongod.log
###need prevent message from log like those:
** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is 'always'.
**        We suggest setting it to 'never'

$> cat /etc/delay_start_mongod.sh 
#!/bin/sh
sleep 8s
echo never >/sys/kernel/mm/transparent_hugepage/defrag
###not need?
###echo never >/sys/kernel/mm/transparent_hugepage/enabled
sleep 2s
systemctl start mongod

$> cat /etc/crontab
......
@reboot     root   /etc/delay_start_mongod.sh
......

--40 result
$ >sudo ss -tlnp|grep 27017
LISTEN     0      128          *:27017                    *:*                   users:(("mongod",pid=1061,fd=7))

$ >sudo systemctl status mongod
● mongod.service - High-performance, schema-free document-oriented database
   Loaded: loaded (/usr/lib/systemd/system/mongod.service; enabled; vendor preset: disabled)
   Active: active (running) since Tue 2018-06-05 16:55:50 CST; 5min ago
     Docs: https://docs.mongodb.org/manual
  Process: 1019 ExecStart=/usr/bin/mongod $OPTIONS (code=exited, status=0/SUCCESS)
  Process: 1015 ExecStartPre=/usr/bin/chmod 0755 /data/mongo (code=exited, status=0/SUCCESS)
  Process: 1007 ExecStartPre=/usr/bin/chown mongod:mongod /data/mongo (code=exited, status=0/SUCCESS)
  Process: 965 ExecStartPre=/usr/bin/mkdir -p /data/mongo (code=exited, status=0/SUCCESS)
 Main PID: 1061 (mongod)
   CGroup: /system.slice/mongod.service
           └─1061 /usr/bin/mongod -f /etc/mongod.conf

######End  mongod.memo #######
######Endmemoof mongod.memo #######
######Startmemoof vim.memo #######
######Start vim.memo #######
#####install vim8 
git clone https://github.com/vim/vim.git
cd vim/src
zypper install python-devel
zypper install gcc gcc-c++ cmake
./configure --prefix=/usr/local/vim8 --enable-pythoninterp=yes --with-python-config-dir=/usr/lib64/python/config ###dir is the config.c in
make
sudo make install
######install YouCompleteMe
a .vimrc Plugin 'Valloric/YouCompleteMe' ###add thi to .vimrc\
b .vimrc PluginInstall  ####run :PluginInstall in .vimrc of vim \need many time download staff
c cd ~/.vim/bundle/YouCompleteMe\
  ./install.py --clang-completer \##?It's Ok with me on no --clang-completer
d .vimrc something later of this m\emo
e copy .ycm_extra_conf.py to ~ or Y\ouCompleteMe ?






http://harttle.com/2015/07/18/vim-cpp.html
http://harttle.com/2013/11/08/vim-config.html
http://harttle.com/2015/11/04/vim-ide.html
http://harttle.com/vim-practice

http://www.jianshu.com/p/f0513d18742a 把vim配置成顺手的python轻量级IDE（一）
http://www.jianshu.com/p/c690a3462224 把vim配置成顺手的python轻量级IDE（二）
https://realpython.com/blog/python/vim-and-python-a-match-made-in-heaven/ VIM and Python - a Match Made in Heaven
http://codingpy.com/article/vim-and-python-match-in-heaven/ Vim与Python真乃天作之合
http://www.cnblogs.com/xbf9xbf/p/4860484.html 【vim环境配置】详细实录
http://www.cnblogs.com/xbf9xbf/p/4876306.html  【vim环境配置】在centos6.4上配置vim的一些零碎记录
http://www.voidcn.com/article/p-utrxbluz-bcx.html vim 插件 youcompleteme full install
https://github.com/yangyangwithgnu/use_vim_as_ide 所需即所获：像 IDE 一样使用 vim


set nocompatible              " required
filetype off                  " required

set rtp+=~/.vim/bundle/Vundle.vim
call vundle#begin()  "these plugin  MUST between begin() and end()
Plugin 'kien/rainbow_parentheses.vim'
Plugin 'gmarik/Vundle.vim'
Plugin 'Xuyuanp/nerdtree-git-plugin'
Plugin 'scrooloose/nerdcommenter'   " commenter: \cc \cu
Plugin 'majutsushi/tagbar'
Plugin 'tmhedberg/SimpylFold'
Plugin 'vim-airline/vim-airline'
Plugin 'vim-airline/vim-airline-themes'
Plugin 'vim-scripts/loremipsum' 
" Plugin 'Lokaltog/powerline', {'rtp': 'powerline/bindings/vim/'}
Plugin 'Valloric/YouCompleteMe'
Plugin 'scrooloose/nerdtree'
call vundle#end()            " required
filetype plugin indent on    " required
set foldmethod=indent
au BufWinLeave * silent mkview  " 保存文件的折叠状态
au BufRead * silent loadview    " 恢复文件的折叠状态
nnoremap <space> za             " 用空格来切换折叠状态
" 这个插件可以显示文件的Git增删状态
set tabstop=4
set clipboard=unnamed
let g:airline_powerline_fonts = 1
" set guifont=Inconsolata\ for\ Powerline:h15
let g:Powerline_symbols = 'fancy'
set encoding=utf-8
set t_Co=256
set fillchars+=stl:\ ,stlnc:\
set term=xterm-256color
set termencoding=utf-8
let mapleader=';'
set pastetoggle=<F9>
set softtabstop=4
inoremap Lorem <Esc><Esc>:Loremipsum 20<CR>
inoremap Ipsum <Esc><Esc>:Loremipsum 70<CR>
set expandtab
set number
map <F3> :TagbarToggle<CR>
set showcmd
set cursorline
set wildmenu
set showmatch
"默认配置文件路径"
"let g:ycm_global_ycm_extra_conf = '~/.ycm_extra_conf.py'
""打开vim时不再询问是否加载ycm_extra_conf.py配置"
let g:ycm_confirm_extra_conf=0
set completeopt=longest,menu
"python解释器路径"
"let g:ycm_path_to_python_interpreter='/usr/bin/python2.7'
""是否开启语义补全"
let g:ycm_seed_identifiers_with_syntax=1
"是否在注释中也开启补全"
"let g:ycm_complete_in_comments=1
"let g:ycm_collect_identifiers_from_comments_and_strings = 0
""开始补全的字符数"
let g:ycm_min_num_of_chars_for_completion=2
"补全后自动关机预览窗口"
"let g:ycm_autoclose_preview_window_after_completion=1
"" 禁止缓存匹配项,每次都重新生成匹配项"
let g:ycm_cache_omnifunc=0
"字符串中也开启补全"
"let g:ycm_complete_in_strings = 1
""离开插入模式后自动关闭预览窗口"
autocmd InsertLeave * if pumvisible() == 0|pclose|endif
"回车即选中当前项"
"inoremap <expr> <CR>       pumvisible() ? '<C-y>' : '\<CR>'     
""上下左右键行为"
inoremap <expr> <Down>     pumvisible() ? '\<C-n>' : '\<Down>'
inoremap <expr> <Up>       pumvisible() ? '\<C-p>' : '\<Up>'
inoremap <expr> <PageDown> pumvisible() ? '\<PageDown>\<C-p>\<C-n>' : '\<PageDown>'
inoremap <expr> <PageUp>   pumvisible() ? '\<PageUp>\<C-p>\<C-n>' : '\<PageUp>'

let g:rbpt_colorpairs = [ ['brown', 'RoyalBlue3'], ['Darkblue', 'SeaGreen3'], ['darkgray', 'DarkOrchid3'], ['darkgreen', 'firebrick3'],['darkcyan', 'RoyalBlue3'],['darkred', 'SeaGreen3'],['darkmagenta', 'DarkOrchid3'],['brown', 'firebrick3'],['gray', 'RoyalBlue3'],['black',       'SeaGreen3'],['darkmagenta', 'DarkOrchid3'],['Darkblue',  'firebrick3'],['darkgreen', 'RoyalBlue3'],['darkcyan', 'SeaGreen3'],['darkred', 'DarkOrchid3'],['red', 'firebrick3']]
let g:rbpt_max = 16
au VimEnter * RainbowParenthesesToggle
au Syntax * RainbowParenthesesLoadRound
au Syntax * RainbowParenthesesLoadSquare
au Syntax * RainbowParenthesesLoadBraces
######End vim.memo #######
######Endmemoof vim.memo #######
######Startmemoof mysql.memo #######
######Start mysql.memo #######
########SQL: Find out number of rows of all tables within a MySQL database
mysql>SELECT table_name, table_rows FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'your_database' order by table_rows;

########SQL: Find out number of rows of all tables within a MySQL database

##############source mysql in bash############
$>cat /etc/custom-scripts/backup-yc50-mysql.sh
#!/bin/bash
PATH=/usr/local/mysql/bin:$PATH
op_date=$(date +%Y%m%d-%H%M)
mysql_backup_file=/root/backup.sql
scriptErrorLog="/var/log/scriptErrorLog"
operationVM=$(hostname)
bak_password="bak-password"
if ! mysqldump -umybak -h127.0.0.1 -P23306 -p"$bak_password" --set-gtid-purged=OFF  backup-db1 backup-db2 > "$mysql_backup_file"

then
        echo "WRONG $op_date backup your-db database $0 ON $operationVM" >>$scriptErrorLog
fi

if ! mysql -pAbcd-123* -e  'source /root/backup.sql' your-db_pro
then
        echo "WRONG $op_date restore your-db database $0 ON $operationVM" >>$scriptErrorLog
fi
##############source mysql in bash############


####profile analyze  ######

mysql> show variables like '%profil%';
+------------------------+-------+
| Variable_name          | Value |
+------------------------+-------+
| have_profiling         | YES   |
| profiling              | OFF   |
| profiling_history_size | 15    |
+------------------------+-------+
3 rows in set (0.00 sec)
   
mysql> set profiling = 1;
Query OK, 0 rows affected, 1 warning (0.00 sec)

mysql> show variables like '%profil%';
+------------------------+-------+
| Variable_name          | Value |
+------------------------+-------+
| have_profiling         | YES   |
| profiling              | ON    |
| profiling_history_size | 15    |
+------------------------+-------+
3 rows in set (0.00 sec)


mysql>select * from t1 where create_time <'2017-09-24';


mysql> show profiles;
+----------+------------+---------------------------------------------------------------------------------------------------------------------------+
| Query_ID | Duration   | Query                                                                                                                     |
+----------+------------+---------------------------------------------------------------------------------------------------------------------------+
|       56 | 0.00567875 | select * from t1 where create_time <'2017-09-24'                                                                          |
+----------+------------+---------------------------------------------------------------------------------------------------------------------------+
15 rows in set, 1 warning (0.00 sec)

mysql> select sum(duration) FROM INFORMATION_SCHEMA.PROFILING  WHERE QUERY_ID = 56 into @total_time;
Query OK, 1 row affected, 1 warning (0.00 sec)

mysql> select @total_time;
+-------------+
| @total_time |
+-------------+
|    0.0567875|
+-------------+
1 row in set (0.00 sec)

mysql> select state,concat((round(duration/@total_time,4)*100),'%') as Percent FROM INFORMATION_SCHEMA.PROFILING WHERE QUERY_ID = 56;
+----------------------+------------------------------------------------+
| state                | Percent                                        |
+----------------------+------------------------------------------------+
| starting             | 2.1000%                                        |
| checking permissions | 0.2600%                                        |
| Opening tables       | 0.4800%                                        |
| init                 | 0.8500%                                        |
| System lock          | 0.4200%                                        |
| optimizing           | 0.2600%                                        |
| statistics           | 3.1700%                                        |
| preparing            | 0.5100%                                        |
| executing            | 0.1200%                                        |
| Sending data         | 88.1900%                                       |
| end                  | 0.2600%                                        |
| query end            | 0.9000%                                        |
| closing tables       | 0.2300%                                        |
| freeing items        | 1.8100%                                        |
| cleaning up          | 0.4600%                                        |
+----------------------+------------------------------------------------+
15 rows in set, 1 warning (0.00 sec)

####profile analyze ######


#####deferred join延迟关联#########

https://www.bennadel.com/blog/3168-high-performance-mysql-optimization-backups-and-replication-by-baron-schwartz-peter-zaitsev-and-vadim-tkachenko.htm
http://www.iheavy.com/2013/06/19/3-ways-to-optimize-for-paging-in-mysql/
http://superve.leanote.com/post/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%88%86%E9%A1%B5%E4%BC%98%E5%8C%96

a)###
mysql> desc t1;
Current database: wlyc_log

+-------------+-------------+------+-----+-------------------+----------------+
| Field       | Type        | Null | Key | Default           | Extra          |
+-------------+-------------+------+-----+-------------------+----------------+
| cip         | varchar(50) | YES  | MUL | NULL              |                |
| create_time | datetime    | NO   | MUL | CURRENT_TIMESTAMP |                |
| id          | int(11)     | NO   | PRI | NULL              | auto_increment |
+-------------+-------------+------+-----+-------------------+----------------+
3 rows in set (0.11 sec)

b)###
mysql> show index from t1;
+-------+------------+-----------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+
| Table | Non_unique | Key_name        | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |
+-------+------------+-----------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+
| t1    |          0 | PRIMARY         |            1 | id          | A         |     1831515 |     NULL | NULL   |      | BTREE      |         |          

c)###
mysql> select count(1) from t1;
+----------+
| count(1) |
+----------+
|  1835986 |
+----------+
1 row in set (0.59 sec)

d1)### 1st clause                               //using(id) equl on t1.id = tmp.id here 
mysql> select t1.id,t1.create_time from t1 inner join (select id from t1 limit 1600000,3) as tmp using(id);
+---------+---------------------+
| id      | create_time         |
+---------+---------------------+
| 1600001 | 2018-02-19 14:26:18 |
| 1600002 | 2018-02-19 14:26:27 |
| 1600003 | 2018-02-19 14:27:06 |
+---------+---------------------+
3 rows in set (0.79 sec)

d2)### 2nd clause                             //on t1.id = tmp.id equl using(id) here
mysql> select t1.id,t1.create_time from t1 inner join (select id from t1 limit 1100000,3) as tmp on t1.id = tmp.id;
+---------+---------------------+
| id      | create_time         |
+---------+---------------------+
| 1100001 | 2018-01-07 23:35:17 |
| 1100002 | 2018-01-07 23:35:27 |
| 1100003 | 2018-01-07 23:35:40 |
+---------+---------------------+
3 rows in set (0.70 sec)

#####deferred join延迟关联#########

###Insert auto increment primary key to existing table
ALTER TABLE tbl ADD id INT PRIMARY KEY AUTO_INCREMENT;
###Insert auto increment primary key to existing table

####simulate the DeadLock issue################

1)initialize
 
mysql>use test ;
mysql> create table table_a ( emp int, ename varchar(100));
mysql> create table table_b ( emp int, ename varchar(100));
mysql> insert into table_a values (1,'anil');
mysql> insert into table_a values (2,'sunil');
mysql> insert into table_b values (2,'sunil');
mysql> insert into table_b values (1,'anil');

2)open two sessions,geneate deadlock

1st session
mysql> use test;
mysql> start transaction;                                            //not commit 
mysql> update table_a set ename='xxx' where emp=1;
mysql> update table_b set ename='xxx' where emp=1;

2nd session
mysql> use test;
mysql> start transaction;
mysql> update table_b set ename='xxx' where emp=1;                  //on 5.7.xx deadlock detected here
mysql> update table_a set ename='xxx' where emp=1;
mysql>  update table_a set ename='zzz' where emp=1;
ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction



3)verification

mysql> SHOW ENGINE INNODB STATUS\G;                                //key step
......omit something......
------------
TRANSACTIONS
------------
Trx id counter 14198
Purge done for trx's n:o < 14196 undo n:o < 0 state: running but idle
History list length 32
LIST OF TRANSACTIONS FOR EACH SESSION:
---TRANSACTION 14197, ACTIVE 785 sec starting index read
mysql tables in use 1, locked 1
LOCK WAIT 2 lock struct(s), heap size 1136, 4 row lock(s)        //thread id is show processlist id
MySQL thread id 186, OS thread handle 139730706839296, query id 1118246 localhost 127.0.0.1 root updating
update table_b set ename='xxx' where emp=1                       //deadlock sql clause
------- TRX HAS BEEN WAITING 5 SEC FOR THIS LOCK TO BE GRANTED:  //below is database and tables 
RECORD LOCKS space id 457 page no 3 n bits 72 index GEN_CLUST_INDEX of table `t1`.`table_b` trx id 14197 lock_mode X waiting
Record lock, heap no 2 PHYSICAL RECORD: n_fields 5; compact format; info bits 0
 0: len 6; hex 000000823f3f; asc     ??;;
 1: len 6; hex 00000000376a; asc     7j;;
 2: len 7; hex eb000001e00110; asc        ;;
.......omit something......
####simulate the Dead Lock issue################


###purge delete binary log
mysql>show binary logs;  //view result
mysql>PURGE BINARY LOGS TO 'mysql-bin.010';
or 
mysql>PURGE BINARY LOGS BEFORE '2008-04-02 22:46:26';
###purge delete binary log

####disable slow log or general log online
mysql>set global slow_query_log = off
and/or 
mysql>set global general_log =off

then add those in my.cnf

slow_query_log = off 
and/or
general_log =off

even free disk space  

$>echo "" > /path/to/log_file 

####disable slow log or general log 

###import table from another_table on different database
If you have shell access you may use mysqldump to dump the content of database1.table1 and pipe it to mysql to database2. The problem here is that table1 is still table1.

$>mysqldump --user=user1 --password=password1 database1 table1 \
| mysql --user=user2 --password=password2 database2

Maybe you need to rename table1 to table2 with another query. On the other way you might use sed to change table1 to table2 between the to pipes.

$>mysqldump --user=user1 --password=password1 database1 table1 \
| sed -e 's/`table1`/`table2`/' \
| mysql --user=user2 --password=password2 database2

If table2 already exists, you might add the parameters to the first mysqldump which dont let create the table-creates.

$>mysqldump --no-create-info --no-create-db --user=user1 --password=password1 database1 table1 \
| sed -e 's/`table1`/`table2`/' \
| mysql --user=user2 --password=password2 database2



mysql>CREATE TABLE db1.table1 SELECT * FROM db2.table1

###import table from another_table on different database


###get data input from another table
create table new_table as select field1,field2,...filedn from another_table
###get data input from another table

###use index from table 
select fld1,fld2.. from table t use index(index_name) where ... group by ...
###use index from table 

###set memory engine size(For Example 512MB)

mysql> set max_heap_table_size = 512 * 1024 *1024;

mysql> show variables like '%heap%'; //verification
+---------------------+-----------+
| Variable_name       | Value     |
+---------------------+-----------+
| max_heap_table_size | 536870912 |
+---------------------+-----------+
1 row in set (0.00 sec)

###set memory engine size


####windows mysql  中文乱码 on  powershell cmd
run
chcp 65001
####windows mysql  中文乱码 on  powershell cmd


######my.cnf config###############
server-id = 2
symbolic-links=0
event_scheduler=ON
log-bin = mysql-bin
binlog_format = MIXED
relay-log = relay-bin
gtid-mode = on
enforce-gtid-consistency = true
log-slave-updates = true
character-set-server=utf8
collation-server=utf8_general_ci
lower_case_table_names = 1
max_connect_errors = 1000
max_connections = 1000
skip-name-resolve = 1
binlog-ignore-db=mysql,information_schema,performance_schema,test

sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
######my.cnf config###############


##############haproxy on azure##############################
=======================azure ilb set====================================
Topology
172.16.0.10--3306 frontend
172.16.0.11--3306 backend1 master 
172.16.0.12--3306 bacdend2 slave


先创建ILB
azure service internal-load-balancer add --serviceName your-service --internalLBName Mysqlilb  --subnet-name coredb-01 --static-virtualnetwork-ipaddress 172.16.0.10

然后附加endpoint到前面创建的ILB，注意-b参数(load balancer)，共两台机器
azure vm endpoint create your-service-DB02L 3306 -n mysqlELB --local-port 3307  --protocol tcp --probe-port 3307 --probe-protocol tcp --probe-interval 10 --probe-timeout 31 -b mysqllbs --internal-load-balancer-name Mysqlilb
azure vm endpoint create your-service-DB01L 3306 -n mysqlELB --local-port 3307  --protocol tcp --probe-port 3307 --probe-protocol tcp --probe-interval 10 --probe-timeout 31 -b mysqllbs --internal-load-balancer-name Mysqlilb

##下面这条计划使用3306工作端口，3307探测端口，使用nc -l生成探测端口，失败了
azure vm endpoint create your-service-DB01L 3306 -n mysqlELB --local-port 3306  --protocol tcp --probe-port 3307 --probe-protocol tcp --probe-interval 5 --probe-timeout 15 -b lbs --internal-load-balancer-name Mysqlilb

chael@linux-gzbl:~> azure vm endpoint list your-service-DB02L
info:    Executing command vm endpoint list
+ Getting virtual machines
data:    Name      Protocol  Public Port  Private Port  Virtual IP       EnableDirectServerReturn  Load Balanced
data:    --------  --------  -----------  ------------  ---------------  ------------------------  -------------
data:    mysqlELB  tcp       3306         3307                           false                     Yes
data:    SSH       tcp       60002        22            128.5.6.9  false                     No
info:    vm endpoint list command OK
Michael@linux-gzbl:~> azure vm endpoint list your-service-DB01L
info:    Executing command vm endpoint list
+ Getting virtual machines
data:    Name      Protocol  Public Port  Private Port  Virtual IP       EnableDirectServerReturn  Load Balanced
data:    --------  --------  -----------  ------------  ---------------  ------------------------  -------------
data:    mysqlELB  tcp       3306         3307          172.16.0.11     false                     Yes
data:    SSH       tcp       3002        22            128.5.6.9  false                     No
info:    vm endpoint list command OK
Michael@linux-gzbl:~> azure vm endpoint create your-service-DB02L 3306 -n mysqlELB --local-port 3307  --protocol tcp --probe-port 3307 --probe-protocol tcp --probe-interval 5 --probe-timeout 15 -b lbs --internal-load-balancer-name Mysqlilb



====powershell set=============
PS C:\Users\wlyd-1> Get-AzureVM -ServiceName t-wlyd-it -Name ilb1 |Add-AzureEndpoint -Name TCP-3306-3306 -Protocol tcp -LocalPort 3306 -PublicPort 3306 -ProbePort 3306 -InternalLoadBalancerName dbilb -LBSetName lbs -ProbeProtocol tcp| Update-AzureVM

OperationDescription OperationId                          OperationStatus
-------------------- -----------                          ---------------
Update-AzureVM       441bca73-64d0-4192-9c7a-8b9f84fdb0e8 Succeeded



PS C:\Users\wlyd-1> Get-AzureVM -ServiceName t-wlyd-it -Name ilb2 |Add-AzureEndpoint -Name TCP-3306-3306 -Protocol tcp -LocalPort 3306 -PublicPort 3306 -ProbePort 3306 -InternalLoadBalancerName dbilb -LBSetName lbs -ProbeProtocol tcp| Update-AzureVM
OperationDescription OperationId                          OperationStatus
-------------------- -----------                          ---------------
Update-AzureVM       430d7187-c766-45c4-b57e-d39e6d844674 Succeeded

====powershell set=============



######mysql haproxy port#############
# ss -tlnp |grep 3306
LISTEN     0      128                      :::3306                    :::*      users:(("mysqld",1972,15))

# ss -tlnp |grep 3307
LISTEN     0      128                       *:3307                     *:*      users:(("haproxy",2012,5))
######mysql haproxy port#############


=======================azure ilb set====================================

==================haproxy core cfg use mysql-check=====================                                                                                    
=======================================================================
=======================================================================
cat /etc/haproxy/haproxy.cfg


listen  proxy-mysql *:3307
        mode tcp
        option mysql-check
        balance roundrobin
        ####InternalLoadBalancerName IP IS 172.16.0.10,Access Port is 3306
        server db01 172.16.0.11:3306 check inter 1s rise 2 fall 2
        server db02 172.16.0.12:3306 check inter 1s rise 2 fall 2 backup
==================haproxy core cfg use mysql-check end=================
=======================================================================
=======================================================================
# nc -vz 172.16.0.10 3306
Connection to 172.16.0.10 3306 port [tcp/mysql] succeeded!


# mysql -uroot -h172.16.0.10 -p
Enter password: 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 8169
Server version: 5.6.33-log Source distribution

Copyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| percona            |
| performance_schema |
+--------------------+
4 rows in set (0.20 sec)


==============db server down log on proxy
# cat /var/log/haproxy.log |grep Server
Dec  1 15:06:10 localhost haproxy[2025]: Server proxy-mysql/db01 is DOWN, reason: Layer4 connection problem, info: "Connection refused", check duration: 0ms. 0 active and 1 backup servers left. Running on backup. 0 sessions active, 0 requeued, 0 remaining in queue.
Dec  1 15:10:26 localhost haproxy[2025]: Server proxy-mysql/db01 is UP, reason: Layer7 check passed, code: 0, info: "5.6.33-log", check duration: 1ms. 1 active and 1 backup servers online. 0 sessions requeued, 0 total in queue.
Dec  1 15:17:03 localhost haproxy[2025]: Backup Server proxy-mysql/db02 is DOWN, reason: Layer4 connection problem, info: "Connection refused", check duration: 0ms. 1 active and 0 backup servers left. 0 sessions active, 0 requeued, 0 remaining in queue.
Dec  1 15:19:39 localhost haproxy[2025]: Backup Server proxy-mysql/db02 is UP, reason: Layer7 check passed, code: 0, info: "5.6.33-log", check duration: 0ms. 1 active and 1 backup servers online. 0 sessions requeued, 0 total in queue.

==============db server down log on proxy


##############haproxy on azure##############################





#####################################################################
#####################################################################
###########batch insert mysql bash script############################
# cat insert2mysql 
#!/bin/bash
PATH=/usr/local/mysql/bin:/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin
rm mish
touch mish
chmod 755 mish

echo '#!/bin/bash'>mish                                                                                                                                                                                                                  
for((i=1;i<20000;i++))
do
        echo "mysql -ucs -h172.16.20.11 -pabcd123 -e 'insert into u value($i)' t">>mish;
done

======================generate like follow==========================
cat mish
mysql -ucs -h172.16.20.11 -pabcd123 -e 'insert into u value(1)' t
mysql -ucs -h172.16.20.11 -pabcd123 -e 'insert into u value(2)' t
mysql -ucs -h172.16.20.11 -pabcd123 -e 'insert into u value(3)' t
#####################################################################
#####################################################################
###########batch insert mysql bash script end########################





####index tuning 索引优化#####

燕十八
http://superve.leanote.com/cate/study


####index tuning 索引优化#####


###############mycli##########
http://www.jianshu.com/p/841e5477d3c0
https://www.tuicool.com/articles/ZnANBvq

tips:
1. Map mysql-server to localhost
## L represent map remote end to LOCAL 
## 23306 represent LOCAL  port
## 3306  represent REMOTE  mysql port
$>ssh -NCfqL 23306:localhost:3306 Michael@mysql-server

2. Test map status
$> nc -vz 127.0.0.1 23306
Connection to 127.0.0.1 23306 port [tcp/*] succeeded!

3. Connect  to localhost
$>mycli -uroot -h127.0.0.1 -P23306 -pPassword

4. Done
$> mycli -h127.0.0.1 -P23306 -uroot -pPassowd
Version: 1.8.1
Chat: https://gitter.im/dbcli/mycli
Mail: https://groups.google.com/forum/#!forum/mycli-users
Home: http://mycli.net
Thanks to the contributor - Anonymous
mysql root@127.0.0.1:(none)> show DATABASES;
+--------------------+
| Database           |
|--------------------|
| information_schema |
| deviceregister     |
| sys                |
| test               |
+--------------------+
14 rows in set
Time: 0.003s


5. Auto complete
##first input select from sysrole s;
##back to select input s. chose your need
##s is alias
## BUT mysql.user table didn't work 
###PATT SPACE,PUCTION ETC DETAIL

> select s.`IsDeleted`,s.`RoleName` from sysrole s;
+-------------+------------+
|   IsDeleted | RoleName   |
|-------------+------------|
|           0 |default_role|
+-------------+------------+

6. Warning 
 mycli didn't support delimiter
 create procedure must like this:
CREATE PROCEDURE dorepeat(p1 INT)
BEGIN
  SET @x = 0;
  REPEAT SET @x = @x + 1; UNTIL @x > p1 END REPEAT;
END;
###############mycli##########



#####procedure variable from select clause
 
mysql> delimiter $
mysql> create procedure procedure_variable_from_select_clause() 
        begin 
        declare days_100_ago date;   ###100days ago 
        SELECT DATE_SUB(NOW(), INTERVAL 100 day) into days_100_ago;
        select count(*) from data_gps where timestamp < days_100_ago; end $
mysql> delimiter ;
mysql> call procedure_variable_from_select_clause();
########schuduler event
mysql> create definer= current_user 
    event event_name 
    on schedule at 'date' + interval time
    do something(or_procedure);




###############schedule with storage procedure ###############
###The follow 2 is manual input 
###official link    https://dev.mysql.com/doc/refman/5.6/en/create-event.html
create procedure sp1() begin insert into t1 value (5) ;end

create event myevent on schedule every 5 second starts current_timestamp + INTERVAL 1 minute do call sp1()


###The fllow is system status 
mysql> show create procedure sp1\G;
*************************** 1. row ***************************
。。。。。。
    Create Procedure: CREATE DEFINER=`root`@`localhost` PROCEDURE `sp1`()
begin insert into t1 value (5) ;end
。。。。。。


mysql> show create event myevent\G;
*************************** 1. row ***************************
               Event: myevent
            sql_mode: STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION
           time_zone: SYSTEM
        Create Event: CREATE DEFINER=`root`@`localhost` EVENT `myevent` ON SCHEDULE EVERY 5 SECOND STARTS '2017-11-13 01:30:39' ON COMPLETION NOT PRESERVE ENABLE DO call sp1()
character_set_client: utf8
collation_connection: utf8_general_ci
  Database Collation: latin1_swedish_ci
1 row in set (0.00 sec)

ERROR: 
No query specified

mysql> show processlist;
+----+-----------------+-----------+------+---------+------+-----------------------------+------------------+
| Id | User            | Host      | db   | Command | Time | State                       | Info             |
+----+-----------------+-----------+------+---------+------+-----------------------------+------------------+
| 26 | event_scheduler | localhost | NULL | Daemon  |    5 | Waiting for next activation | NULL             |
| 94 | root            | localhost | test | Query   |    0 | init                        | show processlist |
+----+-----------------+-----------+------+---------+------+-----------------------------+------------------+
2 rows in set (0.00 sec)

mysql> show events;
+------+---------+----------------+-----------+-----------+------------+----------------+----------------+---------------------+------+---------+------------+----------------------+----------------------+--------------------+
| Db   | Name    | Definer        | Time zone | Type      | Execute at | Interval value | Interval field | Starts              | Ends | Status  | Originator | character_set_client | collation_connection | Database Collation |
+------+---------+----------------+-----------+-----------+------------+----------------+----------------+---------------------+------+---------+------------+----------------------+----------------------+--------------------+
| test | myevent | root@localhost | SYSTEM    | RECURRING | NULL       | 5              | SECOND         | 2017-11-13 01:30:39 | NULL | ENABLED |          0 | utf8                 | utf8_general_ci      | latin1_swedish_ci  |
+------+---------+----------------+-----------+-----------+------------+----------------+----------------+---------------------+------+---------+------------+----------------------+----------------------+--------------------+
1 row in set (0.01 sec)

mysql> show variables like "%schedule%"; ####Here must be ON

+-----------------+-------+
| Variable_name   | Value |
+-----------------+-------+
| event_scheduler | ON    |
+-----------------+-------+
1 row in set (0.00 sec)
###############schedule with storage procedure ###############
===========================================  


############xtrabackup mysql##################################
####install
环境：CENTOS 7+Xtrabackup2.4+mysql 5.7（社区版本）
mysql5.7需要xtrabackup2.4
需要process权限
需要--host --port --socket参数

#####dependent install
yum install libev
yum install perl-devel
yum install rsync
yum install -y perl-Digest-MD5.x86_64
rpm -ivh percona-xtrabackup-24-2.4.7-2.el7.x86_64.rpm 

###backup
1 full backup 
innobackupex --user=bkpuser --port=3306 \
--socket=/usr/local/mysql/mysql.sock \
--password=s3cret ./

2 single table backup
innobackupex --user=root --host=localhost --password=somePW \
--socket=/usr/local/mysql/mysql.sock \
--tables-file=/root/restore/foo.txt .
上面的tables-file需要接完整的路径

###restore
0 innobackupex --apply-log --exports your-backup-full-path

1 systemctl stop mysqld

2 netstat -tlnp|grep mysqld ###确保已经关闭mysql

3 copy your-backup-full-path/tables-file to your-mysql-data-path

        cp your-restored-table.* /usr/local/mysql/data/your-database/
        cp: overwrite ‘/usr/local/mysql/data/your-database/your-restored-table.cfg’? y
        cp: overwrite ‘/usr/local/mysql/data/your-database/your-restored-table.exp’? y
        cp: overwrite ‘/usr/local/mysql/data/your-database/your-restored-table.frm’? y
        cp: overwrite ‘/usr/local/mysql/data/your-database/your-restored-table.ibd’? y

4 chown mysql-user.mysql-user your-mysql-data-path

5 systemctl start mysqld

6 对于数据库级别的恢复，如果还有events，procedure要恢复;需要使用同样的方法恢复mysql数据库

7 tips
模拟了文中丢弃表空间没有问题，
模拟了文中丢弃文件在从备份文件中copy back成功。
使用的是直接copy back后chown的方法，牛，
备份还原单个表，验证成功。





mysql> drop database your-database;
ERROR 1010 (HY000): Error dropping database (can't rmdir './your-database/', errno: 17)

# rm -f /path/2/your-database/*
mysql> drop database your-database;
Query OK, 0 rows affected (0.00 sec)



Partial Backups
使用这个方法还原单个数据库也成功，但文档上要还原mysql，我
没有做，模拟数据文件丢失，在原来的服务器上处理好copy-back，
shutdown mysql，copy back，chown ，start mysql，done



注意：backup后一定要innobackupex --apply-log --export your-backup-full-path
这个过程在源服务器的正常状态下运行，并且一定要成功，
备份结果才可以使用。
==============================================

############xtrabackup mysql##################################



#####忘记root密码Linux 5.7.16#####

0 official link https://dev.mysql.com/doc/refman/5.7/en/resetting-permissions.html 

1 shell>$ pwd #在该目录编辑mysql-init   
/usr/local/mysql

2 shell>$ cat mysql-init 
alter user 'root'@'localhost' identified by 'your-temp-password';

3 shell>$ /usr/local/mysql/bin/mysqld --user=mysql --init-file=/usr/local/mysql/mysql-init &

4 shell>$ mysql -uroot -hlocalhost -pyour-temp-password

5 mysql> alter user 'root'@'localhost' identified by 'your-new-password';

6 mysql> flush privileges;

7 mysql> exit;

8 shell>$ mysqladmin -uroot -hlocalhost shutdown -pyour-new-password

9 shell>$ systemctl start mysqld 

#####忘记root密码Linux 5.7.16#####




#########Windows 安装mysql#########
1 下载zip https://dev.mysql.com/downloads/mysql/
2 解压zip
3 copy TO DEST
4 VIM MY.INI
[mysqld]
basedir=D:\\mysql
datadir=D:\\mysql\\data
character-set-server=utf8
collation-server=utf8_general_ci
log-output=FILE
slow-query-log=1
slow_query_log_file="your-slow.log"
long_query_time=10
skip_ssl
# Binary Logging.
log-bin="mysql-bin.log"
lower_case_table_names = 1
innodb_buffer_pool_size=8192M
# Error Logging.
log-error="your-log.err"


# Server Id.
server-id=166


5 INITIAL （特权模式）
PATH/2/mysqld.exe --defaults-file=path2:\\my.ini  --initialize --console
##有疑问，运行mysqld.exe --verbose --help


6 设置service


\bin\mysqld.exe --install


sc delete MySQL ##删除mysql服务


7 忘记密码（备忘）
a 建立一个文件recover.txt；录入ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass';


b mysqld --init-file=path2:\\recover.txt --console


c 重启后（不重起?)mysql -uroot -hlocalhost -p new-password


8 修改root密码
mysql> alter user 'root'@'localhost' identified by 'newPassword';
Query OK, 0 rows affected (0.00 sec)


mysql> flush privileges;
Query OK, 0 rows affected (0.00 sec)


9 验证：


E:\mysql\bin>mysql.exe -uroot -hlocalhost -p
Enter password: *********
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 3
Server version: 5.7.18 MySQL Community Server (GPL)


Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.


Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.


Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.


mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
| test1              |
+--------------------+
5 rows in set (0.00 sec)
#########Windows 安装mysql end#########




##############


修改5.7 初始密码
You must reset your password using ALTER USER statement before executing this statement.
mysql> alter user 'root'@'localhost' identified by 'you-New-Password-here';
mysql>flush privileges;
##############
##################
http://www.voidcn.com/article/p-bwqyloth-bao.html
c++: internal compiler error: Killed (program cc1plus)


Please submit a full bug report,


with preprocessed source if appropriate.


See <http://bugzilla.redhat.com/bugzilla> for instructions.


make[2]: *** [unittest/gunit/CMakeFiles/merge_small_tests-t.dir/merge_small_tests.cc.o] Error 4


make[1]: *** [unittest/gunit/CMakeFiles/merge_small_tests-t.dir/all] Error 2


make: *** [all] Error 2


google一番后发现是 内存不够 swap分区也不够


解决方案：


[root@web_1 ~]# dd if=/dev/zero of=/swapfile bs=1k count=2048000


[root@web_1 ~]# mkswap /swapfile


[root@web_1 ~]# swapon /swapfile


###############


####mysql bash scrip 含特殊字符#####


# cat readmysql.sh
#!/bin/bash
##can not set password include ' \ ?
##and " need escape
##the pw itself is A1-@;,&!#$"]=+%!>.


pw="A1-@;,&!#$\"]=+%!>."   ##密码中的双引号前面加\转义
mysql -p"$pw" -e 'select user,host,authentication_string from user' mysql


# ./readmysql.sh
mysql: [Warning] Using a password on the command line interface can be insecure.
+-----------+-----------+-------------------------------------------+
| user      | host      | authentication_string                     |
+-----------+-----------+-------------------------------------------+
| root      | localhost | *466D1973D4FA6C14FF90DF20AC7AF3FC6C51AA09 |
| mysql.sys | localhost | *466D1973D4FA6C14FF90DF20AC7AF3FC6C51AA09 |
+-----------+-----------+-------------------------------------------+


####mysql bash scrip 含特殊字符END #####


Windows Mysql配置
# General and Slow logging.
log-output=FILE
general-log=1
general_log_file="your-app-WEB1.log"
slow-query-log=1
slow_query_log_file="your-app-WEB1-slow.log"
long_query_time=10


# Binary Logging.
log-bin="mysql-bin.log" #binlog，可以使用flush log截断。


# Error Logging.
log-error="your-app-WEB1.err"


# Server Id.
server-id=1


# The maximum amount of concurrent sessions the MySQL server will
# allow. One of these connections will be reserved for a user with
# SUPER privileges to allow the administrator to login even if the
# connection limit has been reached.
max_connections=151


性能测试sysbench
sysbench --test=fileio --file-total-size=15G prepare
sysbench --test=fileio --file-total-size=15G --file-test-mode=rndrw --init-rng=on --max-time=300 --max-requests=0 run


time sysbench --test=oltp --oltp-table-size=1000000 --db-driver=mysql --mysql-db=test --mysql-user=root prepare
time sysbench --test=oltp --oltp-table-size=1000000 --mysql-db=test --mysql-user=root/ --max-time=60 --oltp-read-only=on --max-requests=0 --num-threads=8 --db-driver=mysql  run


查询系统页大小
getconf PAGE_SIZE


查询表空间占用大小
mysql> use information_schema
mysql> select TABLE_SCHEMA,TABLE_NAME,INDEX_LENGTH as index_M,DATA_LENGTH as data_M from TABLES order by (INDEX_LENGTH+DATA_LENGTH) desc limit 10;


[mysql 5.5 锁]
Using the INFORMATION_SCHEMA Tables
Using SHOW INNODB STATUS to look at locks is definitely old-school, now that InnoDB
has INFORMATION_SCHEMA tables that expose its transactions and locks.
If you don’t see the tables, you are not using a new enough version of InnoDB. You
need at least MySQL 5.1 and the InnoDB plugin. If you’re using MySQL 5.1 and you
don’t see the INNODB_LOCKS table, check SHOW VARIABLES for the innodb_version variable.
If you don’t see the variable, you’re not using the InnoDB plugin, and you should be!
If you see the variable but you don’t have the tables, you need to ensure that the
plugin_load setting in the server configuration file includes the tables explicitly. Check
the MySQL manual for details.
Fortunately, in MySQL 5.5 you don’t need to worry about all of this; the modern version
of InnoDB is built right into the server.
The MySQL and InnoDB manuals have sample queries you can use against these tables,
which we won’t repeat here, but we’ll add a couple of our own. For example, here is a
query that shows who’s blocking and who’s waiting, and for how long:
SELECT r.trx_id AS waiting_trx_id, r.trx_mysql_thread_id AS waiting_thread,
TIMESTAMPDIFF(SECOND, r.trx_wait_started, CURRENT_TIMESTAMP) AS wait_time,
r.trx_query AS waiting_query,
l.lock_table AS waiting_table_lock,
b.trx_id AS blocking_trx_id, b.trx_mysql_thread_id AS blocking_thread,
SUBSTRING(p.host, 1, INSTR(p.host, ':') - 1) AS blocking_host,
SUBSTRING(p.host, INSTR(p.host, ':') +1) AS blocking_port,
IF(p.command = "Sleep", p.time, 0) AS idle_in_trx,
b.trx_query AS blocking_query
FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS AS w
INNER JOIN INFORMATION_SCHEMA.INNODB_TRX AS b ON b.trx_id = w.blocking_trx_id
INNER JOIN INFORMATION_SCHEMA.INNODB_TRX AS r ON r.trx_id = w.requesting_trx_id
INNER JOIN INFORMATION_SCHEMA.INNODB_LOCKS AS l ON w.requested_lock_id = l.lock_id
LEFT JOIN INFORMATION_SCHEMA.PROCESSLIST AS p ON p.id
= b.trx_mysql_thread_id
ORDER BY wait_time DESC\G
*************************** 1. row ***************************
waiting_trx_id: 5D03
waiting_thread: 3
wait_time: 6
waiting_query: select * from store limit 1 for update
waiting_table_lock: `sakila`.`store`
blocking_trx_id: 5D02
blocking_thread: 2
blocking_host: localhost
blocking_port: 40298
idle_in_trx: 8
blocking_query: NULL
The result shows that thread 3 has been waiting for 6 seconds to lock a row in the
store table. It is blocked on thread 2, which has been idle for 8 seconds.
If you’re suffering from a lot of locking due to threads that are idle in a transaction, the
following variation can show you how many queries are blocked on which threads,
without all the verbosity:
SELECT CONCAT('thread ', b.trx_mysql_thread_id, ' from ', p.host) AS who_blocks,
IF(p.command = "Sleep", p.time, 0) AS idle_in_trx,
MAX(TIMESTAMPDIFF(SECOND, r.trx_wait_started, NOW())) AS max_wait_time,
COUNT(*) AS num_waiters
FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS AS w
INNER JOIN INFORMATION_SCHEMA.INNODB_TRX AS b ON b.trx_id = w.blocking_trx_id
INNER JOIN INFORMATION_SCHEMA.INNODB_TRX AS r ON r.trx_id = w.requesting_trx_id
LEFT JOIN INFORMATION_SCHEMA.PROCESSLIST AS p ON p.id
= b.trx_mysql_thread_id
GROUP BY who_blocks ORDER BY num_waiters DESC\G
*************************** 1. row ***************************
who_blocks:
thread 2 from localhost:40298
idle_in_trx:
1016
max_wait_time:
37
num_waiters:
8
The result shows that thread 2 has now been idle for a much longer time, and at least
one thread has been waiting for up to 37 seconds for it to release its locks. There are
eight threads waiting for thread 2 to finish its work and commit.
We’ve found that idle-in-transaction locking is a common cause of emergency prob-
lems, and is sometimes difficult for people to diagnose. The pt-kill tool from Percona
Toolkit can be configured to kill long-running idle transactions to prevent this situation.
Percona Server itself also supports an idle transaction timeout parameter to accomplish
the same thing.


#查出processlist对应的DML语句
select * from INFORMATION_SCHEMA.PROCESSLIST where db = 'somedb';
| 5 | ssss| localhost:41060 | somedb| Sleep | 3 | | NULL | | 58169 | root |
localhost | somedb| Query | 0
| executing | select * from sometable where tblColumnName = 'someName'


创建range分区
create table orders1(id int not null)
engine = myisam，charset=utf8
partition by range(id) #写表选项的后边
(partition p0 values less than (100),
partition p1 values less than (200),
partition p2 values less than (300));


创建list分区
create table order4 (id int)
partition by list(id)
(partition la values in (1,3,5,7,9),
partition lb values in (2,4,6,8,10));


concat连接
select concat(user,'@',host) as 用户名,password as 密码 from user;
+--------------------+-------------------------------------------+
| 用户名 | 密码 |
+--------------------+-------------------------------------------+
| root@localhost | *F2AF67418B29。。。 |
| repl@localhost | *E74858DB86。。。 |
| user1@192.168.1.7 | *F2AF67418。。。 |
| backup@localhost | *F2AF6741 。。。|


替换函数（replace）


UPDATE [tablename]
SET [fieldname] = REPLACE([fieldname], 'text to find', 'text to replace with')
WHERE [fieldname] LIKE '%text to find%'


mysql> select user ,host,password from user where user='replspace';
+-----------+-------------+-------------------------------------------+
| user | host | password |
+-----------+-------------+-------------------------------------------+
| replspace | localhost | *E74858DB8
| replspace | 192.168.1.% | *F2AF6741
+-----------+-------------+-------------------------------------------+
2 rows in set (0.00 sec)


mysql> update user set user =replace(user,'replspace','repl');


mysql> select user ,host,password from user where user='repl';
+------+-------------+-------------------------------------------+
| user | host | password |
+------+-------------+-------------------------------------------+
| repl | localhost | *E74858DB
| repl | 192.168.1.% | *F2AF674
+------+-------------+-------------------------------------------+
2 rows in set (0.00 sec)


function/trigger/cursor程序结构
if condition then          case varname
                                          when varvalue1 then
          actions;                         actions;
                                           when varvalue2 then
                                                actions；
end if                             end case
------------------------------------------------------------------
label： loop #函数  while condition         repeat
     actions;                    actions;                    actions;
iterate label            end while                  until condition
                                                                 end repeat;


持有写锁自己可以写，但是别的不可以写
mysql> lock tables student write;
Query OK, 0 rows affected (0.00 sec)


mysql> insert into student values(5,'tang','F');
Query OK, 1 row affected (0.00 sec)


mysql> select * from student;
+------+------+--------+
| id | name | gender |
+------+------+--------+
| 1 | zhao | M |
| 2 | YANG | F |
| 3 | XIE | |
| 4 | wang | M |
| 5 | tang | F |
+------+------+--------+
5 rows in set (0.00 sec)


持有读锁自己都不可以写
mysql> lock tables student read;
Query OK, 0 rows affected (0.00 sec)


mysql> select * from student;
+------+------+--------+
| id | name | gender |
+------+------+--------+
| 1 | zhao | M |
| 2 | YANG | F |
| 3 | XIE | |
+------+------+--------+
3 rows in set (0.05 sec)


mysql> insert into student values(4,'wang','M');
ERROR 1099 (HY000): Table 'student' was locked with a READ lock and can't be updated


解锁 mysql> unlock tables; #不需要表名字


备份 # mysqldump -uroot -pyour-password -h 192.168.1.104 Sales goods orders >./Sales.sql


恢复  $> mysql -uroot -pyour-password -h192.168.1.104 Sales < ./Sales.sql
注意，没有能够恢复单张表


隔离级别


[Sales]> show variables like '%iso%';
+---------------+-----------------+
| Variable_name | Value |
+---------------+-----------------+
| tx_isolation | REPEATABLE-READ |
+---------------+-----------------+


[Sales]> SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE;
Query OK, 0 rows affected (0.00 sec)


[Sales]> SHOW VARIABLES LIKE "%ISO%" ;


+---------------+--------------+
| Variable_name | Value |
+---------------+--------------+
| tx_isolation | SERIALIZABLE |
+---------------+--------------+


事务提交


[Sales]> SET AUTOCOMMIT =OFF;
[Sales]> START TRANSACTION;
[Sales]> UPDATE goods SET COUNT=21 WHERE GID=100;
[Sales]> commit;
Query OK, 0 rows affected (0.10 sec)


触发器
update good set num=num-new.much where gid=new.gid;(new代表新加的行，much代表数量的列;)


/×update good set num=num+old.much where gid=old.gid 删除语句×/


/*update good set num = num +old.much-new.much where gid=old.gid 更新操作 */


character_set_client: utf8
collation_connection: utf8_general_ci
Database Collation: utf8_general_ci


delimiter $
CREATE trigger t1


before insert


on orders


begin


declare rnum smallint;


select count into rnum from goods where gid=new.gid;


if new.amount>rnu. Then set new.amount=rnum;


end if;


update goods set count=count-new.amount where gid=new.gid;


end$


$>创建表DEPT


CREATE TABLE dept( /*部门表*/
deptno MEDIUMINT UNSIGNED NOT NULL DEFAULT 0,
dname VARCHAR(20) NOT NULL DEFAULT "",
loc VARCHAR(13) NOT NULL DEFAULT ""
) ENGINE=MyISAM DEFAULT CHARSET=utf8 ;


$>创建表EMP雇员
CREATE TABLE emp
(empno MEDIUMINT UNSIGNED NOT NULL DEFAULT 0,
ename VARCHAR(20) NOT NULL DEFAULT "",
job VARCHAR(9) NOT NULL DEFAULT "",
mgr MEDIUMINT UNSIGNED NOT NULL DEFAULT 0,
hiredate DATE NOT NULL,
sal DECIMAL(7,2) NOT NULL,
comm DECIMAL(7,2) NOT NULL,
deptno MEDIUMINT UNSIGNED NOT NULL DEFAULT 0
)ENGINE=MyISAM DEFAULT CHARSET=utf8 ;


$>工资级别表
CREATE TABLE salgrade
(
grade MEDIUMINT UNSIGNED NOT NULL DEFAULT 0,
losal DECIMAL(17,2) NOT NULL,
hisal DECIMAL(17,2) NOT NULL
)ENGINE=MyISAM DEFAULT CHARSET=utf8;


INSERT INTO salgrade VALUES (1,700,1200);
INSERT INTO salgrade VALUES (2,1201,1400);


$> 随机产生字符串
$>定义一个新的命令结束符合
delimiter $$
$>删除自定的函数
drop function rand_string $$


$>这里我创建了一个函数.


create function rand_string(n INT)
returns varchar(255)
begin
declare chars_str varchar(100) default
'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ';
declare return_str varchar(255) default '';
declare i int default 0;
while i < n do
set return_str =concat(return_str,substring(chars_str,floor(1+rand()*52),1));
set i = i + 1;
end while;
return return_str;
end $$


delimiter ;
select rand_string(6);


$> 随机产生部门编号
delimiter $$
drop function rand_num $$


$>这里我们又自定了一个函数
create function rand_num( )
returns int(5)
begin
declare i int default 0;
set i = floor(10+rand()*500);
return i;
end $$


delimiter ;
select rand_num();


$>******************************************
$>向emp表中插入记录(海量的数据)


delimiter $$
drop procedure insert_emp $$


create procedure insert_emp(in start int(10),in max_num int(10))
begin
declare i int default 0;
set autocommit = 0;
repeat
set i = i + 1;
insert into emp values ((start+i) ,rand_string(6),'SALESMAN',0001,curdate(),2000,400,rand_num());
until i = max_num
end repeat;
commit;
end $$


delimiter ;
$>调用刚刚写好的函数, 1800000条记录,从100001号开始
call insert_emp(100001,1800000);


$>**************************************************************
$> 向dept表中插入记录


delimiter $$
drop procedure insert_dept $$


create procedure insert_dept(in start int(10),in max_num int(10))
begin
declare i int default 0;
set autocommit = 0;
repeat
set i = i + 1;
insert into dept values ((start+i) ,rand_string(10),rand_string(8));
until i = max_num
end repeat;
commit;
end $$


delimiter ;
call insert_dept(100,10);


$>------------------------------------------------
$>向salgrade 表插入数据
delimiter $$
drop procedure insert_salgrade $$
create procedure insert_salgrade(in start int(10),in max_num int(10))
begin
declare i int default 0;
set autocommit = 0;
ALTER TABLE emp DISABLE KEYS;
repeat
set i = i + 1;
insert into salgrade values ((start+i) ,(start+i),(start+i));
until i = max_num
end repeat;
commit;
end $$
delimiter ;
$>测试不需要了
$>call insert_salgrade(10000,1000000);


游标设计


create procedure p3()


declare rcount int;
declare Cgid int;
declare Ccount int;
declare Cname varchar(10);
declare GetGoodsCursor cursor for select gid,count,name from goods;


open GetGoodsCursor;


select count(*) into rcount from goods;


while(rcount>0) do
fetch GetGoodsCursor into Cgid,Ccount,Cname;
select Cname,Ccount;
set rcount := rcount-1;
end while;


close GetGoodsCursor;


[Sales]> call p3()$
+-------+--------+
| Cname | Ccount |
+-------+--------+
| pc | 0 |
+-------+--------+


+-------+--------+
| Cname | Ccount |
+-------+--------+
| nb | 19 |
+-------+--------+


Query OK, 0 rows affected (0.00 sec)


以下的和上面的结果一样，注意是使用的标志位来处理。
create procedure p4()


declare rcount int;
declare Cgid int;
declare Cname varchar(10);
declare flag tinyint default 1;
declare Ccount int;
declare GetGoodsCursor cursor for select gid,count,name from goods;
declare continue handler for NOT FOUND set flag :=0;


open GetGoodsCursor;
fetch GetGoodsCursor into Cgid,Ccount,Cname;


while(flag) do
select Cname,Ccount;
fetch GetGoodsCursor into Cgid,Ccount,Cname;
end while;
close GetGoodsCursor;


修改密码，注意PASSWORD（“NEWPASSWORD”）是函数
UPDATE USER SET PASSWORD = PASSWORD('NEWPASSWORD') WHERE USER='WHO';
FLUSH PRIVILEGES;


授权


grant SomePrivileges on Database.Table to 'somebody'@'someHost' identified by 'Somebody's password';
flush privileges;


如何破解数据库的密码:


1:通过任务管理器或者服务管理,关掉mysqld(服务进程)


2:通过命令行+特殊参数开启mysqld


mysqld --skip-grant-tables --skip-networking


3:此时,mysqld服务进程已经打开,并且,不需要权限检查.


4:mysql -uroot 无密码登陆服务器.


5: 修改权限表


A: use mysql;


B:update user set Password = password('11111') where User = 'root';


C:flush privileges;


show status like 'uptime'; /×系统运行时间
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Uptime | 5710 |
+---------------+-------+


[(none)]> show status like 'com_select'; /×select执行次数
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Com_select | 1 |
+---------------+-------+
[(none)]> show status like 'com_update'; /×update执行次数
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Com_update | 0 |
+---------------+-------+


show variables like 'long_query_time' /×查看慢查询时间的定义
-> ;
+-----------------+-----------+
| Variable_name | Value |
+-----------------+-----------+
| long_query_time | 10.000000 |
+-----------------+-----------+


set long_query_time = 1; /×设置慢查询时间


1, 查看MySQL服务器配置信息
Java代码 收藏代码
mysql> show variables;


2, 查看MySQL服务器运行的各种状态值
Java代码 收藏代码
mysql> show global status;


3, 慢查询
Java代码 收藏代码
mysql> show variables like '%slow%';
+------------------+-------+
| Variable_name | Value |
+------------------+-------+
| log_slow_queries | OFF |
| slow_launch_time | 2 |
+------------------+-------+
mysql> show global status like '%slow%';
+---------------------+-------+
| Variable_name | Value |
+---------------------+-------+
| Slow_launch_threads | 0 |
| Slow_queries | 279 |
+---------------------+-------+


配置中关闭了记录慢查询（最好是打开，方便优化），超过2秒即为慢查询，一共有279条慢查询


4, 连接数


Java代码 收藏代码
mysql> show variables like 'max_connections';
+-----------------+-------+
| Variable_name | Value |
+-----------------+-------+
| max_connections | 500 |
+-----------------+-------+


mysql> show global status like 'max_used_connections';
+----------------------+-------+
| Variable_name | Value |
+----------------------+-------+
| Max_used_connections | 498 |
+----------------------+-------+


设置的最大连接数是500，而响应的连接数是498


max_used_connections / max_connections * 100% = 99.6% （理想值 ≈ 85%）


5, key_buffer_size
key_buffer_size是对MyISAM表性能影响最大的一个参数, 不过数据库中多为Innodb


Java代码 收藏代码
mysql> show variables like 'key_buffer_size';
+-----------------+----------+
| Variable_name | Value |
+-----------------+----------+
| key_buffer_size | 67108864 |
+-----------------+----------+


mysql> show global status like 'key_read%';
+-------------------+----------+
| Variable_name | Value |
+-------------------+----------+
| Key_read_requests | 25629497 |
| Key_reads | 66071 |
+-------------------+----------+


一共有25629497个索引读取请求，有66071个请求在内存中没有找到直接从硬盘读取索引，计算索引未命中缓存的概率：
key_cache_miss_rate ＝ Key_reads / Key_read_requests * 100% =0.27%
需要适当加大key_buffer_size


Java代码 收藏代码
mysql> show global status like 'key_blocks_u%';
+-------------------+-------+
| Variable_name | Value |
+-------------------+-------+
| Key_blocks_unused | 10285 |
| Key_blocks_used | 47705 |
+-------------------+-------+


Key_blocks_unused表示未使用的缓存簇(blocks)数，Key_blocks_used表示曾经用到的最大的blocks数
Key_blocks_used / (Key_blocks_unused + Key_blocks_used) * 100% ≈ 18% （理想值 ≈ 80%）


6， 临时表


Java代码 收藏代码
mysql> show global status like 'created_tmp%';
+-------------------------+---------+
| Variable_name | Value |
+-------------------------+---------+
| Created_tmp_disk_tables | 4184337 |
| Created_tmp_files | 4124 |
| Created_tmp_tables | 4215028 |
+-------------------------+---------+


每次创建临时表，Created_tmp_tables增加，如果是在磁盘上创建临时表，Created_tmp_disk_tables也增加,Created_tmp_files表示MySQL服务创建的临时文件文件数：
Created_tmp_disk_tables / Created_tmp_tables * 100% ＝ 99% （理想值<= 25%）


Java代码 收藏代码
mysql> show variables where Variable_name in ('tmp_table_size', 'max_heap_table_size');
+---------------------+-----------+
| Variable_name | Value |
+---------------------+-----------+
| max_heap_table_size | 134217728 |
| tmp_table_size | 134217728 |
+---------------------+-----------+


需要增加tmp_table_size


7,open table 的情况
Java代码 收藏代码
mysql> show global status like 'open%tables%';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Open_tables | 1024 |
| Opened_tables | 1465 |
+---------------+-------+


Open_tables 表示打开表的数量，Opened_tables表示打开过的表数量，如果Opened_tables数量过大，说明配置中 table_cache(5.1.3之后这个值叫做table_open_cache)值可能太小，我们查询一下服务器table_cache值
Java代码 收藏代码
mysql> show variables like 'table_cache';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| table_cache | 1024 |
+---------------+-------+


Open_tables / Opened_tables * 100% =69% 理想值 （>= 85%）
Open_tables / table_cache * 100% = 100% 理想值 (<= 95%)


8, 进程使用情况
Java代码 收藏代码
mysql> show global status like 'Thread%';
+-------------------+-------+
| Variable_name | Value |
+-------------------+-------+
| Threads_cached | 31 |
| Threads_connected | 239 |
| Threads_created | 2914 |
| Threads_running | 4 |
+-------------------+-------+


如果我们在MySQL服务器配置文件中设置了thread_cache_size，当客户端断开之后，服务器处理此客户的线程将会缓存起来以响应 下一个客户而不是销毁（前提是缓存数未达上限）。Threads_created表示创建过的线程数，如果发现Threads_created值过大的 话，表明 MySQL服务器一直在创建线程，这也是比较耗资源，可以适当增加配置文件中thread_cache_size值，查询服务器 thread_cache_size配置：
Java代码 收藏代码
mysql> show variables like 'thread_cache_size';
+-------------------+-------+
| Variable_name | Value |
+-------------------+-------+
| thread_cache_size | 32 |
+-------------------+-------+


9, 查询缓存(query cache)
Java代码 收藏代码
mysql> show global status like 'qcache%';
+-------------------------+----------+
| Variable_name | Value |
+-------------------------+----------+
| Qcache_free_blocks | 2226 |
| Qcache_free_memory | 10794944 |
| Qcache_hits | 5385458 |
| Qcache_inserts | 1806301 |
| Qcache_lowmem_prunes | 433101 |
| Qcache_not_cached | 4429464 |
| Qcache_queries_in_cache | 7168 |
| Qcache_total_blocks | 16820 |
+-------------------------+----------+


Qcache_free_blocks：缓存中相邻内存块的个数。数目大说明可能有碎片。FLUSH QUERY CACHE会对缓存中的碎片进行整理，从而得到一个空闲块。
Qcache_free_memory：缓存中的空闲内存。
Qcache_hits：每次查询在缓存中命中时就增大
Qcache_inserts：每次插入一个查询时就增大。命中次数除以插入次数就是不中比率。
Qcache_lowmem_prunes：缓存出现内存不足并且必须要进行清理以便为更多查询提供空间的次数。这个数字最好长时间来看；如果这 个数字在不断增长，就表示可能碎片非常严重，或者内存很少。（上面的 free_blocks和free_memory可以告诉您属于哪种情况）
Qcache_not_cached：不适合进行缓存的查询的数量，通常是由于这些查询不是 SELECT 语句或者用了now()之类的函数。
Qcache_queries_in_cache：当前缓存的查询（和响应）的数量。
Qcache_total_blocks：缓存中块的数量。


我们再查询一下服务器关于query_cache的配置：
Java代码 收藏代码
mysql> show variables like 'query_cache%';
+------------------------------+----------+
| Variable_name | Value |
+------------------------------+----------+
| query_cache_limit | 33554432 |
| query_cache_min_res_unit | 4096 |
| query_cache_size | 33554432 |
| query_cache_type | ON |
| query_cache_wlock_invalidate | OFF |
+------------------------------+----------+


各字段的解释：


query_cache_limit：超过此大小的查询将不缓存
query_cache_min_res_unit：缓存块的最小大小
query_cache_size：查询缓存大小
query_cache_type：缓存类型，决定缓存什么样的查询，示例中表示不缓存 select sql_no_cache 查询
query_cache_wlock_invalidate：当有其他客户端正在对MyISAM表进行写操作时，如果查询在query cache中，是否返回cache结果还是等写操作完成再读表获取结果。


query_cache_min_res_unit的配置是一柄”双刃剑”，默认是4KB，设置值大对大数据查询有好处，但如果你的查询都是小数据查询，就容易造成内存碎片和浪费。


查询缓存碎片率 = Qcache_free_blocks / Qcache_total_blocks * 100%


如果查询缓存碎片率超过20%，可以用FLUSH QUERY CACHE整理缓存碎片，或者试试减小query_cache_min_res_unit，如果你的查询都是小数据量的话。


查询缓存利用率 = (query_cache_size – Qcache_free_memory) / query_cache_size * 100%


查询缓存利用率在25%以下的话说明query_cache_size设置的过大，可适当减小；查询缓存利用率在80％以上而且Qcache_lowmem_prunes > 50的话说明query_cache_size可能有点小，要不就是碎片太多。


查询缓存命中率 = (Qcache_hits – Qcache_inserts) / Qcache_hits * 100%


示例服务器 查询缓存碎片率 ＝ 20.46％，查询缓存利用率 ＝ 62.26％，查询缓存命中率 ＝ 1.94％，命中率很差，可能写操作比较频繁吧，而且可能有些碎片。


10,排序使用情况


Java代码 收藏代码
mysql> show global status like 'sort%';
+-------------------+----------+
| Variable_name | Value |
+-------------------+----------+
| Sort_merge_passes | 2136 |
| Sort_range | 81888 |
| Sort_rows | 35918141 |
| Sort_scan | 55269 |
+-------------------+----------+


Sort_merge_passes 包括两步。MySQL 首先会尝试在内存中做排序，使用的内存大小由系统变量 Sort_buffer_size 决定，如果它的大小不够把所有的记录都读到内存中，MySQL 就会把每次在内存中排序的结果存到临时文件中，等 MySQL 找到所有记录之后，再把临时文件中的记录做一次排序。这再次排序就会增加 Sort_merge_passes。实际上，MySQL 会用另一个临时文件来存再次排序的结果，所以通常会看到 Sort_merge_passes 增加的数值是建临时文件数的两倍。因为用到了临时文件，所以速度可能会比较慢，增加 Sort_buffer_size 会减少 Sort_merge_passes 和 创建临时文件的次数。但盲目的增加 Sort_buffer_size 并不一定能提高速度，见 How fast can you sort data with MySQL?（引自http://qroom.blogspot.com/2007/09/mysql-select-sort.html）


另外，增加read_rnd_buffer_size(3.2.3是record_rnd_buffer_size)的值对排序的操作也有一点的 好处，参见：http://www.mysqlperformanceblog.com/2007/07/24/what-exactly-is- read_rnd_buffer_size/


11.文件打开数(open_files)


Java代码 收藏代码
mysql> show global status like 'open_files';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Open_files | 821 |
+---------------+-------+


mysql> show variables like 'open_files_limit';
+------------------+-------+
| Variable_name | Value |
+------------------+-------+
| open_files_limit | 65535 |
+------------------+-------+


比较合适的设置：Open_files / open_files_limit * 100% <= 75％


正常


12。 表锁情况
Java代码 收藏代码
mysql> show global status like 'table_locks%';
+-----------------------+---------+
| Variable_name | Value |
+-----------------------+---------+
| Table_locks_immediate | 4257944 |
| Table_locks_waited | 25182 |
+-----------------------+---------+


Table_locks_immediate 表示立即释放表锁数，Table_locks_waited表示需要等待的表锁数，如果 Table_locks_immediate / Table_locks_waited > 5000，最好采用InnoDB引擎，因为InnoDB是行锁而MyISAM是表锁，对于高并发写入的应用InnoDB效果会好些.


13. 表扫描情况
Java代码 收藏代码
mysql> show global status like 'handler_read%';
+-----------------------+-----------+
| Variable_name | Value |
+-----------------------+-----------+
| Handler_read_first | 108763 |
| Handler_read_key | 92813521 |
| Handler_read_next | 486650793 |
| Handler_read_prev | 688726 |
| Handler_read_rnd | 9321362 |
| Handler_read_rnd_next | 153086384 |
+-----------------------+-----------+


各字段解释参见http://hi.baidu.com/thinkinginlamp/blog/item/31690cd7c4bc5cdaa144df9c.html，调出服务器完成的查询请求次数：
Java代码 收藏代码
mysql> show global status like 'com_select';
+---------------+---------+
| Variable_name | Value |
+---------------+---------+
| Com_select | 2693147 |
+---------------+---------+


计算表扫描率：


表扫描率 ＝ Handler_read_rnd_next / Com_select


如果表扫描率超过4000，说明进行了太多表扫描，很有可能索引没有建好，增加read_buffer_size值会有一些好处，但最好不要超过8MB。


[mysql]> delimiter $ /*修改界定符号为$
[mysql]> select id from scores where id = 100001$
+--------+
| id |
+--------+
| 100001 |
| 100001 |
+--------+

[mysql]> drop index idx_name on some_table;                    
[mysql]> create index idx_name on data_table(field1,field2...);

[mysql]> show index from some_table\G; /×显示索引，\G表示使用如下的方式显示结果，很多命令都可以使用


*************************** 1. row ***************************
Table: scores
Non_unique: 1
Key_name: score_id_idx
Seq_in_index: 1
Column_name: id
Collation: A
Cardinality: 249496
Sub_part: NULL
Packed: NULL
Null: YES
Index_type: BTREE
Comment:
Index_comment:


方法一：


select `name` from mysql.proc where db = 'your_db_name' and `type` = 'PROCEDURE' //存储过程
select `name` from mysql.proc where db = 'your_db_name' and `type` = 'FUNCTION' //函数


方法二：


show rocedure status; //存储过程


show function status; //函数


查看存储过程或函数的创建代码


show create procedure proc_name;
show create function func_name;


查看视图


SELECT * from information_schema.VIEWS //视图


SELECT * from information_schema.TABLES //表


查看触发器


方法一：
语法：SHOW TRIGGERS [FROM db_name] [LIKE expr]
实例：SHOW TRIGGERS\G //触发器


方法二：
对INFORMATION_SCHEMA数据库中的TRIGGERS表查询
mysql>SELECT * FROM triggers T WHERE trigger_name=”mytrigger” \G


分页：


select * from tab limit 起始行，共几行


常用函数：


与oracle的比较


CHARSET(str) //返回字串字符集
CONCAT (string2 [,... ]) //连接字串
INSTR (string ,substring ) //返回substring首次在string中出现的位置,不存在返回0 同oracle
LCASE (string2 ) //转换成小写
LEFT (string2 ,length ) //从string2中的左边起取length个字符
LENGTH (string ) //string长度
LOAD_FILE (file_name ) //从文件读取内容
LOCATE (substring , string [,start_position ] ) 同INSTR,但可指定开始位置
LPAD (string2 ,length ,pad ) //重复用pad加在string开头,直到字串长度为length
LTRIM (string2 ) //去除前端空格
REPEAT (string2 ,count ) //重复count次
REPLACE (str ,search_str ,replace_str ) //在str中用replace_str替换search_str
RPAD (string2 ,length ,pad) //在str后用pad补充,直到长度为length
RTRIM (string2 ) //去除后端空格
STRCMP (string1 ,string2 ) //逐字符比较两字串大小,
SUBSTRING (str , position [,length ]) //从str的position开始,取length个字符, 同oracle
TRIM([[BOTH|LEADING|TRAILING] [padding] FROM]string2) //去除指定位置的指定字符
UCASE (string2 ) //转换成大写
RIGHT(string2,length) //取string2最后length个字符
SPACE(count) //生成count个空格


数学类


ABS (number2 ) //绝对值
BIN (decimal_number ) //十进制转二进制
CEILING (number2 ) //向上取整
CONV(number2,from_base,to_base) //进制转换
FLOOR (number2 ) //向下取整
FORMAT (number,decimal_places ) //保留小数位数
HEX (DecimalNumber ) //转十六进制
LEAST (number , number2 [,..]) //求最小值
MOD (numerator ,denominator ) //求余
POWER (number ,power ) //求指数
RAND([seed]) //随机数
ROUND (number [,decimals ]) //四舍五入,decimals为小数位数]
SIGN (number2 ) //返回符号,正负或0
SQRT(number2) //开平方


日期时间类


ADDTIME (date2 ,time_interval ) //将time_interval加到date2
CONVERT_TZ (datetime2 ,fromTZ ,toTZ ) //转换时区
CURRENT_DATE ( ) //当前日期
CURRENT_TIME ( ) //当前时间
CURRENT_TIMESTAMP ( ) //当前时间戳
DATE (datetime ) //返回datetime的日期部分
DATE_ADD (date2 , INTERVAL d_value d_type ) //在date2中加上日期或时间
DATE_FORMAT (datetime ,FormatCodes ) //使用formatcodes格式显示datetime
DATE_SUB (date2 , INTERVAL d_value d_type ) //在date2上减去一个时间
DATEDIFF (date1 ,date2 ) //两个日期差
DAY (date ) //返回日期的天
DAYNAME (date ) //英文星期
DAYOFWEEK (date ) //星期(1-7) ,1为星期天
DAYOFYEAR (date ) //一年中的第几天
EXTRACT (interval_name FROM date ) //从date中提取日期的指定部分
MAKEDATE (year ,day ) //给出年及年中的第几天,生成日期串
MAKETIME (hour ,minute ,second ) //生成时间串
MONTHNAME (date ) //英文月份名
NOW ( ) //当前时间
SEC_TO_TIME (seconds ) //秒数转成时间
STR_TO_DATE (string ,format ) //字串转成时间,以format格式显示 oracle:to_date
TIMEDIFF (datetime1 ,datetime2 ) //两个时间差
TIME_TO_SEC (time ) //时间转秒数
WEEK (date_time [,start_of_week ]) //第几周
YEAR (datetime ) //年份
DAYOFMONTH(datetime) //月的第几天
HOUR(datetime) //小时
LAST_DAY(date) //date的月的最后日期
MICROSECOND(datetime) //微秒
MONTH(datetime) //月
MINUTE(datetime) //分


附:可用在INTERVAL中的类型
DAY ,DAY_HOUR ,DAY_MINUTE ,DAY_SECOND ,HOUR ,HOUR_MINUTE ,HOUR_SECOND ,MINUTE ,MINUTE_SECOND,MONTH ,SECOND ,YEAR


12: 解决字符集问题:
默认建表一般用utf8, 而我们在windows下窗口是GBK的,
因此,需要声明字符集.
Set names gbk;


连接的两种方法：
select fd1,fd2 from tb1 as p inner/left/right join tb2 as q on p.fdx=q.fdx
select fd1,fd2 from tb1 as p exists(select fd3 from tb2 as q where p.fdx=q.fdx)
增: insert
Insert 3问:
1: 插入哪张表?
2: 插入哪几列?
3: 这几列分别插入什么值?


Insert into TableName
(列1,列2.... 列n)
Values
(值1,值2,....值n)


值 与 列,按顺序,一一对应


特殊: insert语句 允不允许不写列名
答: 允许.
如果没有声明列明,则默认插入所有列.
因此,值应该与全部列,按顺序一一对应.


Delete from 表名 where expr


Update 表名
Set
列1 = 新值 1,
列2 = 新值2,
列n = 新值n.....
Where expr


Select 列1, 列2, 列3,...列n
From 表名
Where expr;


区别: decimal比float精度更高, 适合存储货币等要求精确的数字


注意: char(M),varchar(M)限制的是字符,不是字节.
即 char(2) charset utf8, 能存2个utf8字符. 比如'中国'char与varchar型的选择原则:
1:空间利用效率, 四字成语表, char(4),
个人简介,微博140字, varchar(140)
2:速度
用户名: char


日期时间类型
Year 年(1字节) 95/1995, [1901-2155],
在insert时,可以简写年的后2位,但是不推荐这样.
[00-69] +2000
[70-99] + 1900,
即: 填2位,表示 1970 - 2069


Date 日期 1998-12-31
范围: 1000/01/01 ,9999/12/31


Time 时间 13:56:23
范围: -838:59:59 -->838:59:59


datetime 时期时间 1998-12-31 13:56:23
范围: 1000/01//01 00:00:00 ---> 9999:12:31 23:59:59


时间戳:
是1970-01-01 00:00:00 到当前的秒数.
一般存注册时间,商品发布时间等,并不是用datetime存储,而是用时间戳.
因为datetime虽然直观,但计算不便.


3:在查询时使用了函数,最大的一个坏处,
以 date_format(A)为例
则A列的索引将无法使用.


如果你针对某列作操作,而此次查询,又使用的此列的索引.
此时,速度将显著变慢.


例:
sname, email 两列
email加了索引


Select name,email from table where right(email,6)='qq.com';
将会导致此次查询中, email的索引并不会产生效果.


Create view 视图名 as select 语句;
而temptable是根据创建语句瞬间创建一张临时表,
然后查询视图的语句从该临时表查数据.
create algorethm=temptable view g2 as select goods_id,cat_id,goods_name,shop_price from goods where shop_price > 2000
查询视图的语句:
select * from g2 where shop_price < 3000;


1:告诉服务器,我给你发送的数据是什么编码的? character_set_client
2:告诉转换器,转换成什么编码? Character_set_connection
3:查询的结果用什么编码? Character_set_results


如果以上3者都为字符集N, 则可以简写为 set names N


推论: 什么时将会乱码?
1: client声明与事实不符
2:results与客户端页面不符的时候.


什么时间将会丢失数据?
Connetion和服务器的字符集比client小时.


常用的表的引擎
Myisam ,批量插入速度快, 不支持事务,锁表,所有的索引指向物理行位置，无分裂页面的劣势
Innodb, 批量插入相对较慢,支持事务,锁行.主索引是Cluster索引，其他索引指向主索引，有分裂页面的劣势


全文索引:目前5.5版本,myisam,innodb都已经支持


触发器:
能监视: 增,删,改
四要素:
监视地点
监视事件
触发时间
触发事件


创建触发器的语法
Create trigger triggerName
After/before insert/update/delete on 表名
For each row #这句话是固定的
Begin
Sql语句; # 一句或多句,insert/update/delete范围内
End;
如何在触发器引用行的值
对于insert而言, 新增的行 用new 来表示,
行中的每一列的值 ,用new.列名来表示.


对于 delete来说, 原本有一行,后来被删除,
想引用被删除的这一行,用old,来表示, old.列名,就可以引用被删行中的值.


对于update来说,
被修改的行,
修改前的数据 ,用 old来表示, old.列名引用被修改之前行中的值
修改后的数据,用new 来表示, new.列名引用被修改之后行中的值
触发器里after 和before的区别
After 是先完成数据的增,删,改再触发,
触发的语句晚于监视的增,删,改,无法影响前面的增删改动作.


Before是先完成触发,再增删改,
触发的语句先于监视的增,删,改发生,我们有机会判断,修改即将发生的操作.


备份的工具
Mysqldump可以导出
库
表
cl
例1: 导出mugua库下面的表
Mysqldump -u用户名 -p密码 库名 表1 表2 表3 > 地址/备份文件名称
导出的是建表语句及insert语句


例2:如何导出一个库下面的所有表?
Mysqldump -u用户名 -p密码 库名 > 地址/备份文件名称


例3: 如何导出以库为单位导出?
Mysqldump -u用户名 -p密码 -B 库1 库2 库3 > 地址/备份文件名称


例4: 如何导出所有库?
Mysqldump -u用户名 -p密码 -A > 地址/备份文件名称


恢复:
1:登陆到mysql命令行
对于库级的备份文件
Mysql> source 备份文件地址


对于表级的备份文件
Mysql > use 库名
Mysql> source 备份文件地址


2:不登陆到mysql命令行
针对库级的备份文件
Mysql -u用户名 -p密码 < 库级备份文件地址


针对表级的备份文件
Mysql -u用户名 -p密码 库名 < 表级备份文件地址


Alter table 表名 add index /unique/fulltext [索引名] (列名)
Alter table 表名 add primary key (列名) // 不要加索引名,因为主键只有一个


删除索引
删除非主键索引:Alter table 表名 drop index 索引名;
删除主键: alter table 表名 drop primary key


关于全文索引的用法
Match (全文索引名) against ('keyword');


关于全文索引的停止词
全文索引不针对非常频繁的词做索引,
如this, is, you, my等等.


全文索引:在mysql的默认情况下, 对于中文意义不大.
因为英文有空格,标点符号来拆成单词,进而对单词进行索引.
而对于中文,没有空格来隔开单词,mysql无法识别每个中文词.


存储过程: procedure
概念类似于函数,就是把一段代码封装起来,
当要执行这一段代码的时候,可以通过调用该存储过程来实现.
在封装的语句体里面,可以用if/else, case,while等控制结构.
可以进行sql编程.


查看现有的存储过程:
Show procedure status


删除存储过程
Drop procedure 存储过程的名字


调用存储过程
Call 存储过程名字(varvalue);


校对集: 指字符集的排序规则
一种字符集可以有一个或多个排序规则.
以Utf8为例, 我们默认使的utf8_general_ci 规则,也可以按二进制来排, utf8_bin


怎么样声明校对集?
Create table ()... Charset utf8 collate utf8_general_ci;


注意:声明的校对集必须是字符集合法的校对集.


查看一张表上所有索引
Show index from 表名


安装


准备环境


1、安装确保以下系统相关库文件


gcc gcc-c++ autoconf automake zlib* libxml* ncurses-devel libmcrypt* libtool*(libtool-ltdl-devel*)


$> yum –y install gcc gcc-c++ autoconf automake zlib* libxml* ncurses-devel libmcrypt* libtool* cmake


2、 建立mysql安装目录及数据存放目录


$> mkdir /usr/local/mysql


$> mkdir -p /data/mysql


3、 创建用户和用户组


$> groupadd mysql


$> useradd -g mysql mysql


4、 赋予数据存放目录权限


$> chown mysql.mysql –R /data/mysql


二、安装MySQL 5.5.35
1、 获取解压mysql-5.5.35.tar.gz
在mysql.com官网或国内镜像下载源码
$> wget http://mirrors.sohu.com/mysql/MySQL-5.5/mysql-5.5.35.tar.gz
$> tar zxvf mysql-5.5.35.tar.gz
$> cd mysql-5.5.35
2、 编译mysql-5.5.35
$> cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql \
-DMYSQL_UNIX_ADDR=/tmp/mysqld.sock \
-DDEFAULT_CHARSET=utf8 \
-DDEFAULT_COLLATION=utf8_general_ci \
-DWITH_EXTRA_CHARSETS:STRING=utf8,gbk \
-DWITH_MYISAM_STORAGE_ENGINE=1 \
-DWITH_INNOBASE_STORAGE_ENGINE=1 \
-DWITH_MEMORY_STORAGE_ENGINE=1 \
-DWITH_READLINE=1 \
-DENABLED_LOCAL_INFILE=1 \
-DMYSQL_DATADIR=/data/mysql \
-DMYSQL_USER=mysql \
-DMYSQL_TCP_PORT=3306
$> make
$> make install
3、 复制配置文件
$> cp support-files/my-medium.cnf /etc/my.cnf
4、 初始化数据库
执行前需赋给scripts/mysql_install_db文件执行权限
$> chmod 755 scripts/mysql_install_db
$> scripts/mysql_install_db --user=mysql --basedir=/usr/local/mysql/ \
--datadir=/data/mysql/
注：basedir：mysql安装路径 datadir：数据库文件储存路径
5、 设置mysqld的开机启动
$> cp support-files/mysql.server /etc/init.d/mysql
$> chmod 755 /etc/init.d/mysql
$> chkconfig mysql on
6、 为MySQL配置环境变量
将mysql的bin目录加到PATH中，有利于以后管理和维护，在/etc/profile中加入myslq/bin，同时增加两个别名方便操作：
$> export PATH=/usr/local/mysql/bin:$PATH
$> alias mysql_start="mysqld_safe &"
$> alias mysql_stop="mysqladmin –u root -p shutdown"
7、 启动mysql服务
$> /etc/init.d/mysql start
启动完成之后用ps -ef |grep mysql 命令查看是否启动
8、 登陆mysql
$>mysql -uroot -p
Show processlist;
这个命令是显示当前所有连接的工作状态.
$>!/bin/bash
while true
do
mysql -uroot -e 'show processlist\G'|grep State:|uniq -c|sort -rn
echo '---'
sleep 1
Done
如果观察到以下状态,则需要注意
converting HEAP to MyISAM 查询结果太大时,把结果放在磁盘 (语句写的不好,取数据太多)
create tmp table 创建临时表(如group时储存中间结果,说明索引建的不好)
Copying to tmp table on disk 把内存临时表复制到磁盘 (索引不好,表字段选的不好)
locked 被其他查询锁住 (一般在使用事务时易发生,互联网应用不常发生)
logging slow query 记录慢查询


mysql 5.5 以后加了一个profile设置,可以观察到具体语句的执行步骤.


0:查看profile是否开启


> Show variables like ‘profiling’


+---------------+-------+


| Variable_name | Value |


| profiling | OFF |


1:> set profiling=on;


| profiling | On |


mysql> show profiles;


+----------+------------+----------------------------------------------------------+


| Query_ID | Duration | Query |


| 1 | 0.00034225 | select cat_id,avg(shop_price) from goods group by cat_id |


1 row in set (0.00 sec)


mysql> show profile for query 1;


+----------------------+----------+


| Status | Duration |


| starting | 0.000058 |


| checking permissions | 0.000008 |


...
...


| cleaning up | 0.000004 |


疑问; 如何定位到有问题的语句?


答:


1: 开启服务器慢查询


2: 了解临时表的使用规则


3: 经验


列选择原则:


1:字段类型优先级 int > date,time > enum,char>varchar > blob


列的特点分析:


整型: 定长,没有国家/地区之分,没有字符集的差异


time定长,运算快,节省空间. 考虑时区,写sql时不方便 where > ‘2005-10-12’;


enum: 能起来约束值的目的, 内部用整型来存储,但与char联查时,内部要经历串与值的转化


Char 定长, 考虑字符集和(排序)校对集


varchar, 不定长 要考虑字符集的转换与排序时的校对集,速度慢.


text/Blob 无法使用内存临时表


explain type性能排序 ALL(全表扫描)<index(索引扫描）<range<ref<eq_ref
通俗的说: all 扫描所有的数据行,相当于data_all index 扫描所有的索引节点,相当于index_all


range: 意思是查询时,能根据索引做范围的扫描


ref 意思是指 通过索引列,可以直接引用到某些数据行


eq_ref 是指,通过索引列,直接引用某1行数据


常见于连接查询中


const, system, null 这3个分别指查询优化到常量级别, 甚至不需要查找时间.


一般按照主键来查询时,易出现const,system


或者直接查询某个表达式,不经过表时, 出现NULL(效率极高）


extra:


index: 是指用到了索引覆盖,效率非常高


using where 是指光靠索引定位不了,还得where判断一下


using temporary 是指用上了临时表, group by 与order by 不同列时,或group by ,order by 别的表的列.


using filesort : 文件排序(文件可能在磁盘,也可能在内存), (?????


select sum(shop_price) from goods group by cat_id(???? 这句话,用到了临时表和文件排序


在ecshop商城表中,查询6号栏目的商品, (注,6号是一个大栏目)


最直观的: mysql> select goods_id,cat_id,goods_name from goods where cat_id in (select


cat_id from ecs_category where parent_id=6);


误区: 给我们的感觉是, 先查到内层的6号栏目的子栏目,如7,8,9,11


然后外层, cat_id in (7,8,9,11)


事实: 如下图, goods表全扫描, 并逐行与category表对照,看parent_id=6是否成立


原因: mysql的查询优化器,针对In型做优化,被改成了exists的执行效果.


当goods表越大时, 查询速度越慢.


改进: 用连接查询来代替子查询


explain select goods_id,g.cat_id,g.goods_name from goods as g


inner join (select cat_id from ecs_category where parent_id=6) as t


using(cat_id) \G


内层 select cat_id from ecs_category where parent_id=6 ; 用到Parent_id索引, 返回4行


+--------+


增量备份


mysql> SHOW BINARY LOGS; 显示二进制日志
mysql> SHOW MASTER STATUS; 显示当前二进制日志及POSITION


还原 shell> mysqlbinlog binlog.000002 binlog.000002 | mysql -u root -p


$> mysqlbinlog binlog.000001 > /tmp/statements.sql
$> mysqlbinlog binlog.000002 >> /tmp/statements.sql
$> mysql -u root -p -e "source /tmp/statements.sql"
###windows source
mysql >source d:\path\to\backup.sql;

$> mysqlbinlog --stop-datetime="2005-04-20 9:59:59" \
/var/log/mysql/bin.123456 | mysql -u root -p


$> mysqlbinlog --start-datetime="2005-04-20 10:01:00" \
/var/log/mysql/bin.123456 | mysql -u root -p


$> mysqlbinlog /var/log/mysql/bin.123456 > /tmp/mysql_restore.sql


$> mysqlbinlog --stop-position=368312 /var/log/mysql/bin.123456 \
| mysql -u root -p


$> mysqlbinlog --start-position=368315 /var/log/mysql/bin.123456 \
| mysql -u root -p


主从 1 开启主从 my.cnf server-id=x logbin=mysql-log(Master)/relay-log=mysql-relay logformat=mixed
2 privileges(master) grant replication salve replication client on smsrc to 'smone'@'smhost' identified by 'pwd';
3 start(salve) change master to master_host='$master',m_user='$user',m_p='pwd',m_log_file='logfile',m_log_pos=nn;
4 relative directive: start/stop/reset slave show master/salve status
Windows Mysql配置
# General and Slow logging.
log-output=FILE
general-log=1
general_log_file="your-app-WEB1.log"
slow-query-log=1
slow_query_log_file="your-app-WEB1-slow.log"
long_query_time=10


如 果我们在MySQL服务器配置文件中设置了thread_cache_size，当客户端断开之后，服务器处理此客户的线程将会缓存起来以响应 下一个客户而不是销毁（前提是缓存数未达上限）。Threads_created表示创建过的线程数，如果发现Threads_created值过大的 话，表明 MySQL服务器一直在创建线程，这也是比较耗资源，可以适当增加配置文件中thread_cache_size值，查询服务器 thread_cache_size配置：
Java代码 收藏代码
mysql> show variables like 'thread_cache_size';
+-------------------+-------+
| Variable_name | Value |
+-------------------+-------+
| thread_cache_size | 32 |
+-------------------+-------+


Qcache_free_blocks：缓存中相邻内存块的个数。数目大说明可能有碎片。FLUSH QUERY CACHE会对缓存中的碎片进行整理，从而得到一个空闲块。
Qcache_free_memory：缓存中的空闲内存。
Qcache_hits：每次查询在缓存中命中时就增大
Qcache_inserts：每次插入一个查询时就增大。命中次数除以插入次数就是不中比率。
Qcache_lowmem_prunes： 缓存出现内存不足并且必须要进行清理以便为更多查询提供空间的次数。这个数字最好长时间来看；如果这 个数字在不断增长，就表示可能碎片非常严重，或者内存很少。（上面的 free_blocks和free_memory可以告诉您属于哪种情况）
Qcache_not_cached：不适合进行缓存的查询的数量，通常是由于这些查询不是 SELECT 语句或者用了now()之类的函数。
Qcache_queries_in_cache：当前缓存的查询（和响应）的数量。
Qcache_total_blocks：缓存中块的数量。


另 外，增加read_rnd_buffer_size(3.2.3是record_rnd_buffer_size)的值对排序的操作也有一点的 好处，参见：http://www.mysqlperformanceblog.com/2007/07/24/what-exactly-is- read_rnd_buffer_size/


主从 1 开启主从 my.cnf server-id=x logbin=mysql-log(Master)/relay-log=mysql-relay logformat=mixed
2 privileges(master) grant replication salve replication client on smsrc to 'smone'@'smhost' identified by 'pwd';
3 start(salve) change master to master_host='$master',m_user='$user',m_p='pwd',m_log_file='logfile',m_log_pos=nn;
4 relative directive: start/stop/reset slave show master/salve status

GUID WITH REPLICATION UUID GTID
change master to
master_host='172.16.0.2',
master_user='repli',
master_password='replicat',
master_auto_position=1;

GRANT  REPLICATION SLAVE ON *.* TO 'repli'@'172.16.0.%' IDENTIFIED  BY 'replicat';


【mysql备份权限】


CREATE USER 'backup-user-name'@'ip-address' IDENTIFIED BY 'bak-password';
GRANT RELOAD ON *.* TO 'backup-user-name'@'ip-address';
GRANT CREATE, INSERT, DROP, UPDATE ON mysql.backup_progress TO 'backup-user-name'@'ip-address';
GRANT CREATE, INSERT, SELECT, DROP, UPDATE ON mysql.backup_history TO 'backup-user-name'@'ip-address';
GRANT REPLICATION CLIENT ON *.* TO 'backup-user-name'@'ip-address';
GRANT SUPER ON *.* TO 'backup-user-name'@'ip-address';
GRANT EVENT ON *.* TO 'backup-user-name'@'ip-address';
GRANT PROCESS ON *.* TO 'backup-user-name'@'ip-address';
GRANT LOCK TABLES, SELECT, CREATE, ALTER ON *.* TO 'backup-user-name'@'ip-address';
GRANT CREATE, INSERT, DROP, UPDATE ON mysql.backup_sbt_history TO 'backup-user-name'@'ip-address';
mysql> grant event on *.* to  'backup-user-name'@'ip-address';
flush privileges;

 backup bash shell //backup every dbs but system dbs,then package with tar and move to lsyncd dir to transfer to other place
#!/bin/bash
export PATH=/usr/local/mysql/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin
optDate=$(date +%Y%m%d-%H%M)
bakPath="/data/backup/"
scriptErrorLog="/var/log/scriptErrorLog"
operationVM=$(hostname)
bakPwd="Bak-pwd"
bakUser="backup-User"
bakHost="127.0.0.1"
lsyncPath="/data/lsyncd"


###0 delete old sql

            rm -f "$bakPath"*.sql                                                                                                                                       

####1 get dbs need backup
if ! dbs=$(mysql -e 'show databases;' -u"$bakUser" -p"$bakPwd" -h"$bakHost" \
            |grep -Ev 'Database|information_schema|performance_schema|sys')

then
            echo "WRONG $0 ON $operationVM" >>$scriptErrorLog
fi

#####2 bakup dbs in seperately files
for db in $dbs;do
      if !  mysqldump -u"$bakUser" -h"$bakHost" -p"$bakPwd" --databases "$db" \
       --set-gtid-purged=OFF --hex-blob --triggers --routines >"$bakPath""$db"-"$optDate".sql
      then
            echo "WRONG $0 ON $operationVM on dump $db" >>$scriptErrorLog
      fi
done

#####3 tar file and transfer to lsync path
if ! tar zcPf "$lsyncPath"/"$operationVM"-"$optDate".tar.gz "$bakPath"*.sql
then 
            echo "WRONG $0 ON $operationVM" >>$scriptErrorLog
fi

######End mysql.memo #######
######Endmemoof mysql.memo #######
######Startmemoof zabbix.memo #######
######Start zabbix.memo #######

###add custom item###
05
$>vim  /usr/local/zabbix/etc/zabbix_agentd.conf
Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/

10 
$> cat /usr/local/zabbix/etc/zabbix_agentd.conf.d/userparameter_custom.conf 
UserParameter=myCPU.cpunumber,/bin/cat /proc/cpuinfo | /bin/grep process | /bin/wc -l
UserParameter=myOS.TCP_ESTABLISHED_COUNT,ss -tlnpa|/bin/grep ESTAB|wc -l
UserParameter=myOS.TCP_LISTEN_COUNT,ss -tlnpa|/bin/grep LISTEN|wc -l
UserParameter=myOS.TCP_TIMEWAIT_COUNT,ss -tlnpa|/bin/grep TIME-WAIT|wc -l


20 
$> service zabbix_agentd restart && ss -tlnp |grep 10050
Restarting zabbix_agentd (via systemctl):                  [  OK  ]
LISTEN     0      128          *:10050                    *:*                   users:(("zabbix......

30 check result 
$>/usr/local/zabbix/sbin/zabbix_agentd -t myOS.TCP_TIMEWAIT_COUNT
myOS.TCP_TIMEWAIT_COUNT                       [t|337]   ####here 337 is the value

40 add item on zabbix web protal
template-->your-select-template-->item-->create item-->name:numbers_of_TCP_TIMEWAIT-->type:zabbix agent-->
key:myOS.TCP_TIMEWAIT_COUNT-->Applications:OS-->UPDATE

50 view item on zabbix web portal
open host of the templates-->open item-->select OS-->check your custom item

60 tips
 PATT set conf need restart zabbix_agentd
 PATT conf dir must clean,have not any other files
###add custom item###

#####get real ip php####
# cat ip.php 
link https://stackoverflow.com/questions/13646690/how-to-get-real-ip-from-visitor

<?PHP

function getUserIP()
{
    $client  = @$_SERVER['HTTP_CLIENT_IP'];
    $forward = @$_SERVER['HTTP_X_FORWARDED_FOR'];
    $remote  = $_SERVER['REMOTE_ADDR'];

    if(filter_var($client, FILTER_VALIDATE_IP))
    {
        $ip = $client;
    }
    elseif(filter_var($forward, FILTER_VALIDATE_IP))
    {
        $ip = $forward;
    }
    else
    {
        $ip = $remote;
    }

    return $ip;
}


$user_ip = getUserIP();

echo $user_ip; // Output IP address [Ex: 177.87.193.134]


?>

#####get real ip php####


#######passive mode
--10 zabbix_agentd.conf 
LogFile=C:\zabbix_agentd.log
StartAgents=0
Server=srv-name-or-ip
#ServerActive=srv-name-or-ip:port
HostnameItem=system.hostname
HostMetadataItem=system.uname

--20 portal config
configuration-->hosts-->target host-->host-->ip address change to 0.0.0.0

-->Dns name change to null-->update

configuration-->hosts-->target host-->host-->templates-->delete old temp
-->select an active mode template-->add-->update


#######passive mode

########zabbix_get syntax
./zabbix_get -s 127.0.0.1 -p 10050 -k "system.cpu.load[all,avg1]"
  
  -s --host <host name or IP>      Specify host name or IP address of a host.
  -p --port <port number>          Specify port number of agent running on the host. Default is 10050.
  -I --source-address <IP address> Specify source IP address.
  -k --key <item key>              Specify key of item to retrieve value for.
  -h --help                        Give this help.
  -V --version                     Display version number.
########zabbix_get syntax

########zabbix with self signature certificate########
###ca.pem is CA certificate,Not CA key

1. server end key cfg 
# grep -v '#' /etc/zabbix/zabbix_server.conf |grep -v '^$'|grep TLS
TLSCAFile=/etc/zabbix/ca.pem
TLSCertFile=/etc/zabbix/server.crt
TLSKeyFile=/etc/zabbix/server.key

2. client end key cfg
grep -v '#' /etc/zabbix/zabbix_agentd.conf |grep -v '^$'|grep TLS
TLSConnect=cert
TLSAccept=cert
TLSCAFile=/etc/zabbix/ca.pem
TLSCertFile=/etc/zabbix/client.crt
TLSKeyFile=/etc/zabbix/client.key

########zabbix with self signature certificate########

#######zabbix with nat port map on windows######
###server
ZABBIX_SERVER的网关配置到10051的nat map
完成后使用psping检查是否成功
server配置不变
开启需要的防火墙端口与监听端口

###agent
LogFile=C:\zabbix_agentd.log
Server=server_public_ip
ListenPort=10010
ServerActive=server_public_ip:10051
HostnameItem=system.hostname
HostMetadataItem=system.uname

开启需要的防火墙端口与监听端口

zabbix agent的网关配置到10010的NAT MAP
完成后使用psping检查是否成功
#######zabbix with nat port map on windows######

######zabbix server clean database 清理数据库##########
DELETE FROM history WHERE 'clock' < 1509984000;
optimize table history;
######zabbix server clean database##########


######windows 使用mobaxterm ssh tunnnel 
$ sudo ps -ef |grep 10|grep infra
###sshtunnel 表示远端服务器的10051端口映射到本地的10000，本地仅需要与我本身localhost:10000通信
###10051是Zabbix_server的服务端口
ssh -NCfqL 10000:localhost:10051 -p 3002 someOne@example.com
###sshtunnel 表示本地服务器的10060端口映射到远端的10060，远端仅需要与它本身的localhost:10060通信
ssh -NCfqR 10060:localhost:10060 -p 3002 someOne@example.com


$ Windows zabbix_agentd.conf配置
LogFile=c:\zabbix_agentd.log
Server=127.0.0.1
###sshtunnel 表示本地服务器的10060端口映射到远端的10060，远端仅需要与它本身的localhost:10060通信
###ListenPort表示本地Zabbix_agentd的服务端口，默认位10050
ListenPort=10060
###sshtunnel 表示远端服务器的10051端口映射到本地的10000，本地仅需要与我本身localhost:10000通信
###10051是Zabbix_server的服务端口
ServerActive=127.0.0.1:10000
HostnameItem=system.hostname  ###自动注册
HostMetadataItem=system.uname ###按照操作系统自动归类

######windows 使用mobaxterm ssh tunnnel 
######End zabbix.memo #######
######Endmemoof zabbix.memo #######
######Startmemoof git.memo #######
######Start git.memo #######

user@linux:~/git> ssh-add ~/.ssh/rsa-key
Enter passphrase for /home/user/.ssh/rsa-key:
Identity added: /home/user/.ssh/rsa-key (/home/user/.ssh/rsa-key)

user@linux:~/git> git config --global user.email you-name@somemail.com

user@linux:~/git> git config --list
user.email=you-name@somemail.com
core.repositoryformatversion=0
core.filemode=true
core.bare=false
core.logallrefupdates=true

user@linux:~/git> ssh -T git@github.com
Hi your-gitid! You've successfully authenticated, but GitHub does not provide shell access.


user@linux:~/git> git clone git@github.com:your-gitid/your-repo
Cloning into 'your-repo'...
remote: Counting objects: 23, done.
remote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 23
Receiving objects: 100% (23/23), done.
Resolving deltas: 100% (7/7), done.

user@linux:~/git> cd your-repo/

user@linux:~/git> git add .  添加当前所有文件 到暂存区

user@linux:~/git/your-repo> vim sourFileList

user@linux:~/git/your-repo> git commit -a -m "update source list"
[master 46d78ca] update source list
1 file changed, 1 insertion(+), 1 deletion(-)

user@linux:~/git/your-repo> git push
Counting objects: 3, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 283 bytes | 0 bytes/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2), completed with 2 local objects.
To github.com:your-gitid/your-repo
23637cc..46d78ca  master -> master

user@linux:~/git/your-repo> git status
On branch master
Your branch is up-to-date with 'origin/master'.
nothing to commit, working tree clean

user@linux:~/git/your-repo> git log
commit 46d78caf90e08273a9deee359b8b2e61a19d3db3
Author: user <you-name@somemail.com>
Date:   Wed Sep 20 17:04:57 2017 +0800

update source list

commit 23637cce04220b6f668894865a4c3bd31eb86873
Author: user <you-name@somemail.com>
Date:   Wed Sep 20 16:58:26 2017 +0800

update compare-backup.sh

commit c11d0dc67fb8b07e5b6b7dd080cdce4648878cc4
Author: user <you-name@somemail.com>
Date:   Wed Sep 20 16:54:38 2017 +0800

update sh file

commit bb9c88bada6debd26ab9d370900751cc27b47fba
Author: root <root@your-name.localdomain>
Date:   Fri Aug 4 17:48:58 2017 +0800

5th
######End git.memo #######
######Endmemoof git.memo #######
######Startmemoof docker.memo #######
######Start docker.memo #######

 
####kubernetes best practice####
https://jimmysong.io/kubernetes-handbook/practice/
####kubernetes best practice####

####docker-compose nginx php #####################
# pwd
/usr/local/lnmp
# cat docker-compose.yml
version: '2'

services:
    web:
        image: nginx:latest
        ports:
            - "80:80"
        volumes:
            - /usr/local/php:/code
            - ./site.conf:/etc/nginx/conf.d/default.conf
        networks:
            - code-network
    php:
        image: php:fpm
        volumes:
            - /usr/local/php:/code
        networks:
            - code-network

networks:
    code-network:
        driver: bridge
# cat site.conf
server {
    listen 80;
    index index.php index.html;
    server_name localhost;
    error_log  /var/log/nginx/error.log;
    access_log /var/log/nginx/access.log;
    root /code;

    location ~ \.php$ {
        try_files $uri =404;
        fastcgi_split_path_info ^(.+\.php)(/.+)$;
        fastcgi_pass php:9000;
        fastcgi_index index.php;
        include fastcgi_params;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        fastcgi_param PATH_INFO $fastcgi_path_info;
    }
}
# cat /usr/local/php/index.php
<?php
echo "0322-1434";
?>

####docker-compose nginx php ############################


#####docker php#####

# cat Dockerfile
FROM php               //or FROM php:7-fpm
ADD index.php /var/www/
EXPOSE 8080
WORKDIR /var/www/
ENTRYPOINT ["php","-S","0.0.0.0:8080"]

# cat /usr/local/php/index.php
<?php
echo "your-php-script";
?>

# docker run --rm -v /usr/local/php:/var/www/ -p 8080:8080 09bcc
[Wed Mar 21 04:23:06 2018] 10.0.0.10:63443 [200]: /index.php

# docker ps
CONTAINER ID        IMAGE               COMMAND                 CREATED              STATUS              PORTS                    NAMES
2c407b93086f        09bcc               "php -S 0.0.0.0:8080"   About a minute ago   Up About a minute   0.0.0.0:8080->8080/tcp   sick_wing

# ip addr show |grep 161
    inet 10.0.0.161/24 brd 10.0.0.255 scope global eth0

# curl 10.0.0.161:8080/index.php
your-php-script


#####docker php#####



####How To Install and Use Docker Compose on CentOS 7#######
https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-compose-on-centos-7    How To Install and Use Docker Compose on CentOS 7 
1 install Docker
2.0 install docker-compose
sudo yum install epel-release
sudo yum install -y python-pip
sudo pip install docker-compose
sudo yum upgrade python*
pip install --upgrade pip

2.1 install docker-compose on opensuse
sudo curl -L https://github.com/docker/compose/releases/download/1.17.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

3 run demo
mkdir hello-world
cd hello-world


nano docker-compose.yml
my-test:
  image: hello-world

docker-compose up


4 php nginx demo url
http://geekyplatypus.com/dockerise-your-php-application-with-nginx-and-php7-fpm/
https://github.com/mikechernev/dockerised-php
####How To Install and Use Docker Compose on CentOS 7#######

http://www.cnblogs.com/sparkdev/p/7077333.html Docker Machine 创建 Azure 虚拟主机
http://www.cnblogs.com/sparkdev/p/7044950.html 在远程主机上安装 Docker
http://www.cnblogs.com/sparkdev/p/7066789.html Docker Machine 详解
http://www.cnblogs.com/sparkdev/p/6890995.html 局域网内部署 Docker Registry
http://www.cnblogs.com/sparkdev/p/8032330.html Docker: 限制容器可用的内存




https://yeasy.gitbooks.io/docker_practice/content/ Docker — 从入门到实践

#######连接到已经后台运行的docker container
$ docker exec -it containerid bash

$ docker images ###########列镜像
REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE
ubuntu/ubuntu_httpd v0 ba8ba558ddfb About an hour ago 227.9 MB

$ $ sudo docker run -itdp 8080:80 ubuntu/ubuntu_httpd:v0 #######以后台方式运行镜像
########注意端口格式是对外端口号：对内端口号###########
0b62724e1d06ca685cd4567ad46d4c5f26fe55089d423579e22942083a185e62

$ docker ps ###列出正在运行的镜像
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
0b62724e1d06 ubuntu/ubuntu_httpd:v0 "/bin/bash" ...... 0.0.0.0:8080->80/tcp rever

$ docker inspect 0b62724e1d06 |grep -Ei ipaddr ##########获取运行镜像的IP地址
"IPAddress": "172.17.0.26"         ####宿主机器的ip192.168.1.93

$ curl 172.17.0.26 #######运行的镜像初始没有启动nginx
curl: (7) couldn't connect to host

$ docker exec 0b62724e1d06 service nginx start######为启动的镜像启动nginx
$ curl 172.17.0.26 ##########nginx启动了,curl 192.168.1.93:8080也是一样#####
.............Some nginx html PAGE HERE.....................
<title>Welcome to nginx!</title>
.............OMIT MANY URL CONTENT..........................

使用宿主机器的目录作为工作目录(冒号前面是宿主机器目录，后面是容器目录）
$docker run -d -p 1080:80 --name website \
-v $PWD/website:/var/www/html/website jamtur01/nginx nginx

$ ls $PWD
default.htm index.html lb.html Test.html
\

###########创建私有HUB             //here 172.31.11.144 is Host IP Address###########
docker run -dp 5000:5000 registry  #创建服务器
docker tag 3620872edb5e 172.31.11.144:5000/your-name/ubuntu #标记待上传image
docker push 172.31.11.144:5000/your-name/ubuntu #上传image

# docker push 172.31.11.144:5000/michael/my-private-image
The push refers to a repository [172.31.11.144:5000/michael/my-private-image]


vim /etc/default/docker  #使用http的方式，编辑这个文件，加入下一句,CentOS6 worked,
CentOS7 not work.
DOCKER_OPTS="--insecure-registry 172.31.11.144:5000"

//CentOS 7 worked here
 //server gave HTTP response to HTTPS client error edit /etc/docker/daemon.json 
# cat /etc/docker/daemon.json               //PATT format style
{"registry-mirrors": [
"http://9993f789.m.daocloud.io"],           //This is speed up 
 "insecure-registries":[                    //This is http private repository
        "172.31.11.144:5000"
        ]
 }

# docker pull 172.31.11.144:5000/hw        //pull private repository 
Using default tag: latest
Trying to pull repository 172.31.11.144:5000/hw ... 
latest: Pulling from 172.31.11.144:5000/hw
Digest: sha256:8a8e4ca374451ac419bacb36ffe21edf3eee360d290d846b2c75e7b084fb5887

# docker images
REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE
172.31.11.144:5000/hw         latest              09bccff3fdd3        2 days ago          352 MB

###########创建私有HUB             //here 172.31.11.144 is Host IP Address###########


“Unable to locate package” while trying to install packages by apt

Try running sudo apt-get update before trying to install the package. After installation the system doesn't have an up-to-date package list so you won't be able to find the package.

制作完整docker自定义镜像的方法：

docker pull 拉源image
docker run -it imageID

进入Container
apt-get update 升级软件仓库源
apt-get install nginx 安装
nginx -v 验证
exit 退出docker

docker ps 查找ContainerID
docker commit 提交
docker commit -m "Added nginx from ubuntu14.04" -a "saymagic" 79c761f627f3 saymagic/ubuntu-nginx:v1

docker run -it

docker pull microsoft/dotnet

C#

###############加速#############

curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://9993f789.m.daocloud.io
如果报错，编辑下面的文件，去掉多余的逗号
vim /etc/docker/daemon.json
然后重启DOCKER

Copy

该脚本可以将 --registry-mirror 加入到你的 Docker 配置文件 /etc/default/docker 中。适用于
Ubuntu14.04、Debian、CentOS6 、CentOS7、Fedora、Arch Linux、openSUSE Leap 42.1，其他版本可能有细微不同。更多详情请访问文档。

网易
https://c.163.com/wiki/index.php?title=Dockerhub%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F

$ sudo echo "DOCKER_OPTS=\"\$DOCKER_OPTS --registry-mirror=http://hub-mirror.c.163.com\"" >> /etc/default/docker
$ service docker restart


docker offcial 官方
 为了永久性保留更改，您可以修改 /etc/docker/daemon.json 文件并添加上 registry-mirrors 键值。

{
  "registry-mirrors": ["https://registry.docker-cn.com"]
}

修改保存后重启 Docker 以使配置生效。 
#################################

Error starting daemon: layer does not exist" centos 7

https://github.com/moby/moby/blob/620339f166984540f15aadef2348646eee9a5b42/contrib/nuke-graph-directory.sh
运行下面的脚本,成功后删除DOCKER重装


#!/bin/sh

set -e

dir="$1"

if [ -z "$dir" ]; then

{

echo 'This script is for destroying old /var/lib/docker directories more safely than'

echo ' "rm -rf", which can cause data loss or other serious issues.'

echo

echo "usage: $0 directory"

echo " ie: $0 /var/lib/docker"

} >&2

exit 1

fi

if [ "$(id -u)" != 0 ]; then

echo >&2 "error: $0 must be run as root"

exit 1

fi

if [ ! -d "$dir" ]; then

echo >&2 "error: $dir is not a directory"

exit 1

fi

dir="$(readlink -f "$dir")"

echo

echo "Nuking $dir ..."

echo ' (if this is wrong, press Ctrl+C NOW!)'

echo

( set -x; sleep 10 )

echo

dir_in_dir() {

inner="$1"

outer="$2"

[ "${inner#$outer}" != "$inner" ]

}

# let's start by unmounting any submounts in $dir

# (like -v /home:... for example - DON'T DELETE MY HOME DIRECTORY BRU!)

for mount in $(awk '{ print $5 }' /proc/self/mountinfo); do

mount="$(readlink -f "$mount" || true)"

if dir_in_dir "$mount" "$dir"; then

( set -x; umount -f "$mount" )

fi

done

# now, let's go destroy individual btrfs subvolumes, if any exist

if command -v btrfs > /dev/null 2>&1; then

root="$(df "$dir" | awk 'NR>1 { print $NF }')"

root="${root#/}" # if root is "/", we want it to become ""

for subvol in $(btrfs subvolume list -o "$root/" 2>/dev/null | awk -F' path ' '{ print $2 }' | sort -r); do

subvolDir="$root/$subvol"

if dir_in_dir "$subvolDir" "$dir"; then

( set -x; btrfs subvolume delete "$subvolDir" )

fi

done

fi

# finally, DESTROY ALL THINGS

( set -x; rm -rf "$dir" )

] 27.57MB/82.5MB
eca642e7826b: Download complete
3638d91a9039: Download complete ########################################################
######End docker.memo #######
######Endmemoof docker.memo #######
######Startmemoof lsyncd.memo #######
######Start lsyncd.memo #######




####centos 6 service####
--10 script
$> cat /etc/init.d/syncd 

#!/bin/sh
#
# Startup sript for lsyncd call 
# 
# chkconfig: - 80 20
# description: lsyncd call 
# processname: lsyncd
# config: /etc/lsyncd_backup.lua
#

PROG=lsyncd
EXEC=/usr/local/bin/lsyncd
PIDFILE=/var/run/lsyncd.pid           ##same as lsyncd_backup.lua 
LOCKFILE=/var/lock/subsys/lsyncd
CONF=/etc/lsyncd_backup.lua
RETVAL=0

# Source function library.
. /etc/rc.d/init.d/functions


start() {
        if [ -f $PIDFILE ]
        then
                RETVAL=1
                echo "$PIDFILE exists, process is already running or crashed" && failure
                echo
                return $RETVAL
        else
                echo "Staring lsyncd ..."
                #ulimit -Hn 10240
                #ulimit -Sn 10240
                $EXEC  $CONF  > /dev/null 2>&1 &
                RETVAL=$?
                [ $RETVAL -eq 0 ] && touch $LOCKFILE &&  success || failure
                echo
                return $RETVAL
        fi
}

stop() {
        echo "Stopping..."
        if [ ! -f $PIDFILE ]
        then
                RETVAL=1
                echo "$PIDFILE does not exist, process is not running" && warning
                echo
            return $RETVAL
        else
                PID=$(cat $PIDFILE)
                pkill $PROG
                rm -f $LOCKFILE
                rm -f $PIDFILE
                echo "lsyncd stopped" && success
                echo
        fi
}


case "$1" in
        start)
                start
                ;;
        stop)
                stop
                ;;
        restart)
                stop
                start
                ;;
        *)
                echo "Please use start, stop or restart as first argument"
                RETVAL=2
                ;;
esac

exit $RETVAL

--20 setup service
 $> chmod +x /etc/init.d/syncd

 $> chkconfig syncd on
 
 $> service syncd start

####centos 6 service####



####centos 7 use service####
$> cat /usr/lib/systemd/system/syncd.service

[Unit]
Description=lsyncd daemon
After=network.target

[Service]
User=root
Group=root
Restart=always                ############crashed auto restart key 
ExecStart=/usr/local/bin/lsyncd /etc/lsyncd_backup.lua
Type=forking
# file size
LimitFSIZE=infinity
# cpu time
LimitCPU=infinity
# virtual memory size
LimitAS=infinity
# open files
LimitNOFILE=64000
# processes/threads
LimitNPROC=64000
# locked memory
LimitMEMLOCK=infinity
# total threads (user+kernel)
TasksMax=infinity
TasksAccounting=false

[Install]
WantedBy=multi-user.target

$> systemctl daemon-reload
$> systemctl start syncd
$> systemctl enable syncd

####centos 7 use service####

############使用证书的成功的配置############
PATT，注意：源和目标都要有rsync软件
源一定有lsyncd,版本2.1.6;
目标的rsync版本3.0.9;
注意文件和目录的权限，selinx;防火墙;
sshd的配置文件细节,ssh先配置全功能的，
成功后才使用限定的命令。

在备份源的机器上的known_hosts上有目标服务器的条目。
# cat /home/your-backup/.ssh/authorized_keys
no-agent-forwarding,no-pty,no-port-forwarding ssh-rsa AAAAB3ZeENJrZ2RRb root@backup_server
##no-agent-forwarding,no-pty,no-port-forwarding这几条保证只能传输文件，不能登陆server

在备份服务器的机器的Authorized_keys上有源机器的ssh条目
# cat .ssh/known_hosts
[backup_server]backup_server ecdsa-sha2-nistp256 AAAAE2VjZHNh。。。。。。zsyUk=


_________安装_______________
$> yum install -y lua cmake lua-devel gcc gcc-c++ rsync
cmake .
make       
make install
lsyncd -version
_________安装END_______________


-----------备份源设置----------------
settings {
    insist = true,  --如果出错，不断进行
    logfile = "/var/log/lsyncd.log",
    statusFile = "/var/log/lsyncd.stat", 
    pidfile = "/var/run/lsyncd.pid",     --same as /etc/init.d/syncd 
    statusInterval = 2
}

--comment 10,backup A
sync {
    default.rsync,
    source="/home/user/",
    target="example.com:/backup/",
    delete = false,
    exclude = {"your-directory/dir1","your-directory/dir2"},  --排查特定的目录，注意时相对于$source的路径 
    rsync = {
        rsh ="/usr/bin/ssh -i /root/.ss h/your-ssh-rsa-privity-key -p your-port -l your-user-name",
        compress = true,
        perms = ture,
        acls = true,
        xattrs = true,
        archive = true
    }
}

--comment 20 backup B
sync {

......similar to backup A 

}
以上的配置文件名为backupcfg.lua,
调用方法：/path/2/lsyncd /path/2/backupcfg.lua
调用排错：使用ps -ef |grep lua查看进程是否运行，没有网络端口开放，使用netstat看不到状态。
可以配置多个rsync段来实现备份多个目录

-----------备份源设置END----------------




----------备份目标服务器设置---------------
setfacl -R -m u:your-backup:rwx backup
[root@cd-mon-01l /]# ll |grep backup
drwxrwx---+   5 1004 group-name 4096 Mar  8 15:11 backup
[root@cd-mon-01l /]# getfacl backup
# file: backup
# owner: 1004
# group: group-name
user::rwx
user:your-backup:rwx
group::---
mask::rwx
other::---

[root@cd-mon-01l /]# ll /home/your-backup/ -A|grep ssh
drwx------ 2 your-backup your-backup   28 Mar  8 14:51 .ssh



###sshd的server配置，先不使用这些，第一次client ssh成功后再添加这些
#grep backup /etc/ssh/sshd_config
Match user backup
        PasswordAuthentication no
        RSAAuthentication yes
        AllowAgentForwarding no
        AllowTcpForwarding no
        GatewayPorts no
        PermitTTY no

####如果有问题，tail log

------备份目标服务器设置END-----------------------
############使用证书的成功的配置END############





https://axkibe.github.io/lsyncd/manual/invoking/   这个靠谱
参考：（仅供参考）
https://www.keycdn.com/support/how-to-setup-lsyncd-over-ssh/
https://axkibe.github.io/lsyncd/manual/config/layer4/
https://www.lucasrolff.com/ha/replication-using-lsyncd/
http://blog.uouo123.com/post/100.html
https://www.scalescale.com/tips/nginx/lsyncd-live-file-syncronization-linux/#

######End lsyncd.memo #######
######Endmemoof lsyncd.memo #######
######Startmemoof ansible.memo #######
######Start ansible.memo #######
######How to continue execution on failed task after fixing error in playbook?
--10 Link:
https://stackoverflow.com/questions/29900096/how-to-continue-execution-on-failed-task-after-fixing-error-in-playbook

--20 failed here
TASK [zabbix : create scriptErrorLog]

--30 start from fixing error
$> ansible-playbook task.yml --start-at-task "zabbix : create scriptErrorLog" -u --ask-pass --sudo --ask-sudo-pass

######How to continue execution on failed task after fixing error in playbook?


#########login before ansible######
 "failed": true, 
    "msg": "Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this.  Please add this host's fingerprint to your known_hosts file to manage this host."
#########login before ansible######



####ping##########
ansible hostGrp -m ping -u user --ask-pass
###ping###############


####tips############
ansible hostGrp -m shell -a 'some-command' --keyfile=path/2/key -u user --sudo --ask-sudo    //MayBe need keyfile register in keychain
                          //and some self installed command only support shell but not raw 
####tips############



####报selinx错误处理（目标被操作主机上操作）
yum -y install libselinux-python

####不存bar才创建文件（或者目录）
name: create bar
ls /path/to/bar >&/dev/null || cd /path/to && touch bar
ls /path/to/bar >&/dev/null || mkdir /path/to/bar

#### 使用系统变量替换特定字符
- name: replace hostname
  raw: /bin/sed -i "s:HOSTNAME:$HOSTNAME:g" /path/2/foo

####对特定的文件新加原来不存在的一行在末尾 ,line=后面的是添加的内容
ansible test -m lineinfile -a "dest=/root/cs.txt line='92.168.1.99'" -u userName --become --ask-sudo-pass --key-file=key-file

SUDO password: ###下面是结果
192.168.1.15 | SUCCESS => {
    "backup": "",
    "changed": true,
    "msg": "line added"
}

使用密码连接远程的方式
ansible HostGrp -m raw -a "/cmd" -u userName -k --become --ask-sudo-pass

###ansible with expect ####
cat /tmp.com.sh
#!/bin/bash
   username=$1;
   newpass=$2;
   export HISTIGNORE="expect*";
   expect -c "
        set timeout 5
        spawn passwd $username
        expect "?assword:"
        send \"$newpass\r\"
        expect "?assword:"
        send \"$newpass\r\"
        expect eof"
  export HISTIGNORE="";

~> ansible db -a "/bin/sh /tmp.com.sh Alice com-2358" -u Michael \
--key-file=.ssh/rsa_private_keys --sudo -K
SUDO password:
192.168.20.10 | SUCCESS | rc=0 >>
spawn passwd Alice
Changing password for user Alice.
New password:
Retype new password:
passwd: all authentication tokens updated successfully.
###ansible with expect ####

######服务器多角色#####
######服务器多角色#####
######服务器多角色#####
Shell> tree ansible
ansible
├── roles
│   ├── screen
│   │   ├── defaults
│   │   ├── files
│   │   │   ├── ansibleInstallScreen.sh
│   │   │   └── screen.tar.gz
│   │   ├── handlers
│   │   ├── meta
│   │   ├── tasks
│   │   │   └── main.yml
│   │   ├── templates
│   │   └── vars
│   └── zabbix
│       ├── defaults
│       ├── files
│       │   ├── autoInstallZbxClient.sh
│       │   └── zabbix-3.0.4.tar.gz
│       ├── handlers
│       ├── meta
│       ├── tasks
│       │   └── main.yml
│       ├── templates
│       └── vars
└── web.yml

17 directories, 7 files

Shell> cat ansible/web.yml
- hosts: all
  remote_user: Michael
  roles:
    - screen
    - zabbix
######服务器多角色#####
######服务器多角色#####
######服务器多角色#####

######################
######################
######################
安装screen成功
服务器opensuse 42.2 客户端CentOS 7
ansible 2.1.1 用户Michael使用key登陆客户端

Shell>mkdir -p ansible/roles/screen/{defaults,files,handlers,meta,tasks,templates,vars}

Shell> tree
.
├── roles
│   └── screen
│       ├── defaults
│       ├── files
│       │   ├── ansibleInstallScreen.sh
│       │   └── screen.tar.gz
│       ├── handlers
│       ├── meta
│       ├── tasks
│       │   └── main.yml
│       ├── templates
│       └── vars
└── web.yml

Shell> cat web.yml （在这以下的yml文件有严格的格式要求，否则报错）
- hosts all
  remote_user Michael
  roles
    - screen
Shell> cat roles/screen/tasks/main.yml
---
- name copy tar.gz
  copy src=screen.tar.gz dest=/tmp/screen.tar.gz
- name copy sh
  copy src=ansibleInstallScreen.sh dest=/tmp/ansibleInstallScreen.sh mode=0755
- name run
  shell /bin/sh /tmp/ansibleInstallScreen.sh

Shell> cat roles/screen/files/ansibleInstallScreen.sh
#!/bin/bash
export
PATH=/usr/local/bin/bin/usr/bin/usr/local/sbin/usr/sbin/sbin/home/Alen/bin
yum -y install ncurses-devel gcc gcc++ autoconf automake
/bin/mkdir -p /usr/local/screen
/bin/tar zxf /tmp/screen.tar.gz -C /usr/local/screen
cd /usr/local/screen/v.4.3.1/src
./autogen.sh
./configure
make
rm /usr/bin/screen -f
ln -s /usr/local/screen/v.4.3.1/src/screen /usr/bin/screen

Shell> ansible-playbook web.yml --syntax-check

playbook web.yml
Shell> ansible-playbook web.yml -u Michael --key-file=.ssh/logcdbak --sudo -K
Shell> ansible-playbook web.yml -u Michael --key-file=.ssh/logcdbak --sudo --ask-sudo-pass
Shell> ansible-playbook web.yml -u Michael --ask-pass  --sudo --ask-sudo-pass

SUDO password:(输入目标机器的sudo密码）

PLAY [all] *********************************************************************

TASK [setup] *******************************************************************
ok [192.168.0.11]

TASK [screen  copy tar.gz] ****************************************************
changed [192.168.0.11]

TASK [screen  copy sh] ********************************************************
changed [192.168.0.11]

TASK [screen  run] ************************************************************
changed [192.168.0.11]

PLAY RECAP *********************************************************************
192.168.0.11             : ok=4    changed=3    unreachable=0    failed=0

######################
######################
######################

#!/bin/bash
PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/root/bin:/usr/local/mysql/bin
export PATH
srvIP="192.168.1.13"
ftpUser="xml"
ftpPwd="Y0urFtpP@ssw)rd"
mysqlPkg="mysql-5.6.33.tar.gz"
ftpPath="ftp://$srvIP/$mysqlPkg"
srcPath="/usr/local/src"
installPath="/usr/local/mysql"
mysqlConf="/etc/my.comf"
initialpw='YourRootPasswordHere'
vmCpuCores=$(cat /proc/cpuinfo |grep processor |wc -l)
cd $srcPath
wget --user=$ftpUser --password=$ftpPwd $ftpPath

#add mysql user
if [ `cat /etc/passwd|grep 'mysql' |wc -l` -eq 0 ];then
        groupadd -r mysql
        useradd -g mysql -s /sbin/nologin -g mysql -M mysql
fi
yum install -y gcc-c++ ncurses-devel gcc gcc++ gcc-g77 openssl-devel cmake
tar zxf $mysqlPkg

cd $srcPath/mysql-5.6.33
 cmake \
-DCMAKE_INSTALL_PREFIX=$installPath \
-DMYSQL_DATADIR=$installPath/data \
-DSYSCONFDIR=/etc \
-DWITH_MYISAM_STORAGE_ENGINE=1 \
-DWITH_INNOBASE_STORAGE_ENGINE=1 \
-DWITH_MEMORY_STORAGE_ENGINE=1 \
-DWITH_READLINE=1 \
-DMYSQL_UNIX_ADDR=$installPath/mysql.sock \
-DMYSQL_TCP_PORT=3306 \
-DENABLED_LOCAL_INFILE=1 \
-DWITH_PARTITION_STORAGE_ENGINE=1 \
-DEXTRA_CHARSETS=all \
-DDEFAULT_CHARSET=utf8 \
-DDEFAULT_COLLATION=utf8_general_ci \
-DMYSQL_USER=mysql \
-DWITH_DEBUG=0 \
-DWITH_SSL=system

if [ $? -eq 0 ];then
      make -j $vmCpuCores
fi

if [ $? -eq 0 ];then
      make install
fi

chmod +w $installPath
chown -R mysql.mysql $installPath
cd $srcPath/mysql-5.6.33/support-files/

mv $mysqlConf "$mysqlConf".bak
cp my-default.comf $mysqlConf

$installPath/scripts/mysql_install_db --defaults-file=$mysqlConf --basedir=$installPath --datadir=$installPath/data -user=mysql

cp $srcPath/mysql-5.6.33/support-files/mysql.server /etc/init.d/mysqld

chmod +x /etc/init.d/mysqld
chkconfig mysqld on
service mysqld start

if [ `cat /etc/profile|grep 'mysql/bin' |wc -l` -eq 0 ];then
  echo "export PATH=$installPath/bin:$PATH" /etc/profile
  source /etc/profile
fi

sleep 1s
#update mysql credential
$installPath/mysql -uroot -e "update user set password=password('$initialpw') where host='127.0.0.1'" mysql;
$installPath/mysql -uroot -e "delete from user where password=''" mysql
$installPath/mysql -uroot -e "flush privileges" mysql
sleep 1s
service mysqld restart

############install 5.7########################
################start#########################
#!/bin/bash
PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/root/bin:/usr/local/mysq/bin
export PATH
srvIP="192.168.1.13"
ftpUser="xml"
ftpPwd="Y0urFtpP@ssw)rd"
mysqlPkg="mysql-5.7.17.tar.gz" ##需要boost版本
ftpPath="ftp://$srvIP/$mysqlPkg"
srcPath="/usr/local/src"
initialpw='abcd-1238'
installPath="/usr/local/mysql"
mysqlConf="/etc/my.comf"
vmCpuCores=$(cat /proc/cpuinfo |grep processor |wc -l)
cd $srcPath
wget --user=$ftpUser --password=$ftpPwd $ftpPath

#add mysql user
if [ `cat /etc/passwd|grep 'mysql' |wc -l` -eq 0 ];then
        groupadd -r mysql
        useradd -g mysql -s /sbin/nologin -g mysql -M mysql
fi
yum install -y gcc-c++ ncurses-devel gcc gcc++ gcc-g77 openssl-devel cmake
tar zxf $mysqlPkg

cd $srcPath/mysql-5.7.17
 cmake \
-DCMAKE_INSTALL_PREFIX=$installPath \
-DMYSQL_DATADIR=$installPath/data \
-DSYSCONFDIR=/etc \
-DWITH_MYISAM_STORAGE_ENGINE=1 \
-DWITH_INNOBASE_STORAGE_ENGINE=1 \
-DWITH_MEMORY_STORAGE_ENGINE=1 \
-DWITH_READLINE=1 \
-DMYSQL_UNIX_ADDR=$installPath/mysql.sock \
-DMYSQL_TCP_PORT=3306 \
-DENABLED_LOCAL_INFILE=1 \
-DWITH_PARTITION_STORAGE_ENGINE=1 \
-DEXTRA_CHARSETS=all \
-DDEFAULT_CHARSET=utf8 \
-DDEFAULT_COLLATION=utf8_general_ci \
-DMYSQL_USER=mysql \
-DWITH_DEBUG=0 \
-DWITH_SSL=system \
-DWITH_BOOST=/usr/local/src/mysql-5.7.17/boost/boost_1_59_0
if [ $? -eq 0 ];then
      make -j $vmCpuCores
fi

if [ $? -eq 0 ];then
      make install
fi
mkdir -p $installPath/data
chmod +w $installPath
chown -R mysql.mysql $installPath
cd $srcPath/mysql-5.7.17/support-files/

mv $mysqlConf "$mysqlConf".bak
cp my-default.comf $mysqlConf

$installPath/bin/mysqld --initialize --basedir=$installPath --datadir=$installPath/data/ --user=mysql

cp $srcPath/mysql-5.7.17/support-files/mysql.server /etc/init.d/mysqld

chmod +x /etc/init.d/mysqld
chkconfig mysqld on
service mysqld start

if [ `cat /etc/profile|grep 'mysql/bin' |wc -l` -eq 0 ];then
        echo "export PATH=$installPath/bin:$PATH" >>/root/.bashrc
  source /root/.bashrc
fi

sleep 1s
#update mysql credential
#$installPath/bin/mysql -uroot -e "update user set password=password('$initialpw') where host='127.0.0.1'" mysql;
#$installPath/bin/mysql -uroot -e "delete from user where password=''" mysql
#$installPath/bin/mysql -uroot -e "flush privileges" mysql
#sleep 1s

安装完成5.7后最后部分系统会给你一个初始密码；
使用这个初始密码登陆到Mysql后，
用Alter User 'root'@'localhost' identified by 'nespassword'后才可以使用Mysql。

ALTER USER 'jeffrey'@'localhost' IDENTIFIED WITH sha256_password BY 'new_password' PASSWORD EXPIRE INTERVAL 180 DAY;
############install 5.7########################
################end#########################

++ansible++++++++++
ansible zbx  -a "/usr/bin/wget --user=xml --password=Y0urFtpP@ssw)rd ftp://192.168.1.13/getMysql.sh" -u MIKE --sudo -K
 ansible zbx  -a "/bin/sh getMysql.sh" -u MIKE --sudo -K
++++++ansible end++++++++++

############screen start#############
++++++++++++
#!/bin/bash
export PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/Alice/bin
yum -y install ncurses-devel gcc gcc++ autoconf automake
/bin/mkdir -p /usr/local/screen
/bin/tar zxf /tmp/screen.tar.gz -C /usr/local/screen
cd /usr/local/screen/v.4.3.1/src
./autogen.sh
./configure
make
rm /usr/bin/screen -f
ln -s /usr/local/screen/v.4.3.1/src/screen /usr/bin/screen
++++++++++++

调用命令：输入Alice的sudo密码
ansible tstclient  -a "/bin/sh /tmp/installscreen.sh" -u Alice --key-file dlu --sudo -K
注意sh的任何命令出现错误都会导致整个ansible错误

############screen start#############

##########以下的在2.2.1.0版本下操作###################
####one ip with more port on remote #########
#####edit in /etc/ansible host###############
[tstdb]
db1 ansible_ssh_port=6001 ansible_ssh_host=yc.example.com
db2 ansible_ssh_port=6002 ansible_ssh_host=yc.example.com
####one ip with more port on remote END#########
查证ansible的command命令无法使用grep操作，要想使用管道命令，需要使用shell来操作。？？

# ansible tstdb -m shell -a "grep -v '#' /etc/selinux/config" -u user --key-file dlu  -K
SUDO password:
db2 | SUCCESS | rc=0 >>

SELINUX=disabled
SELINUXTYPE=targeted

db1 | SUCCESS | rc=0 >>

SELINUX=disabled
SELINUXTYPE=targeted

需要适用命令的绝对路径（如下面的/sbin/ifconfig)
ansible tstdb -m shell -a "/sbin/ifconfig|grep 172" -u user --key-file dlu  -K

++++ingore ssh key error on run asinsble ad-hoc start++++
vim /etc/ansible/ansible.cfg
$ grep host_key /etc/ansible/ansible.cfg
host_key_checking = False
++++++++key error end+++++++++++++++

++++++++++none standard port start++++++
none standard port only add port number to /etc/ansible/host
like this
10.2.3.4:60000
192.168.5.6:22
www.example.com:60100
++++++++++none standard port end++++++

$ ansible bak -m copy -a "src=./installVsftpd.sh dest=/tmp/iv.sh" -u some-user --sudo -K
SUDO password:
10.31.100.13 | SUCCESS => {
    "changed": true,
    "checksum": "be4292da978ead81fea35f9eabed15608ef240bd",
    "dest": "/tmp/iv.sh",
    "gid": 0,
    "group": "root",
    "md5sum": "07ac7f2cf9b106f998a08c209d036861",
    "mode": "0644",
    "owner": "root",
    "size": 178,
    "src": "/home/some-user/.ansible/tmp/ansible-tmp-1480586111.94-149658495898370/source",
    "state": "file",
    "uid": 0
}
$ ansible bak -m file -a "path=/tmp/iv.sh mode=755" -u some-user --sudo -K
SUDO password:
10.31.100.13 | SUCCESS => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "mode": "0755",
    "owner": "root",
    "path": "/tmp/iv.sh",
    "size": 178,
    "state": "file",
    "uid": 0
}

$ ansible bak  -a "/bin/sh /tmp/iv.sh" -u some-user --sudo -K
SUDO password:
10.31.100.13 | SUCCESS | rc=0 >>
Loaded plugins: fastestmirror, security
Determining fastest mirrors
Setting up Install Process
Resolving Dependencies
--> Running transaction check
---> Package vsftpd.x86_64 0:2.2.2-21.el6 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

================================================================================
 Package          Arch             Version                 Repository      Size
================================================================================
Installing:
 vsftpd           x86_64           2.2.2-21.el6            base           155 k

Transaction Summary
================================================================================
Install       1 Package(s)

Total download size: 155 k
Installed size: 340 k
Downloading Packages:
Running rpm_check_debug
Running Transaction Test
Transaction Test Succeeded
Running Transaction
  Installing : vsftpd-2.2.2-21.el6.x86_64                                   1/1
  Verifying  : vsftpd-2.2.2-21.el6.x86_64                                   1/1

Installed:
  vsftpd.x86_64 0:2.2.2-21.el6

Complete!
Starting vsftpd for vsftpd: [  OK  ]Warning: RPMDB altered outside of yum.

$ cat /tmp/iv.sh
#!/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:/usr/local/mongodb/bin
export PATH
yum install -y vsftpd
service vsftpd start
######End ansible.memo #######
######Endmemoof ansible.memo #######
######Startmemoof parellel-ping.py #######
######Start parellel-ping.py #######
link:http://blog.boa.nu/2012/10/python-threading-example-creating-pingerpy.html
#!/usr/bin/env python

import subprocess
import threading

class Pinger(object): 
    status = {'alive': [], 'dead': []} # Populated while we are running
    hosts = [] # List of all hosts/ips in our input queue

    # How many ping process at the time.
    thread_count = 20

    # Lock object to keep track the threads in loops, where it can potentially be race conditions.
    lock = threading.Lock()

    def ping(self, ip):
        # Use the system ping command with count of 1 and wait time of 1.
        ret = subprocess.call(['ping', '-c', '1', '-W', '1', ip],
                              stdout=open('/dev/null', 'w'), stderr=open('/dev/null', 'w'))

        return ret ==  0 # Return True if our ping command succeeds
                         #equl if ret == 0 return true else return false
    def pop_queue(self): 
        ip = None

        self.lock.acquire() # Grab or wait+grab the lock.

        if self.hosts:
            ip = self.hosts.pop()

        self.lock.release() # Release the lock, so another thread could grab it.

        return ip

    def dequeue(self):
        while True:
            ip = self.pop_queue()

            if not ip:
                return None

            result = 'alive' if self.ping(ip) else 'dead' ##TernaryFunction
            self.status[result].append(ip)                ##like c++ if a>b?a:b

    def start(self):
        threads = []

        for i in range(self.thread_count):
            # Create self.thread_count number of threads that together will
            # cooperate removing every ip in the list. Each thread will do the
            # job as fast as it can.
            t = threading.Thread(target=self.dequeue)
            t.start()
            threads.append(t)

        # Wait until all the threads are done. .join() is blocking.
        [ t.join() for t in threads ]

        return self.status 

if __name__ == '__main__': 
    ping = Pinger()
    ping.thread_count = 8
    ping.hosts = [
        '192.168.28.1', '192.168.28.2', '192.168.28.3', '192.168.28.4', '192.168.28.0', '192.168.28.255', '192.168.28.100',
        'google.com', 'github.com', 'nonexisting', '127.0.1.2', '*not able to ping!*', '8.8.8.8'
        ]

    print ping.start()
######End parellel-ping.py #######
######Endmemoof parellel-ping.py #######
######Startmemoof postfix.memo #######
######Start postfix.memo #######
######postfix config##########
##########plain txt###########
########Example.com has MX dns record
step 1
#DNS record https://support.rackspace.com/how-to/create-an-spf-txt-record/
$> cat /var/named/example.com.zone |grep mail
@                                IN  MX     10  mail;
pop                              IN  CNAME  mail
imtp                             IN  CNAME  mail
mail                             IN  A          19.18.218.11
example.com. TXT "v=spf1 mx example.com -all" 

step 2
$>yum install cyrus-sasl-*
$>setenforce 0
##config selinux                           //waiting for make perfect 
$>yum install setroubleshoot setools
$>sealert -a /var/log/audit/audit.log      //find out where is blocked by selinux

$>semanage fcontext -a -t user_home_dir_t 'Maildir'
$>restorecon -v 'Maildir'
$>ausearch -c 'local' --raw | audit2allow -M my-local
$>semodule -i my-local.pp
$>ausearch -c 'pop3' --raw | audit2allow -M my-pop3
$>semodule -i my-pop3.pp
$>semanage fcontext -a -t data_home_t 'dovecot-uidlist.tmp'
$>restorecon -v 'dovecot-uidlist.tmp'
$>ausearch -c 'saslauthd' --raw | audit2allow -M my-saslauthd
$>semodule -i my-saslauthd.pp
$>auditctl -w /etc/shadow -p w
$>setsebool -P saslauthd_read_shadow 1


step 3
# grep -v "#" /etc/postfix/main.cf |grep -v "^$"
queue_directory = /var/spool/postfix
command_directory = /usr/sbin
daemon_directory = /usr/libexec/postfix
data_directory = /var/lib/postfix
mail_owner = postfix
myhostname = mail.Example.com
mydomain = Example.com
myorigin = $mydomain
inet_interfaces = all
inet_protocols =  all
mydestination = $myhostname, localhost.$mydomain, localhost, $mydomain
unknown_local_recipient_reject_code = 550
mynetworks =192.168.16.0/24, 127.0.0.0/8,0.0.0.0/0  ###0/0 is permit public use##
relay_domains = *                                   #############################
alias_maps = hash:/etc/aliases
alias_database = hash:/etc/aliases
home_mailbox = Maildir/
 
  
debug_peer_level = 2
debugger_command =
PATH=/bin:/usr/bin:/usr/local/bin:/usr/X11R6/bin
sendmail_path = /usr/sbin/sendmail.postfix
newaliases_path = /usr/bin/newaliases.postfix
mailq_path = /usr/bin/mailq.postfix
setgid_group = postdrop
html_directory = no
manpage_directory = /usr/share/man
sample_directory = /usr/share/doc/postfix-2.10.1/samples

#sasl authentication                               //very important
smtpd_sasl_auth_enable = yes
smtpd_sasl_security_options = noanonymous
broken_sasl_auth_clients = yes
smtpd_recipient_restrictions = permit_sasl_authenticated,reject_unauth_destination,permit_mynetworks
smtpd_client_restrictions = permit_sasl_authenticated

step 4
#######dovecot config#############
# grep -v "#" /etc/dovecot/dovecot.conf |grep -v "^$"
protocols = imap pop3   #####delete ssl support#####
mail_location = maildir:~/Maildir
pop3_uidl_format = %08Xu%08Xv
login_process_size = 64
login_trusted_networks = 0.0.0.0/0
disable_plaintext_auth = no
dict {
}
!include conf.d/*.conf
!include_try local.conf
[root@mail-server dovecot]# grep -v "#" /etc/dovecot/dovecot.conf
protocols = imap pop3 
mail_location = maildir:~/Maildir
pop3_uidl_format = %08Xu%08Xv
login_process_size = 64
login_trusted_networks = 0.0.0.0/0
disable_plaintext_auth = no
dict {
  #quota = mysql:/etc/dovecot/dovecot-dict-sql.conf.ext
  #expire = sqlite:/etc/dovecot/dovecot-dict-sql.conf.ext
}
!include conf.d/*.conf
!include_try local.conf

# grep -v "#" /etc/dovecot/conf.d/10-auth.conf |grep -v "^$"
disable_plaintext_auth = no 
auth_mechanisms = plain login
!include auth-system.conf.ext


####
vim /etc/dovecot/conf.d/10-auth.conf
disable_plaintext_auth = no
auth_mechanisms = plain

###
vim /etc/dovecot/conf.d/10-mail.conf
mail_location = maildir:~/Maildir

###
vim /etc/dovecot/conf.d/10-ssl.conf
ssl = no

step 5
###########sasl2 config
vim /etc/sysconfig/saslauthd
MECH=shadow  #指定以本地系统用户名认证

vim /etc/sasl2/smtpd.conf
pwcheck_method: saslauthd
mech_list: PLAIN LOGIN
log_level:3

step 6
########reboot service
systemctl  restart  dovecot
systemctl  restart  postfix
systemctl  restart  saslauthd


###reboot auto run
[root@localhost ~]# systemctl enable postfix
[root@localhost ~]# systemctl enable dovecot
[root@localhost ~]# systemctl enable saslauthd

###open firewall-port 
[root@localhost ~]# firewall-cmd --add-service smtp --permanent
success
[root@localhost ~]# firewall-cmd --add-service pop3 --permanent
success
[root@localhost ~]# firewall-cmd --reload
success
[root@localhost ~]# firewall-cmd --list-all
public (active)
  target: default
  icmp-block-inversion: no
  interfaces: ens192
  sources: 
  services: dhcpv6-client pop3 smtp ssh


step 7
####################add user
>$groupadd postfixusers

>$useradd -g postfixusers -d /data/mail_user  mail_user

>$mkdir -p /data/mail_user/Maildir
>$passwd mail_user

#deny ssh login
>$ usermod -s /sbin/nologin mail_user  and/or AllowGroups postfixusers@127.0.0.1 in /etc/ssh/sshd_config

>$cat /etc/passwd
mail_user:x:1002:1001::/data/mail_user:/bin/bash

>$chown -R mail_user.postfixusers   /data/mail_user/
>$chmod 700 /data/mail_user


>$ ls -ld /data/mail_user/Maildir/
drwxr-xr-x. 5 mail_user root 171 Oct 26 12:40 /data/mail_user/Maildir/
>$ ls -ld /data/mail_user
drwx------. 3 mail_user postfixusers 77 Oct 26 11:32 /data/mail_user



step 8
#########telnet test mail function#####
https://mediatemple.net/community/products/dv/204404584/sending-or-viewing-emails-using-telnet 

perl -MMIME::Base64 -e 'print encode_base64("username");'   // with out domain name
perl -MMIME::Base64 -e 'print encode_base64("password");'

https://www.ndchost.com/wiki/mail/test-smtp-auth-telnet
user@localhost [~]# telnet exampledomain.com 25 //user input command 
Trying 1.1.1.1...
Connected to exampledomain.com (1.1.1.1).
Escape character is '^]'.
220-server1.exampledomain.com ESMTP Exim 4.66 #1 Wed, 09 May 2007 23:55:12 +0200
220-We do not authorize the use of this system to transport unsolicited,
220 and/or bulk e-mail.
EHLO exampledomain.com                          //user input command 
250-server1.exampledomain.com Hello  [1.1.1.2]
250-SIZE 52428800
250-PIPELINING
250-AUTH PLAIN LOGIN
250-STARTTLS
250 HELP
AUTH LOGIN                                      //user input command 
334 VXNlcm5hbWU6
dXNlcm5hbWUuY29t                                //user input user name 
334 UGFzc3dvcmQ6
bXlwYXNzd29yZA==                                //user input user password

235 Authentication succeeded

step 9
#############client config###############
#########outlook
1 email address:       your_name@Example.com
2 Account type:        pop3
3 receive server:      example.com ###MX DNS record here
4 send server:         example.com ###MX DNS RECORD HERE
5 USER NAME:           your_name
6 Password             your_password

7 Other setup

  7.0  check on: smtp need authentication
  7.1  check on: logon in server before send mail 
  7.2  pop3:     110
  7.3  smtp:     25



#########Tips ##########
1 view logs on /var/log/malllog
2 on outlook sometime test failuer,skip it,enter and use it,no Problem

#####How to send email using telnet
 Below are instructions on how to test SMTP AUTH against a mail server using Telnet and entering the commands by hand.

The first thing you need to do is get a base64 encoding of your username and password. There are a couple ways to do this, the example below uses Perl:

perl -MMIME::Base64 -e 'print encode_base64("username");'
perl -MMIME::Base64 -e 'print encode_base64("password");'




    Open your command prompt.
    Now, connect with telnet using the following command:

    telnet example.com 25

    Type ehlo example.com. Some servers also accept helo in place of ehlo.

    ehlo example.com

    Type mail from: username@example.com:

    mail from: username@example.com

    Type rcpt to: friend@hotmail.com, friend2@yahoo.com (replace with your actual recipient name):

    rcpt to: friend@hotmail.com, friend2@yahoo.com

    To write the message - type data, followed by your subject and message. To end the message, put a period on a line by itself and press enter:

    data
    Subject: My Telnet Test Email

    Hello,

    This is an email sent by using the telnet command.

    Your friend,
    Me

    .

    Type quit to exit telnet.

#####How to check or read email with telnet

    Open your command prompt.
    At the command prompt, type in

    telnet example.com 110

    Type user and the email address (username@example.com) of the user for which you wish to view emails:

    user username@example.com

    Then type in pass followed by your password:

    pass yourpasswordgoeshere

    Type list to bring up a list of your emails:

    list

    You will see a list of items with labels like "1 897" and "2 5136." Here is an example:

    list
    +OK POP3 clients that break here, they violate STD53.
    1 897
    2 5136
    3 1884
    4 2973
    5 2595
    6 3063
    7 3509
    8 2283
    9 1926
    10 2763
    11 1795
    12 2780
    13 2342
    14 2342
    15 2342
    16 3833
    17 2211
    18 793
    19 797
    20 2599
    .

    If you wish to read an email message such as 2 5136, you can type the following:

    retr 2 

    If you want to delete a message such as 1 897, type dele 1:

    dele 1

    When you are done checking your email, type quit.

######End postfix.memo #######
######Endmemoof postfix.memo #######
######Startmemoof sftp-server.memo #######
######Start sftp-server.memo #######
--10 server end 
#server on centos 7.3 azure
##This can use sftp but not ssh login
###Reference https://www.howtoforge.com/tutorial/how-to-setup-an-sftp-server-on-centos/

####MUST PATT owner and permission##########
##and /etc/passwd home dir && /etc/ssh/sshd_config ##
############################################
$> groupadd sftp-group 
$> useradd -g sftp-group -d /home/sftp-user -s /sbin/nologin sftp-user 
$> passwd sftp-user 

$> ll -d /home/
drwxr-xr-x 4 root root 4096 May 31 14:32 /home/
$> ll -d /home/sftp-user/ 
drwxr-xr-x 3 sftp-user sftp-group 4096 May 31 15:15 /home/sftp-user/
$> ll -d /home/sftp-user/data/
drwxr-xr-x 3 sftp-user sftp-group 4096 May 31 15:15 /home/sftp-user/data/

$> cat /etc/passwd |grep sftp-data
sftp-user:x:1005:1006::/home/sftp-user:/sbin/nologin
$> id  sftp-user
uid=1005(sftp-user) gid=1006(sftp-group) groups=1006(sftp-group)

$> grep -A 3 sftp-group /etc/ssh/sshd_config 
......
Subsystem sftp internal-sftp
......
Match group sftp-group
    ChrootDirectory /home 
    ForceCommand internal-sftp
    PasswordAuthentication yes

$> systemctl restart sshd 

--20 client
~> sftp -P Your_port shahrilk@ip_or_dns_name
shahrilk@ip_or_dns_name's password: 
Connected to ip_or_dns_name.
sftp> ls
upload  
sftp> cd upload
sftp> put demo.py
Uploading demo.py to /upload/demo.py
demo.py             100%  423     0.4KB/s   00:00    
sftp> cd /tmp
Couldn't canonicalize: No such file or directory
sftp> ls
demo.py  ip.txt   


~> ssh -p Port shahrilk@ip_or_dns
shahrilk@ip_or_dns's password: 
Could not chdir to home directory /data/shahrilk/upload: No such file or directory
This service allows sftp connections only.
Connection to ip_or_dns closed.
######End sftp-server.memo #######
######Endmemoof sftp-server.memo #######
######Startmemoof rabbitmq-server.memo #######
######Start rabbitmq-server.memo #######
install rabbitmq on centos centOs6.7/7.3

##step 10
rpm -ivh erlang-18.3-1.el6.x86_64.rpm

##step 20 way 1,maybe failure
wget –no-cache http://www.convirture.com/repos/definitions/rhel/6.x/convirt.repo -O /etc/yum.repos.d/convirt.repo
yum install socat

##step 20 way 2
wget http://www.dest-unreach.org/socat/download/socat-1.7.0.1.tar.gz
tar -zxvf socat-1.7.0.1.tar.gz && cd socat-1.7.0.1
./configure --disable-fips && make && make install

--???need these???
yum -y install epel-release
rm -f /etc/yum.repos.d/ep*
yum -y install socat


##step 30
rpm -ivh rabbitmq-server-3.6.6-1.el6.noarch.rpm

##step 40
service rabbitmq-server start
or
systemctl enable rabbitmq-server && systemctl start rabbitmq-server

##step 50
rabbitmq-plugins enable rabbitmq_management
rabbitmqctl add_user admin 123456
rabbitmqctl set_user_tags admin administrator
rabbitmqctl set_permissions -p "/" admin "." "." ".*"

##step 60
rabbitmqctl --help
service iptables stop
setenforce 0

http://ip:15672
user admin
pw 123456

##step 70

$>ss -tlnp|grep 5672
LISTEN     0      128          *:15672                    *:*                   users:(("beam.smp",pid=39937,fd=54))
LISTEN     0      128          *:25672                    *:*                   users:(("beam.smp",pid=39937,fd=43))
LISTEN     0      128         :::5672                    :::*                   users:(("beam.smp",pid=39937,fd=53))


###security access management protal
ssh -NCfqL 15672:localhost:15672 user@rabbit-server
http://127.0.0.1:15672


参考：(注意参考资料中的中文字符和命令正确性，查看官网更高效)

https://www.rabbitmq.com/management.html
http://blog.csdn.net/zhu_tianwei/article/details/40832185
FAQ http://blog.csdn.net/qq315737546/article/details/53105418
RPM安装
http://blog.csdn.net/zhu_tianwei/article/details/53572604

######End rabbitmq-server.memo #######
######Endmemoof rabbitmq-server.memo #######
######Startmemoof linux.memo #######
######Start linux.memo #######

##########centos install iftop####
$>yum install -y epel-release
$>yum install -y iftop

$>iftop -n -P -o 10 ##-o 10 IntervalBy 10s,-P pid -n no-dns-lookup
##########centos install iftop####
####php nginx opt###
$>cat /usr/local/nginx/conf/nginx.conf
......
 location ~ \.php$ {
            root           html;
            proxy_set_header Host $host;
            proxy_set_header            X-Forwarded-For    $proxy_add_x_forwarded_for;
            proxy_set_header X-Real-IP $remote_addr;
            fastcgi_pass   127.0.0.1:9000;
            fastcgi_index  index.php;
            fastcgi_param  SCRIPT_FILENAME  /path/2/$fastcgi_script_name;
            include        fastcgi_params;
            fastcgi_connect_timeout 60;    #####from here to end
            fastcgi_send_timeout 180;
            fastcgi_read_timeout 180;
            fastcgi_buffer_size 128k;
            fastcgi_buffers 256 16k;
            client_body_buffer_size 1024k;    
    }
......

$> cat php.ini 
memory_limit = 512M  ####default is 128M,assign as much as you need

####php nginx opt###



#####cggroup resource restrict###########
$>  cat /usr/lib/systemd/system/mongod.service
[Unit]
......

[Service]
CPUShares=2048            ####default is 1024
MemoryLimit=1G
BlockIOWeight=500        ####valid from 10 to 1000?
......

#####cggroup resource restrict###########

ln -s /usr/local/mongod/bin/* /bin 

#####lsof##########
##list Michael's bash command 
$> lsof -c bash -u Michael -a
COMMAND   PID    USER   FD   TYPE DEVICE  SIZE/OFF      NODE NAME
bash    34695 Michael  cwd    DIR  253,0      4096  67549910 /home/Michael
bash    34695 Michael  rtd    DIR  253,0      4096       192 /
bash    34695 Michael  txt    REG  253,0    960472  34538199 /usr/bin/bash
bash    34695 Michael  mem    REG  253,0 106070960  67169099 /usr/lib/locale/locale-archive
bash    34695 Michael  mem    REG  253,0     62184  67881687 /usr/lib64/libnss_files-2.17.so

##list Michael's or bash command
$> lsof -c bash -u Michael

##list TCP listen 
$> lsof -i :22
COMMAND   PID    USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME
sshd    34686    root    3u  IPv4 12012985      0t0  TCP Srv:22->client:59416 (ESTABLISHED)
sshd    34691    root    3u  IPv4 12014314      0t0  TCP Srv:22->client:59426 (ESTABLISHED)
sshd    34694 Michael    3u  IPv4 12012985      0t0  TCP Srv:22->client:59416 (ESTABLISHED)
sshd    34721 Michael    3u  IPv4 12014314      0t0  TCP Srv:22->client:59426 (ESTABLISHED)
sshd    52535    root    3u  IPv4 14630580      0t0  TCP *:ssh (LISTEN)
sshd    52535    root    4u  IPv6 14630582      0t0  TCP *:ssh (LISTEN)

$> lsof -i @client-ip-address(i.e 192.168.1.3)
COMMAND   PID    USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME
sshd    34686    root    3u  IPv4 12012985      0t0  TCP Srv:22->client:59416 (ESTABLISHED)
sshd    34691    root    3u  IPv4 12014314      0t0  TCP Srv:22->client:59426 (ESTABLISHED)
sshd    34694 Michael    3u  IPv4 12012985      0t0  TCP Srv:22->client:59416 (ESTABLISHED)
sshd    34721 Michael    3u  IPv4 12014314      0t0  TCP Srv:22->client:59426 (ESTABLISHED)
#####lsof##########


#####strace##########
strace -f -r -s 30 -o debug.log  -e trace=file \
 /path/2/cmd -f /path/2/conf --args 

-f follow forks
-r relative time 
-s char number 
-e trace filter
-o save to file 

PATT:exec native cmd instead service or systemctl
to get more exactly info
#####strace##########

###Centos 7 opt####
--10 set somaxconn
#> sysctl -a|grep somaxconn
net.core.somaxconn = 32768

#> grep -v '#' /etc/sysctl.conf 
net.core.somaxconn=32768
net.ipv4.tcp_tw_recycle=1
net.ipv4.tcp_tw_reuse=1 

--20 set open files
#> cat /etc/security/limits.conf |grep -v '#'

*              hard     nofile        4096
*              soft     nofile        4096

###Centos 7 opt####

####sed and vim regex#####
--05 sed cmd  
sed -En 's/(12|34|56)(abc){1,3}[a-d]/num/p' 
()represented group
[]represented list
{}represented repeat

vim extended regex mode
--10 vim cmd

:%s:\v(12|34)(abc){1}[a-d]:NumB:g
  key is \v represented extended mode 
--20
orgin
  1 12abcd1
  2 34abcabce2
  3 56abcabcabcd3
  4 34abcabce4
  5 56abcabcabc1    
--30
processed
  1 NumB1
  2 NumBbce2
  3 56abcabcabcd3
  4 NumBbce4                                                                                                                
  5 56abcabcabc1


vim zero-width assertions
:help \@
\@=     Matches the preceding atom with zero width. {not in Vi}
        Like "(?=pattern)" in Perl.
        Example                 matches  
        foo\(bar\)\@=           "foo" in "foobar"
        foo\(bar\)\@=foo        nothing

---link: https://quickteckiteasy.blogspot.com.au/2011/06/vim-search-with-zero-width.html
\@=   Zero-width positive look ahead assertion 
\@!   Zero-width negative look ahead assertion
\@<=  Zero-width positive look behind assertion
\@<!  Zero-width negative look behind assertion

--100 orgin
  7 xxxyyy                                                                                                                  
  8 yyyxxx
  9 xxx yyy
 10 yyy xxx
 11 xxxyyyxxx
 12 yyyxxxyyy

--110   
vim-cmd  %s:xxx\(yyy\)\@=:3x-Followed-3y:g

Result:

  7 3x-Followed-3y-yyy
  8 yyyxxx
  9 xxx yyy
 10 yyy xxx
 11 3x-Followed-3y-yyyxxx
 12 yyy-3x-Followed-3y-yyy  

--120
vim-cmd  %s:xxx\(yyy\)\@!:3x-not-Followed-3y:g

Result:

  7 xxxyyy
  8 yyy-3x-not-Followed-3y
  9 3x-not-Followed-3y yyy
 10 yyy 3x-not-Followed-3y
 11 xxxyyy-3x-not-Followed-3y                                                                                            
 12 yyyxxxyyy


--100 orgin
  7 xxxyyy                                                                                                                  
  8 yyyxxx
  9 xxx yyy
 10 yyy xxx
 11 xxxyyyxxx
 12 yyyxxxyyy

--130 
vim-cmd  %s:\(yyy\)\@<!xxx:3x-NotPrecededWith-3y:g

Result:

  7 3x-NotPrecededWith-3y-yyy
  8 yyyxxx
  9 3x-NotPrecededWith-3y yyy
 10 yyy 3x-NotPrecededWith-3y
 11 3x-NotPrecededWith-3y-yyyxxx                                                                                                 
 12 yyyxxxyyy

--140
vim-cmd  %s:\(yyy\)\@<=xxx:3x-PrecededWith-3y:g

Result:

  7 xxxyyy
  8 yyy-3x-PrecededWith-3y
  9 xxx yyy
 10 yyy xxx
 11 xxxyyy-3x-PrecededWith-3y
 12 yyy-3x-PrecededWith-3y-yyy    

####sed and vim regex#####

######去掉windows下的回车符（^M 写法 ^M 是回车换行符,先CTRL+v,松开v,按m)
1)sed -i 's/^M//g' filename

2) 在vim下类似(probably not take effect yet)

:%s/^M//g
######去掉windows下的回车符（^M 写法 ^M 是回车换行符,先CTRL+v,松开v,按m)



#######linux add to Windows AD#######
--05 set dns server
at /etc/resolv.conf 
nameserver 172.16.1.1   ###172.16.1.1 is your AD DNS server 
nameserver 8.8.8.8      ###public DNS server

--10 install package
#>yum -y install adcli sssd authconfig

--20 setup logon auth to AD
#>authconfig --enablesssd \
--enablesssdauth \
--enablemkhomedir \
--update

--30 add to domain (MUST domain Admin user) ##Your_password can used by "$x" in shell script  
echo -n 'Your_passw0$d'|adcli join --login-user=domain_admin domain.name --stdin-password

--40 vim /etc/sssd/sssd.con
[sssd]
domains = domain.name 
config_file_version = 2
services = nss, pam
[domain/domain.name]
ad_domain = domain.name
krb5_realm = domain.name
realmd_tags = manages-system joined-with-samba
cache_credentials = True
id_provider = ad
krb5_store_password_if_offline = True
default_shell = /bin/bash
ldap_id_mapping = True
use_fully_qualified_names = False
fallback_homedir = /home/%d/%u
access_provider = ad

--50 setup sssd.conf permissions
#>chmod 600 /etc/sssd/sssd.conf 

--60 start sssd
service sssd start /systemctl start sssd
chkconfig --add sssd && chkconfig sssd on /systemctl enable sssd
 
--70 check 
#>id domain\\user

uid=985001104(user) gid=985000513(domain users) groups=985000513(domain users),985000512(domain admins)

#######linux add to Windows AD#######


####here documented in bash script#######
--10 bash script  
#> cat change-user-password.sh 
#!/bin/bash
cat <<eof|passwd $1
$2
$2
eof

--20 call 
#> sh -x change-user-password.sh zhang bcd-pa
+ cat
+ passwd zhang
Changing password for user zhang.
New password: BAD PASSWORD: The password is shorter than 7 characters
Retype new password: passwd: all authentication tokens updated successfully.

####here documented in bash script#######


########How to create and format a partition using a bash script?
Similar to the previous suggestions, piping commands to fidsk, I've found 
this approach useful to leave details for subsequent maintainers. The sed
bits strip off all the comments before fdisk gets the input.

# to create the partitions programatically (rather than manually)
# we're going to simulate the manual input to fdisk
# The sed script strips off all the comments so that we can 
# document what we're doing in-line with the actual commands
# Note that a blank line (commented as "defualt" will send a empty
# line terminated with a newline to take the fdisk default.
sed -e 's/\s*\([\+0-9a-zA-Z]*\).*/\1/' << EOF | fdisk ${TGTDEV} ###here documented 
  o # clear the in memory partition table
  n # new partition
  p # primary partition
  1 # partition number 1
    # default - start at beginning of disk 
  +100M # 100 MB boot parttion
  n # new partition
  p # primary partition
  2 # partion number 2
    # default, start immediately after preceding partition
    # default, extend partition to end of disk
  a # make a partition bootable
  1 # bootable partition is partition 1 -- /dev/sda1
  p # print the in-memory partition table
  w # write the partition table
  q # and we're done
EOF

############https://superuser.com/questions/332252/how-to-create-and-format-a-partition-using-a-bash-script

############Linux script with curl to check webservice is up 
link:https://stackoverflow.com/questions/12747929/linux-script-with-curl-to-check-webservice-is-up
curl -sL -w "%{url_effective} %{remote_ip} %{http_code}\\n" "http://www.google.com/" -o /dev/null

    -s = Silent cURL's output
    -L = Follow redirects
    -w = Custom output format
    -o = Redirects the HTML output to /dev/null

Example:

[~]$ curl -sL -w "%{url_effective} %{remote_ip} %{http_code}\\n" "http://www.google.com/" -o /dev/null
https://www.google.com 1.2.3.4 200

I would probably remove the \\n if I were to capture the output.



Also of note: the \\n (escaped backslash) is only required if you're using bash as your shell interactively, but
if you put this in a script OR you use tcsh you should use \n instead. This is a quoting issue; the command line 
works the same in both shells, interactively and in scripts if you use single quotes instead, 
à la: '%{http_code}\n' Probably best for consistency to use that instead.



############Linux script with curl to check webservice is up 


#####non-greedy and backreference in vim ########
--10 orgin text 
%network-add %network-mask 
%public-interface% and mask                                                                                                                                                          

--20 processed text      
%network-add% %network-mask% 
%public-interface% and mask                                                                                                                                                               

--30 vim command 
1,2s:\(%.\{-}\)\s:\1% :g


--40 explain 
1,2 Execute lines 
s:replace meta char

\(%.\{-}\)\s:\1%  replace begin with % after some char with first space to those staff add % 
\(\)  is backreference define \1 is reference
.\{-} is non-greedy match 

#####non-greedy and backreference in vim ########

####sed append newline after some pattern
#---10 here append set -u AFTER #!/bin/bash
sed -i 's:#!/bin/bash:#!/bin/bash\nset -u:g' somefile
####sed append newline after some pattern

####bash shell safe 
set -u  ###Meaning if some undefine while being call will exit shell
####that protect some accident 
####bash shell safe


####sed tip
replace all abc to def of files in current path 
$>find ./ -type f|xargs -t -P 1 -n 1 -i sed -i 's:abc:def:g'

append multiple line after pattern
$>sed -i "/abc/aI-add-three\nline\n\'s" files

insert multiple line before pattern
$>sed -i "/abc/iI-add-three\nline\n\'s" files
####sed tip


#######install crontab on centos 6/7
Link:https://stackoverflow.com/questions/21802223/how-to-install-crontab-on-centos
As seen in Install crontab on CentOS, the crontab package in CentOS is vixie-cron. Hence, do install it with:

yum install vixie-cron
And then start it with:

service crond start
To make it persistent, so that it starts on boot, use:

chkconfig crond on
On CentOS 7 you need to use cronie:

yum install cronie
On CentOS 6 you can install vixie-cron, but the real package is cronie:

yum install vixie-cron
and

yum install cronie
In both cases you get the same output:

.../...
==================================================================
 Package         Arch       Version         Repository      Size
==================================================================
Installing:
 cronie          x86_64     1.4.4-12.el6    base             73 k
Installing for dependencies:
 cronie-anacron  x86_64     1.4.4-12.el6    base             30 k
 crontabs        noarch     1.10-33.el6     base             10 k
 exim            x86_64     4.72-6.el6      epel            1.2 M

Transaction Summary
==================================================================
Install       4 Package(s)
As seen in Install crontab on CentOS, the crontab package in CentOS is vixie-cron. Hence, do install it with:

$>yum install vixie-cron
And then start it with:

service crond start
To make it persistent, so that it starts on boot, use:

$>chkconfig crond on
On CentOS 7 you need to use cronie:

$>yum install cronie
On CentOS 6 you can install vixie-cron, but the real package is cronie:

$>yum install vixie-cron
and

$>yum install cronie
In both cases you get the same output:

.../...
==================================================================
 Package         Arch       Version         Repository      Size
==================================================================
Installing:
 cronie          x86_64     1.4.4-12.el6    base             73 k
Installing for dependencies:
 cronie-anacron  x86_64     1.4.4-12.el6    base             30 k
 crontabs        noarch     1.10-33.el6     base             10 k
 exim            x86_64     4.72-6.el6      epel            1.2 M

Transaction Summary
==================================================================
Install       4 Package(s)

#######install crontab on centos 6/7






###find out the biggest file in current folder (exclude .snapshots)
find . -name .snapshots -prune -o -type f -print0 2>/dev/null |xargs -0 du 2>/dev/null |sort -nr|head -n 1
###find out the biggest file in current folder

#####grep or#####
1 grep -E 'condition1|condition2' some-text
2 grep 'condition1\|condition2' some-text
#####grep or#####

####detect ssh tunnel failed restart ssh shell

#!/bin/bash
if  curl -IL hostname.example.com|grep "Bad Gateway"
then
        ssh -R external-port:internal-ip:internal-port -N -q -f -C -i rsa-key ssh-tunnel-user@external-ip-or-domain
fi

####detect ssh tunnel failed restart ssh shell


####get date from timestamp
# date -d @1267619929
Wed Mar  3 07:38:49 EST 2010
####get timestamp from date
> date -d '2012-03-22 22:00:05 EDT' +%s
1332468005
> date +%s
1519889699



####get endpoint automated
$>cat vm.txt
1 vm1
2 vm2

$>awk '{print $2}' vm.txt |xargs -t -P 1 -n 1 -i  azure vm endpoint list {} &>endpoint
####get endpoint automated





####find out Linux: Most recent file in a directory
It seems that ls doesn't sort the files correctly when doing a recursive call:
$>ls -Art | tail -n 1

or

https://stackoverflow.com/questions/4561895/how-to-recursively-find-the-latest-modified-file-in-a-directory
$>find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d" "

For a huge tree, it might be hard for sort to keep everything in memory.
%T@ gives you the modification time like a unix timestamp, sort -n sorts numerically, tail -1 takes the last line (highest timestamp), cut -f2 -d" " cuts away the first field (the timestamp) from the output.
Edit: Just as -printf is probably GNU-only, ajreals usage of stat -c is too. Although it is possible to do the same on BSD, the options for formatting is different (-f "%m %N" it would seem)
And I missed the part of plural; if you want more then the latest file, just bump up the tail argument.
####find out Linux: Most recent file in a directory





####ssh tunnel with security
1 add user without sudo
2 ssh_config AllowUser sombody@some_specific_IP and other user AllowUser otheruser@*
3 client upload  rsa key to this user/ssh-copy-id -i someRSA somebody@server 
4 usermod -s /sbin/nologin
5 systemctl restart sshd/service sshd restart

6
AutoRestart on Crontab
# cat /etc/custom-scripts/auto-restart-ssh-tunnel.sh 
#!/bin/bash
if ! ps -ef |grep [5]618 2>&1 >/dev/null
##PATT 5618 MUST THE WHOLE FIELD,IF USE [5]61,WILL GET WRONG RESULT??
then

    ssh -p 5618 -i .ssh/your-rsa -NCfqL 23306:localhost:3306 somebody@server
fi

7
 verify on centos 6.5

####ssh tunnel with security


####route persist
持久化：（自定义路由出接口时172.16.0.11，172.16.0.12）
Option 1, include the below in /etc/sysconfig/network-scripts/route-eth0 file: –

GATEWAY0=172.16.0.11
NETMASK0=255.255.255.0
ADDRESS0=192.168.1.0

GATEWAY1=172.16.0.12
NETMASK1=255.255.255.0
ADDRESS1=10.20.30.0

下面这个更简单
Option 2, include the below in /etc/sysconfig/network-scripts/route-eth0 file: –
192.168.1.0/24 via 172.16.0.11 dev eth0
10.20.30.0/24 via 172.16.0.12 dev eth0

####route persist



###########OpenSSH Change a Passphrase With ssh-keygen command

 ssh-keygen -f id_dsa -p

###########OpenSSH Change a Passphrase With ssh-keygen command


#############################
#stress test memory cpu disk#
#############################
##############################
1) yum install stress

2) stress-ng --cpu 4 --io 2 --vm 1 --vm-bytes 1G --timeout 60s




#############################
#stress test memory cpu disk#
#############################



#####ssh/config example######
ForwardAgent yes                                                                          
ControlMaster auto
ControlPath /tmp/ssh_mux_%h_%p_%r

Host                  prefix-hostname1
Hostname              4.19.14.4
User                  username
Port                  6001
IdentityFile          ~/privity-key

Host                  prefix2-hostname2
Hostname              192.168.2.16
User                  username  
IdentityFile          ~/privity-key-2

Host                  prefix-hostname3
Hostname              example.cn  
Port                  3021
User                  username
IdentityFile          ~/privity-key


connect example:
$>ssh prefix-hostname1
##############################
#####.ssh/config example######

###Linux inital install
install and config tmux
install and config screen
instll gcc gcc++ autoconf automake 
install and config zabbix_client
install and config lsyncd
config timezone
config backup
config opt file-system tcp stack
config python ansible lib
config vimrc
config bashrc
config sshd_config
config ssh_key
config yum repo
yum update
install nc
reboot

###Linux inital install

####top tips
3. Display Specific User Process  
$ top -u tecmint
5. Display All CPUs / Cores in the Top Output – Press 1 (one)Top output by default shows CPU line for all the CPUs combined together as shown below

6. Refresh Unix Top Command Output On demand (or) Change Refresh IntervalBy default, linux top command updates the output every 3.0 seconds. When you want to update the output on-demand, press space bar.

7. Highlight Running Processes in the Linux Top Command Output – Press z or bPress z or b, which will highlight all running process as shown below.

13. Decrease Number of Processes Displayed in Top Output – Press nPress n in the Interactive mode, which prompts for a number and shows only that. Following example will display only 2 process as a time.



To display the top 15 processes sorted by memory use in descending order, do:
$ top -b -o +%MEM | head -n 22
As opposed to the previous tip, here you have to use +%MEM (note the plus sign) to sort the output in descending order:
From the command above, the option:

	1. -b : runs top in batch mode
	2. -o : used to specify fields for sorting processes
	3. head utility displays the first few lines of a file and
	4. the -n option is used to specify the number of lines to be displayed.


####top tips








############server opt 优化 系统 TCP/IP栈 内存 文件
From here https://tweaked.io/guide/kernel/
Practice https://www.researchgate.net/publication/267253313_Tuning_the_Linux_Kernel

File Handle LimitsWhen you're serving a lot of traffic it is usually the case that the traffic you're serving is coming from a large number of local files.
The kernel has built-in limits on the number of files that a process can open, and raising these limits, at a cost of some system memory, is usually a sane thing to attempt.
You can view the current limit on the number of open-files by running:
$ cat /proc/sys/fs/file-max

The limit can be raised interactively by running, as root:
# sysctl -w fs.file-max=100000

If you wish that change to be made persistently you should append to the file /etc/sysctl.conf the line:
fs.file-max = 100000

Then run the following command to make your change take effect:
# sysctl -p

Socket TuningFor servers which are handling large numbers of concurent sessions, there are some TCP options that should probabaly be tweaked.
With a large number of clients comnunicating with your server it wouldn't be unusual to have a 20,000 open sockets or more. To increase that range you append the following to the bottom of /etc/sysctl.conf:
# Use the full range of ports.
net.ipv4.ip_local_port_range = 1024 65535

You can also increase the recycling time of sockets, avoiding large numbers of them staying in the TIME_WAIT status by adding these values to /etc/sysctl.conf:
# Enables fast recycling of TIME_WAIT sockets.
# (Use with caution according to the kernel documentation!)
net.ipv4.tcp_tw_recycle = 1

# Allow reuse of sockets in TIME_WAIT state for new connections
# only when it is safe from the network stack’s perspective.
net.ipv4.tcp_tw_reuse = 1

Finally one problem you'll find is that if a socket is listening and busy a connection-backlog will pile up. The kernel will keep pending connections in a buffer before failing. You can tweak several values to increase the size of the backlog:
#
# 16MB per socket - which sounds like a lot, but will virtually never
# consume that much.
#
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216

# Increase the number of outstanding syn requests allowed.
# c.f. The use of syncookies.
net.ipv4.tcp_max_syn_backlog = 4096
net.ipv4.tcp_syncookies = 1

# The maximum number of "backlogged sockets".  Default is 128.
net.core.somaxconn = 1024

The trade-off here is that a connecting client will see a slow connection, but this is almost certainly better than a Connection Refused error.
Once you've made those additions you can cause them to be loaded by running:
# sysctl -p

Finally if you've changed these limits you will need to restart the associated daemons. (For example "service nginx restart".)
Process SchedulerIf you're running a recent ( newer than approx 2.6.32) you've got the 'Completely Fair Scheduler' (CFS) For modern systems serving lots of connections on lots of cores, you may hit issues with process migration.
There's a kernel parameter that determines how long a migrated process has to be running before the kernel will consider migrating it again to another core. The sysctl name is sched_migration_cost_ns, default value 50000 (that's ns so 0.5 ms):
$ cat /proc/sys/kernel/sched_migration_cost_ns

(It was renamed from sched_migration_cost at some point between 3.5 and 3.8)
Forking servers, like PostgreSQL or Apache, scale to much higher levels of concurrent connections if this is made larger, by at least an order of magnitude:
The limit can be raised interactively by running, as root:
# sysctl -w kernel.sched_migration_cost_ns=5000000

If you wish that change to be made persistently you should append to the file /etc/sysctl.conf the line:
kernel.sched_migration_cost_ns = 5000000

Another parameter that can dramatically impact forking servers is sched_autogroup_enabled. This setting groups tasks by TTY, to improve perceived responsiveness on an interactive system. On a server with a long running forking daemon, this will tend to keep child processes from migrating away as soon as they should. It can be disabled like so:
# sysctl -w kernel.sched_autogroup_enabled=0

Various PostgreSQL users have reported (on the postgresql performance mailing list) gains up to 30% on highly concurrent workloads on multi-core systems.
If you wish that change to be made persistently you should append to the file /etc/sysctl.conf the line:
kernel.sched_autogroup_enabled = 0

Then run the following command to make your change take effect:
# sysctl -p

Filesystem TuningYou almost certainly want to disable the "atime" option on your filesystems.
With this disabled that the last time a file was accessed won't be constantly updated every time you read a file, since this information isn't generally useful inand causes extra disk hits, its typically disabled.
To do this, just edit /etc/fstab and add "notime" as a mount option for the filesystem. For example:
    /dev/rd/c0d0p3          /test                    ext3    noatime        1 2

############server opt



##########
echo "your-password" | passwd "your-user" --stdin

How to avoid being prompted for a password by sudo? [duplicate]


Note that this will produce an error if your sudo access token is active, if you don't need to enter your password because you've already done so recently. To get around that, you could use -k to reset the access token:

#######
echo 'password' | sudo -kS ls


　　使用 HISTCONTROL 强制 history 不记住特定的命令

　　将 HISTCONTROL 设置为 ignorespace，并在不想被记住的命令前面输入一个空格：

　　# export HISTCONTROL=ignorespace  可以使用ansible处理，处理后下次登录到服务器就生效  
    ansible sfwm -m lineinfile -a "dest=/etc/profile line='HISTCONTROL=ignorespace'" \
     -f your-fork-number -u your-user --become --ask-pass --ask-sudo-pass

####set bash mode 设置bash模式
set -o vi
set -o emacs


########xargs 替换参数位置start##########
#>cat ip.txt
1
201
3
11
#> cat ip.txt |xargs -t -P 1 -n 1 -i  ping -c 1 192.168.1.{}

PING 192.168.1.1 (192.168.1.1)
PING 192.168.1.201 (192.168.1.201)
。。。。。。
########xargs 替换参数位置End######




#######################################
#######################################
###使用parallel并行处理######
-k后面的’与end后面的’之间直接可以运行多个命令，这些命令使用；区格；这些命令使用-k强制执行顺序相同
To force the output in the same order as the arguments use --keep-order/-k:
  parallel -j64 -k 'printf "%s-start\n%s" {} {};
    sleep {};printf "%s\n" -middle;echo {}-end' ::: 4 2 1
Output:
  4-start
  4-middle
  4-end
  2-start
  2-middle
  2-end
  1-start
  1-middle
  1-end

--{} represented variables,after ::: the value of the variables list here--
$>time parallel -j8 -k 'ping -c 1 172.16.1.{}' ::: 10 20 118 136

Academic tradition requires you to cite works you base your article on.
......
To silence the citation notice: run 'parallel --bibtex'.

PING 172.16.1.10 (172.16.1.10) 56(84) bytes of data.

--- 172.16.1.10 ping statistics ---
1 packets transmitted, 0 received, 100% packet loss, time 0ms

PING 172.16.1.20 (172.16.1.20) 56(84) bytes of data.
From 172.16.1.156 icmp_seq=1 Destination Host Unreachable

--- 172.16.1.20 ping statistics ---
1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms

PING 172.16.1.118 (172.16.1.118) 56(84) bytes of data.
64 bytes from 172.16.1.118: icmp_seq=1 ttl=128 time=0.585 ms

--- 172.16.1.118 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.585/0.585/0.585/0.000 ms
PING 172.16.1.136 (172.16.1.136) 56(84) bytes of data.
64 bytes from 172.16.1.136: icmp_seq=1 ttl=128 time=1.13 ms

--- 172.16.1.136 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 1.138/1.138/1.138/0.000 ms

real    0m10.346s
user    0m0.294s
sys     0m0.139s



重定向错误到/dev/null
# time cat pl.txt |parallel -j 8 2>/dev/null 'echo -n "{} " ;curl -X GET -IL {}|grep HTTP'







####ping 172.16.21.1--11 success return 0;Failure return 1 
seq 1 11 | parallel -j 32 -k 'ping -c 1 172.16.21.{} &>/dev/null && echo 0 || ech
o 1'
Academic tradition requires you to cite works you base your article on.
When using programs that use GNU Parallel to process data for publication
please cite:

  O. Tange (2011): GNU Parallel - The Command-Line Power Tool,
  ;login: The USENIX Magazine, February 2011:42-47.

This helps funding further development; and it won't cost you a cent.
If you pay 10000 EUR you should feel free to use GNU Parallel without citing.

To silence the citation notice: run 'parallel --bibtex'.

0
1
0
1
1
0
1
1
0
0
1

####ping 172.16.21.1--11 success return 0;Failure return 1 


GNU Parallel tutorial 精华 验证

man parallel_tutorial 手册

###使用parallel并行处理######
#######################################
######################################







#### ping youSite 端口80 直到成功才退出 #######

cat continue-test.sh
while true
    do
        nc -vz youSite.com 80 >/dev/null 2>&1 && break;
    done

====##command line run
while true; do nc -vz ip-or-domain port >/dev/null 2>&1 && break; done
====###exit until failed
while true; do nc -vz ip-or-domain port >/dev/null 2>&1 || break; done

#### ping youSite 直到成功才退出 #######

#########vimrc###########
###########
$ cat .vimrc
set smartindent
set pastetoggle=<f5>
syntax enable
set tabstop=4
set softtabstop=4
set expandtab
set number
set showcmd
set cursorline
filetype indent on
set wildmenu
set showmatch
######

.vimrc 黏贴时先按F5
set pastetoggle=<f5>

or
:set paste
in vim

黏贴不自动indent
#########vimrc end########

##############SED 区间操作START############
##delete between #start and #stop
shell> sed -i '/#start/,/#stop/ d' someScript

##BEFORE DELETE
shell> cat someScript
#!/bin/bash
export
PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/bin
yum -y install ncurses-devel gcc gcc++ autoconf automake
/bin/mkdir -p /usr/local/screen
#start
/bin/tar zxf /tmp/screen.tar.gz -C /usr/local/screen
cd /usr/local/screen/v.4.3.1/src
./autogen.sh
./configure
make
#stop
rm /usr/bin/screen -f
ln -s /usr/local/screen/v.4.3.1/src/screen /usr/bin/screen

###AFTER DELETE
shell> cat someScript
#!/bin/bash
export
PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/bin
yum -y install ncurses-devel gcc gcc++ autoconf automake
/bin/mkdir -p /usr/local/screen
##############SED 区间操作END##############

侦测新网卡/虚拟机迁移后网卡变化解决处理
https://superuser.com/questions/332593/how-do-you-automatically-detect-a-new-network-card-in-centos-6-redhat

With CentOS 6 everthing is handled by udev now. Go into /etc/udev/rules.d and delete the 70-persistent-net.rules file and reboot. If you open it berfore hand you will most likey see the original NIC MAC listed as eth0 and the new one as eth1.

Now you need to edit /etc/sysconfig/network-scripts/ifcfg-eth0 and manually update to the MAC of your new NIC card.

Deleting the file forces the detection process to run again at boot with no baggage left over from the cloning process, namely the old NIC MAC address(es).

I have to do it with my CentOS 6 clones on VMware ESXi 4.1 all the time. It's a pain kudzu would just handle it in the past with previous versions.
编辑 /etc/udev/rules.d/70-persistent-net.rules 这个文件符合实际情况，然后重启。CentOS6.5验证成功。

CentOS6.5

####audit input审计键盘输入####
前提需要保证auditd服务处于运行状态
/etc/pam.d/system-auth添加下面这行
session required pam_tty_audit.so enable=*
在/etc/audit/audit.rules中加入
In /etc/audit/audit.rules we need to ensure that the following exists.

-a exit,always -F arch=b64 -S execve
-a exit,always -F arch=b32 -S execve
使用下面的方式查看
ausearch  -ui 502 -i    ##502是用户ID
ausearch -ui 501  -i |grep EXECVE -A 2 -B 2 --color

 重新登录使用下面的方式查看
ausearch -m tty -i  ###过时？
azure centos 6.X成功
####audit input审计键盘输入####

########selinux排除故障#####
#安装文件
$yum install setroubleshooot setools

#分析得到的结果
$sealert -a /var/log/audit/audit.log

给selinux权限，持久化？
$semanage fcontext -a -t

#还原上面给的权限
$ restorecon -v

########selinux排除故障END#####

#########selinux持久化####

- Run the semanage fcontext -a options file-name|directory-name command, remembering to use the full path to the file or directory.  ##新增

- Run the restorecon -v file-name|directory-name command to apply the context changes.  ##生效

-  semanage fcontext -d "/web(/.*)?"  删除

semanage未安装 not found centos 6.x
yum install policycoreutils-python
系统安装sealter
yum install setroubleshoot setools
#########selinux持久化####

#########bash and expect###########
#!/bin/bash
Scp_ip()
{
cat /root/app.txt | while read line
do
(
   /usr/bin/expect << EOF
   set time 20
   spawn scp /root/apache-tomcat-7.0.75.tar.gz root@$line:/root/
   expect {
        "*yes/no*"
          { send "yes\r";exp_continue }
        "*password:"
          { send "Lh##U1H9Q"{}()\r"}
   }
   expect eof
EOF
) &>/dev/null

   if [ $? -eq 0 ]
   then
       echo "复制文件到$line成功！"
   else
       echo "复制文件到$line失败！"
   fi
done
}
Scp_ip

#########bash and expectEND#####

###AWK在bash script中调用bash变量#######
variable="line one\nline two"
awk -v var="$variable" 'BEGIN {print var}'
line one
line two
###AWK在bash script中调用bash变量END####

文本操作关键命令

Get-ChildItem -Recurse .\ |Where-Object {$_.Mode -eq "-a---"}|%{certutil -hashfile $_.FullName md5}|Select-String -Pattern "CertUtil: -hashfile
命令成功完成" -NotMatch

sed -e 's/^CertUtil:.*$//g' -e ':a;N;$!ba;s/\n/ /g' -e 's/MD5 哈希(文件 /\n/g' -e 's/ CertUtil: -hashfile 命令成功完成。//g' -e 's/): /\n):/g' 1.txt|sed -r '/^\):/ s/\ //g' |sed -e 's/)://g' -e 's/^/"/' -e 's/$/"/' |sed -e ':a;N;$!ba;s/\n/ /g' -e 's/"C:/\n"C:/g'|awk '-F " {print $4,$2}
###注意Linux中使用双引号（”）作为文件名 的包含符号
###awk -F ‘"’使用双引号作为分隔符号
###sed的条件操作
###sed的正则操作-r
###sed -e 有时会出错，只能使用多级管道？？？？
处理前：
MD5 哈希(文件 C:\yoursite\d2b-8057-5df9269e072b-包装有.txt):
c7 c5 46 f3 a0 e7 38 d1 bd d9 cb bb fc b3 d6 5b
CertUtil: -hashfile 命令成功完成。
MD5 哈希(文件 C:\yoursite\2af-bc7d-55c0bdb189c3-Scan.pdf):
3c 66 ed 12 42 49 8c 90 80 d3 c3 56 35 e1 56 5b
CertUtil: -hashfile 命令成功完成。
MD5 哈希(文件 C:\yoursite\e0975c3d22f-Scan1.pdf):
fd ef cf fb 3b 04 9c ae 43 33 77 3b 96 12 fe d9
CertUtil: -hashfile 命令成功完成。

处理后：
c7c546f3a0e738d1bdd9cbbbfcb3d65b C:\yoursite\d2b-8057-5df9269e072b-包装有.txt
3c66ed1242498c9080d3c35635e1565b C:\yoursite\2af-bc7d-55c0bdb189c3-Scan.pdf
fdefcffb3b049cae4333773b9612fed9 C:\yoursite\e0975c3d22f-Scan1.pdf

###条件SED,注意s操作符号前面的空格 condition
sed '/conditional_pattern/ s/pattern/replacement/g'

####sed反向引用，需要新建SED管道，不能使用-e
####注意正则表达方式
cat 1.txt |sed -r
's/(^.*)(\): )(.*)(CertUtil.*)$/\1\3/g'

########awk系统调用system###########
###后面的命令和参数都需要使用双引号包含;
###只有AWK中的$n不需要使用双引号包含;
###下面的正常命令是grep $1 20.txt在awk中的调用方式;
###其中$1是awk中一行 的第一个字段。
awk '{md5[$2]++} END{ for (var in md5) print var,md5[var]}' 20.txt |awk
'$2!=2{system("grep " $1 " " "20.txt")}'

###操作文件的调用方法
awk '{system("mv -R " $1 " " $2)}' file.cfg
########awk系统调用system END###########

find + exec + mv 兼容空格
find . -type f -iname '*.cpp' -exec mv -t ./test/ {} \+
http://stackoverflow.com/questions/5607542/why-does-find-exec-mv-target-not-work-on-cygwin

-exec command ;

Execute command; true if 0 status is returned. All following arguments to find are taken to be arguments to the command until an argument consisting of `;' is encountered. The string `{}' is replaced by the current file name being processed everywhere it occurs in the arguments to the command, not just in arguments where it is alone, as in some versions of find. Both of these constructions might need to be escaped (with a `\') or quoted to protect them from expansion by the shell. See the EXAMPLES section for examples of the use of the -exec option. The specified command is run once for each matched file. The command is executed in the starting directory. There are unavoidable security problems surrounding use of the -exec action; you should use the -execdir option instead.

-exec command {} +

This variant of the -exec action runs the specified command on the selected files, but the command line is built by appending each selected file name at the end; the total number of invocations of the command will be much less than the number of matched files. The command line is built in much the same way that xargs builds its command lines. Only one instance of `{}' is allowed within the command. The command is executed in the starting directory.

这两个待测试
find ./ -name '*article*' -exec mv {}  ../backup  \;
find ./ -name '*article*' -exec mv {}  ../backup  \;

对于有特殊字符的情况，xargs不能正确处理，而find+exec可以 ，如下
#touch "ab c\\ \"'.txt"
注意后边有分号
# find ./ -maxdepth 1 -type f -exec rm -fv {} \;
已删除"./ab c\\ \"'.txt"
# touch "ab c\\ \"'.txt"
# find ./ -maxdepth 1 -type f -exec rm -fv {} \+
已删除"./ab c\\ \"'.txt"
# touch "ab c\\ \"'.txt"
# find ./ -maxdepth 1 -type f | xargs  rm -fv {} \+
xargs: 未匹配的 双 引用；默认情况下，引用是针对 xargs 的，除非您使用了 -0 选项

##########linux回车替换为空格############
$  echo "$string" | tr '\n' ' '
as others had pointed.
But if you want to convert new lines into spaces on a file using sed, then you
can use:
$ sed -i ':a;N;$!ba;s/\n/\t/g' file_with_line_breaks
or even awk:
$ awk '$1=$1' ORS=' ' file_with_line_breaks > new_file_with_spaces
e this solution with GNU sed:
sed ':a;N;$!ba;s/\n/ /g'
This will read the whole file in a loop, then replaces the newline(s) with a
space.

Explanation:
    Create a label via :a.
    Append the current and next line to the pattern space via N.
    If we are before the last line, branch to the created label $!ba ($! means
not to do it on the last line as there should be one final newline).
    Finally the substitution replaces every newline with a space on the pattern
space (which is the whole file).

Here is cross-platform compatible syntax which works with BSD sed (as per
@Benjie comment)
##tr的替换目标只能是单个字符？？
#########linux回车替换为空格END#########

###zabbixAgent with ssh Tunnel####
ssh -NCfqL 1000:localhost:10051 someone@ZbxServer -p 3000 -i ca
##上面1000Agent所在的本机端口，10051是zbxServer端口;
##someone@ZbxServer是登录到Server的用户和服务器地址;
##-p端口，-i证书
##ssh的参数和值之间只有一个空格，坑的很？
##为为避免和ZabbixServer的Agnet冲突，需要修改Agent的监听的端口到10060
##并且要在ZbxSrv端ssh Tunnel回到10060
ssh -NCfqL 10060:localhost:10060 someone@ZbxClinet -p 3000 -i ca1
##完成后修改zabbix_agentd.conf,ServerActive=127.0.0.1:1000
##然后启动zabbix_agentd就可以在服务端监控这台远程的Agent了
###zabbixAgent with ssh Tunnel End####

Zabbix磁盘监控指标:{Adan Linux CentOS 6:vfs.fs.size[{#FSNAME},pfree].last(0)}<20 and {Adan Linux CentOS 6:vfs.fs.size[{#FSNAME},free].last(0)}<4294967296

##########3.在以普通用户打开的VIM当中保存一个ROOT用户文件,VIM保存没有权限的文件##########

:w !sudo tee %

这题目读起来纠结，其实是很常见的，常常忘记了sudo就直接用vim编辑/etc内的文件，
（不过也不一定，vim发现保存的文件无法保存时候会提示）等编辑好了，保存时候才发现没权限。
曲线方法是先保存个临时文件，退出后再sudo cp回去。不过实际上在vim里面可以直接完成这个过程的，命令就是如此。

查阅vim的文档（输入:help :w），会提到命令:w!{cmd}，让vim执行一个外部命令{cmd}，然后把当前缓冲区的内容从stdin传入。

tee是一个把stdin保存到文件的小工具。

而%，是vim当中一个只读寄存器的名字，总保存着当前编辑文件的文件路径。

所以执行这个命令，就相当于从vim外部修改了当前编辑的文件，好完工。
###################END################################################

##########后项引用变量替换##################
:%s:\($[a-zA-Z]\+\):"\1":g 变量替换，由$var换为"$var"
:%s:"\($[a-zA-Z0-9]\+\)":\1:g   变量替换，由“$var”换为$var
##########后项引用变量替换END###############

##########detecv port status V4####################
cat /data/backup/detectServiceStatusV4.mon01.sh
#!/bin/bash
PATH="/usr/local/bin:/usr/bin:/bin"
export PATH
managedServiceFile="/data/backup/managedServiceListMon01"
logFile="/var/log/serviceStatusLogs/serviceStatusLog"
operationDate=$(date +%Y%m%d-%H%M)
echo -n "$operationDate:">"$logFile"
###每次的操作输入到一个文件，多个错误拼接到一行
while IFS= read -r managedServiceItem
do(
        if echo "$managedServiceItem"|grep '#' &>/dev/null
        then
           continue
        fi

        host=$(echo "$managedServiceItem"|awk '{print $1}')
        port=$(echo "$managedServiceItem"|awk '{print $2}')
        name=$(echo "$managedServiceItem"|awk '{print $3}')
        if ！ nc -w 2 "$host" "$port" < /dev/null &>/dev/null
        #if [ $? != 0 ];then
                echo -n "WRONG $name ">>"$logFile"
        fi)&
done <"$managedServiceFile"
wait
echo "">>"$logFile" ##打印换行
sed -i 's# WRONG##g' "$logFile"  ##删除多余的WRONG字符

##输出格式：2017xxxx：WRONG HOST1 HOST2  .....
##########detecv port status V4 END侦测端口开启状态 ####################

##########detecv port status V3侦测端口开启状态####################
##程序,变量做了双引号包含，避免意外的扩展，并把状态打印在第一个位置，方便阅读
#!/bin/bash
PATH="/home/Michael/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/games"
export PATH
managedServiceFile="/data/backup/managedServiceListMon01"
logFile="/var/log/serviceStatusLogs/serviceStatusLog"
operationDate=$(date +%Y%m%d-%H%M)

echo "">>"$logFile"
echo "$operationDate">>"$logFile"

while IFS= read -r managedServiceItem
do(
        if echo "$managedServiceItem"|grep '#' &>/dev/null
        then
           continue
        fi  ###如果配置行中有#，忽略该行

        host=$(echo "$managedServiceItem"|awk '{print $1}')
        port=$(echo "$managedServiceItem"|awk '{print $2}')
        name=$(echo "$managedServiceItem"|awk '{print $3}')
        nc -w 2 "$host" "$port" < /dev/null &>/dev/null
        if [ $? == 0 ];then
                echo OK "$name" "$operationDate">>"$logFile"
        else
                echo !!WRONG!! "$name" "$operationDate">>"$logFile"
        fi)&
done <"$managedServiceFile"
wait
##########detecv port status V3 END####################

######################detect port status V2####################
####程序文件
#!/bin/bash
managedServiceFile="mg.txt"
logFile="sb.txt"
operationDate=$(date +%Y%m%d-%H%M)

echo "">>"$logFile"
echo "$operationDate">>"$logFile"

while IFS= read -r managedServiceItem ##逐行读入处理
do(
        host=$(echo "$managedServiceItem"|awk '{print $1}')
        port=$(echo "$managedServiceItem"|awk '{print $2}')
        name=$(echo "$managedServiceItem"|awk '{print $3}')
        if  nc -w 2 "$host" "$port" < /dev/null &>/dev/null
        then
                echo "$name" is OK at "$operationDate">>"$logFile"
        else
                echo "$name" is Wrong at "$operationDate">>"$logFile"
        fi)&   ####后台处理，等待所有进程完成后才退出
done <"$managedServiceFile"
wait ####后台处理，等待所有进程完成后才退出

####配置文件
$cat mg.txt
172.16.10.156 22 bak01ssh
172.16.10.156 3306 bak01Mysql
172.16.10.156 80 bak01Nginx
172.16.10.156 8030 bak01Tomcat156-8080
172.16.10.13 3389 cdDC01RDP13-3389
41.1.24.41 5682 cloud-ssh-5682

####输出结果
$cat sb.txt

20170315-1049
bak01Mysql is OK at 20170315-1049
bak01Nginx is OK at 20170315-1049
bak01Tomcat156-8080 Wrong at 20170315-1049
bak01ssh is OK at 20170315-1049
Redis-ssh-56183 is OK at 20170315-1049
cdDC01RDP13-3389 is OK at 20170315-1049

20170315-1050
bak01Tomcat156-8080 Wrong at 20170315-1050
bak01Mysql is OK at 20170315-1050
bak01Nginx is OK at 20170315-1050
bak01ssh is OK at 20170315-1050
cloud-ssh-56183 is OK at 20170315-1050
cdDC01RDP13-3389 is OK at 20170315-1050
######################detect port status V2 END####################

######################detect port status探测端口状态#######################
$>cat detectServiceStatus.sh

#!/bin/bash
########变量值定义为ip，端口，服务描述,用于此后调用时候方便分离
cdbak01ssh="172.16.10.156 22 bak01ssh"
cdbak01db="172.16.10.156 3306 bak01Mysql"
cdbak01web="172.16.10.156 80 bak01Nginx"
cdbak01web2="172.16.10.156 8030 bak01Tomcat156-8080"
cddc01rdp="172.16.10.13 3389 cdDC01RDP13-3389"
log_file="sb.txt"
op_date=$(date +%Y%m%d-%H%M)
####注意引号的使用，特别是变量处理的时候
#######nc要使用 nc-1.84-24.el6.x86_64.rpm这个版本，CentOS7 yum自动安装的
#######对Windows的端口兼容性不好，坑货Windows

for managedService in "$cdbak01ssh" "$cdbak01db" "$cdbak01web" "$cdbak01web2" "$cddc01rdp"
do

####使用eval来逐层的剥离变量名字，得到实际的值
####$managedServic-->$cdbak01ssh-->"172.16.10.156 22 bak01ssh" 。。。。。。

       host=$(eval eval echo "$managedService" |awk '{print $1}')
        #echo host=$host
        port=$(eval eval echo "$managedService" |awk '{print $2}')
        name=$(eval eval echo "$managedService" |awk '{print $3}')
        #echo port=$port
        #echo name=$name

        nc -w 2 $host $port < /dev/null &>/dev/null
        if [ $? == 0 ];then
                #echo $name is OK at $op_date
                echo $name is OK at $op_date>>$log_file
        else
                echo $name Wrong at $op_date>>$log_file
                #echo $name Wrong at $op_date
        fi
done
###############探测端口状态 detect port status End######################

##############文档去除重复段落#########################
对于空格，可以将空格替换为文档中不存在的字符
比如在vim中，%s:^$:abcdefghijklmnopq1234567890:g
然后使用awk 'BEGIN {RS="abcdefghijklmnopq1234567890"} !seen[$0]++' file.txt >file-processed.txt

http://stackoverflow.com/questions/1444406/how-can-i-delete-duplicate-lines-in-a-file-in-unix

awk '!seen[$0]++' file.txt

seen is an associative-array that Awk will pass every line of the file to. If a line isn't in the array then seen[$0] will evaluate to false. The ! is a logical NOT operator and will invert the false to true. Awk will print the lines where the expression evaluates to true. The ++ increments seen so that seen[$0] == 1 after the first time a line is found and then seen[$0] == 2, and so on.
Awk evaluates everything but 0 and "" (empty string) to true. If a duplicate line is placed in seen then !seen[$0] will evaluate to false and the line will not be written to the output.

##############文档去除重复段落END######################

##########nc centos 7 探测开放端口#####################
$ nc -w 2 172.16.20.11 22 < /dev/null &>/dev/null && echo Success || echo Failure
Success
$ nc -w 2 172.16.20.11 25 < /dev/null &>/dev/null && echo Success || echo Failure
Failure
##########nc centos 7 探测开放端口END#################

#########UPGRADE升级SSH#####
https://gist.github.com/faishal/add912b9b4c3899ec26c488a91446a84

#!/bin/bash
# Copyright © 2016 Faishal Saiyed
cd
timestamp=$(date +%s)
if [ ! -f openssh-7.3.zip ]; then wget https://github.com/faishal/openssh-portable/releases/download/cent.os.6.7.openssh.7.3p1/openssh-7.3.zip; fi;
unzip -o openssh-7.3.zip -d openssh-7.3p1
cd openssh-7.3p1/
cp /etc/pam.d/sshd pam-ssh-conf-$timestamp
rpm -U *.rpm
yes | cp pam-ssh-conf-$timestamp /etc/pam.d/sshd
/etc/init.d/sshd restart
#########升级SSH END######

###########并行处理############
#/bin/bash
#filename: generate_checksums.sh
PIDARRAY=()
for file in File1.iso File2.iso
do md5sum $file & PIDARRAY+=("$!") done
wait ${PIDARRAY[@]}
###########并行处理end############

####stdin stdout with -#############

$ tar cvf - files/ | ssh user@example.com "tar xv -C Documents/"
In the preceding example, the directory files/ is added to a tar archive which is output to stdout (denoted by '-')

####stdin stdout with - end#############

##########delete n days before files and directory##########
$ cat del_before_10days_backup_mon01_v2.sh
#!/bin/bash
PATH="/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin"
####find -ctime +10 表示10天以前的所有时间
####find -ctime 10 表示只是前第10天的文件
####注意rm所操作的目录
mallimage_path="/data/backup/mall/attachement/"
mallattache_path="/data/backup/mall/image/pictures/"
dbbak_path="/data/backup/db/"
if [ -d $mallimage_path ];then
        find $mallimage_path  -ctime +10 |xargs rm  -rf
else
        echo "Error,Directory not exist!"
fi

if [ -d $mallattache_path ];then
        find $mallattache_path -ctime +10 |xargs rm  -rf
else
        echo "Error,Directory not exist!"
fi

if [ -d $dbbak_path ];then
        find $dbbak_path -name "*.sql" -ctime +10 |xargs rm  -f
else
        echo "Error,Directory not exist!"
fi
##########delete n days before files and directory END########

删除N天以前的文件
#!/bin/bash
find /usr/local/nginx/logs/ -mtime +15 -type f -name *.log | xargs rm -f
“find: paths must precede expression:” How do I specify a recursive search that also finds files in the current directory?
find /usr/local/nginx/logs/ -mtime +15 -type f -name "*.log" | xargs rm -f
仅找出当前目录的文件
find ./ -maxdepth 1 -name "*.conf"

#!/bin/bash
find /usr/local/nginx/logs/ -mtime +15 -type f -name *.log | xargs rm -f
##################################################

http://kodango.com/ linux 运维开发
https://my.oschina.net/leejun2005/blog

ssh tunnel 隧道
###########mall###########
ssh -R 28000:172.16.10.118:80 -p 30023 -N -q -f -C -i you-privity-ssh-key user@www.example.com
ssh -R 28080:172.16.10.118:8080 -p 30023 -N -q -f -C -i you-privity-ssh-key user@www.example.com
###########shunfeng waas#################
ssh -R 30080:192.168.28.99:80 -p 30023 -N -q -f -C -i you-privity-ssh-key user@www.example.com
ssh -R 30180:172.16.10.124:9010 -p 30023 -N -q -f -C -i you-privity-ssh-key user@www.example.com

#############################
#############split view#########
http://unix.stackexchange.com/questions/7453/how-to-split-the-terminal-into-more-than-one-view
You can do it in screen the terminal multiplexer.
here ctrla is press Ctrl + a
To split vertically: ctrla then |.
To split horizontally: ctrla then S (uppercase one).
To unsplit: ctrla then Q (uppercase one).
To switch from one to the other: ctrla then tab
Note: After splitting, you need to go into the new region and start a new session via ctrla then c before you can use that area.

EDIT, basic screen usage:

New terminal: ctrla then c.
Next terminal: ctrla then space.
Previous terminal: ctrla then backspace.
N'th terminal ctrla then [n]. (works for n∈{0,1…9})
Switch between terminals using list: ctrla then " (useful when more than 10 terminals)
Send ctrla to the underlying terminal ctrla then a.

#############################
###split view end###

########screen config 20170320######

hardstatus on

hardstatus alwayslastline

hardstatus string "%{.bW}%-w%{.rW}%n %t%{-}%+w %=%{..G} %H

%{..Y} %m/%d %C%a "

##scroll 2048 line

defscrollback 2048

##bind shorcut Fn to switch screen

##f10-->k; select 0

##f11-->F1 monitor

##f12-->F2 kill

##f7--->k7 new screen

##f8--->k8 title screen

bindkey -k k1 select 1

bindkey -k k2 select 2

bindkey -k k3 select 3

bindkey -k k4 select 4

bindkey -k k5 select 5

bindkey -k k6 select 6

bindkey -k k7 screen

bindkey -k k8 title

bindkey -k k9 time

bindkey -k k;  select 0

bindkey -k F1  monitor

bindkey -k F2  kill

##initial named session

screen -t config 1 bash

screen -t debug 1 bash

screen -t test 1 bash

screen -t misc 1 bash

##initail screen from 1

bind c screen 1

bind ^c screen 1

bind 0 select 10

screen 1
########screen config 20170320 END######

########config 20170215 #######
hardstatus on
hardstatus alwayslastline
hardstatus string "%{.bW}%-w%{.rW}%n %t%{-}%+w %=%{..G} %H %{..Y} %m/%d %C%a "
##scroll 2048 line
defscrollback 2048
##bind shorcut Fn to switch screen
bindkey -k k1 select 1
bindkey -k k2 select 2
bindkey -k k3 select 3
bindkey -k k4 select 4
bindkey -k k5 select 5
##initial named session
screen -t config 1 bash
screen -t debug 1 bash
screen -t test 1 bash
screen -t misc 1 bash
##initail screen from 1
bind c screen 1
bind ^c screen 1
bind 0 select 10
screen 1
termcapinfo xterm* ti@:te@
########config 20170215 #######
############end###############

632 down vote accepted
"kill" will only kill one screen window. To "kill" the complete session, use quit.

Example 删除已经deteatch的sockets
$ screen -X -S [session # you want to kill] quit

+++++++inital centos 6 start++++++++
++++++only run once ++++++++++

#!/bin/bash
PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin
export PATH
personBashCfg=/root/.bashrc
personScreenCfg=/root/.screenrc
mv /etc/localtime /tmp
ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
if [ `grep AlreadyInitiald $personBashCfg | wc -l` -eq 0 ];then
        echo "alias hg='history |egrep -i --color'">>$personBashCfg
        echo "alias h='history'">>$personBashCfg
        echo "alias fcn='find ./ -name'">>$personBashCfg
        echo "alias frn='find / -name'">>$personBashCfg
        echo "alias lc='locate / | grep -i -E --color'">>$personBashCfg
        echo "alias les='less -I'">>$personBashCfg
        echo "alias ng='netstat -tlanp | grep -Ei --color'">>$personBashCfg
        echo "alias pg='ps aux | grep -E -i --color'">>$personBashCfg
        echo "alias ud='updatedb'">>$personBashCfg
        echo "alias yuml='yum --disablerepo=\* --enablerepo=c6-media install'">>$personBashCfg
        echo "alias gre='grep -E -i --color'">>$personBashCfg
        echo "alias yumm='yum --enablerepo=c6-media install'">>$personBashCfg
        echo "alias mc='mount /dev/cdrom /mnt/cdrom -t iso9660'">>$personBashCfg
        echo "alias la='ls -Al'">>$personBashCfg
        echo "alias lh='ls -hAl'">>$personBashCfg
        echo "alias h='history'">>$personBashCfg
        echo "alias lrd='locate / | grep -Ei'">>$personBashCfg
        echo "alias scs='screen -S'">>$personBashCfg
        echo "alias scl='screen -li'">>$personBashCfg
        echo "alias scd='screen -d'">>$personBashCfg
        echo "alias scr='screen -r'">>$personBashCfg
        echo "alias lrd='locate / | grep -Ei'">>$personBashCfg
        echo "alias gre='grep -i --color -A 3 -B 3 -n'">>$personBashCfg
        source ~/.bashrc
        rm -f $personScreenCfg
        touch $personScreenCfg
        echo  "hardstatus on ">$personScreenCfg
        echo "hardstatus alwayslastline" >>$personScreenCfg
        echo 'hardstatus string "%{.bW}%-w%{.rW}%n %t%{-}%+w %=%{..G} %H %{..Y} %m/%d %C%a "'>>$personScreenCfg
        echo "defscrollback 2048 " >>$personScreenCfg
        echo "termcapinfo xterm* ti@:te@ ">>$personScreenCfg
        ##bind shorcut Fn to switch screen
        echo "bindkey -k k1 select 1 ">>$personScreenCfg
        echo "bindkey -k k2 select 2 ">>$personScreenCfg
        echo "bindkey -k k3 select 3 ">>$personScreenCfg
        echo "bindkey -k k4 select 4 ">>$personScreenCfg
        echo "bindkey -k k5 select 5 ">>$personScreenCfg
        echo "##initail screen from 1 ">>$personScreenCfg
        echo "bind c screen 1 ">>$personScreenCfg
        echo "bind ^c screen 1 ">>$personScreenCfg
        echo "bind 0 select 10 ">>$personScreenCfg
        echo "screen 1 ">>$personScreenCfg

        yum install -y epel-release.noarch  mlocate vim  gcc gcc++ gcc-c++ cmake screen
        yum update -y
        echo "#TheVMhasAlreadyInitialed">>$personBashCfg
else
        echo "AlreadyInitialed"
fi

++++++inital centos 6++++++
+++++++end++++++++++++

=======screen op ===========
=======start==============
for centos 7 title 不是期待的设置
I am using bash and GNU screen on centos7. I notice that if I ssh to another server, change the title (via ctrl+a+A), and log out of the server that my new title gets overwritten by USER@HOST:~. How can I stop it from doing this?

As documented in the man page, screen looks for a null title-escape-sequence. bash sends this sequence via the PROMPT_COMMAND environment variable (for example, mine defaults to printf "\033k%s@%s:%s\033\\" "${USER}" "${HOSTNAME%%.*}" "${PWD/#$HOME/~}".

To disable this feature for a particular window, I just run unset PROMPT_COMMAND from that window. Of course, one could just add this to their ~/.bashrc or to a specific environment file to make it more persistent.
shareimprove this answer

If $PROMPT_COMMAND is empty, check $PS1. – choroba Oct 22 '14 at 22:44
http://unix.stackexchange.com/questions/163691/how-do-i-stop-screen-from-clobbering-my-titles

vim %userHome%/.screenrc
hardstatus on
hardstatus alwayslastline
hardstatus string "%{.bW}%-w%{.rW}%n %t%{-}%+w %=%{..G} %H %{..Y} %m/%d %C%a "
##scroll 2048 line
defscrollback 2048
##bind shorcut Fn to switch screen
bindkey -k k1 select 1
bindkey -k k2 select 2
bindkey -k k3 select 3
bindkey -k k4 select 4
bindkey -k k5 select 5
##initail screen from 1
bind c screen 1
bind ^c screen 1
bind 0 select 10
screen 1
termcapinfo xterm* ti@:te@

screen -S sharing -t one 创建带名称的screen

alias scd='screen -d'
alias scl='screen -li'
alias scr='screen -r'
alias scs='screen -S'
=======screen op ===========
=======end==============

====bash shell 并行后台ping========
====start===================
#!/bin/bash
#Filename: fast_ping.sh
# Change base address 192.168.0 according to your network.
for ip in 192.168.28.{1..255} ;
 do   (ping $ip -c2 &> /dev/null ;
     if [ $? -eq 0 ];
    then
 echo $ip is alive
        fi)&
 done
wait
====bash shell 并行后台ping========
====end===================

====vim编辑替换时候的转意字符元字符meta char start===========
必须转意：～ [ ] $ / \
   (口诀：心 有一点邪，关门 撑伞 造美元,太浪，危险要转移（转义）,怎么转移，不走斜路(MS 是反斜路) 
                 --> * .  /\ [ ^ $ ~  ==> \* \. \/ \\ \[ \^ \$ \~)

不必转意：@ > : - （) {
随意：/ } ] space 

成功的示意:
:%s:now\=:\=:g 转意=
:%s#Michael@linux-gzbl:\~>##g            //仅仅转意～
:%s:\[root@RD-CD-SVN-BAK-1\ xml\]::g  //-没有转意
====vim编辑替换时候的转意字符end===========

===from http://vim.wikia.com/wiki/Search_and_replace start==============================
When searching:

., *, \, [, ^, and $ are metacharacters.
+, ?, |, &, {, (, and ) must be escaped to use their special function.
\/ is / (use backslash + forward slash to search for forward slash)
\t is tab, \s is whitespace
\n is newline, \r is CR (carriage return = Ctrl-M = ^M)
After an opening [, everything until the next closing ] specifies a /collection. Character ranges can be represented with a -; for example a letter a, b, c, or the number 1 can be matched with [1a-c]. Negate the collection with [^ instead of [; for example [^1a-c] matches any character except a, b, c, or 1.
\{#\} is used for repetition. /foo.\{2\} will match foo and the two following characters. The \ is not required on the closing } so /foo.\{2} will do the same thing.
\(foo\) makes a backreference to foo. Parenthesis without escapes are literally matched. Here the \ is required for the closing \).
When replacing:

\r is newline, \n is a null byte (0x00).
\& is ampersand (& is the text that matches the search pattern).
\0 inserts the text matched by the entire pattern
\1 inserts the text of the first backreference. \2 inserts the second backreference, and so on.
=============from http://vim.wikia.com/wiki/Search_and_replace end=============

###tcpdump
#tcpdump -nNxXi eth0 -s 0 proto TCP and port 25 -w mail.txt
tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes
^C14 packets captured
14 packets received by filter
0 packets dropped by kernel
# strings mail.txt
>220 163.com Anti-spam GT for Coremail System (163com[20141201])
ehlo [10.21.100.4]
N250-mail
250-PIPELINING
250-AUTH LOGIN PLAIN
250-AUTH=LOGIN PLAIN
250-coremail 1Uxr2xKj7kG0xkI17xGrU7I0s8FY2U3Uj8Cz28x1UUUUU7Ic2I0Y2UrNWAAgUCa0xDrUUUUj
250-STARTTLS
250 8BITMIME
AUTH PLAIN AHh0ODMzYQBtaW1haW1hOSk=
535 Error: authentication failed

#tcpdump -nNxXi eth0 -s 0 proto TCP and host 192.168.1.0 -w mail.txt
#tcpdump -nNxXi eth0 -s 0 proto TCP and host 192.168.1.5 -w mail.txt   
#VIM 空格高亮黄色  显示所有隐藏的字符
set nohls取消搜索的高亮关键字。

set list 显示所有隐藏的字符

hlsearch 是高亮选择搜索的关键字。

原来我此前搜索替换了空格，所以就把所有空格染色了。

而set nohls，则以后的搜索都不会高亮所有搜索的关键字。所以空格也不会有颜色了

当然这个方面只是一次性开关，下次打开时又会出现黄色空格。如果想以后打开所有的文件里的黄色空格都不要的话，就打开用户主目录下的.vimrc文件，（如果没有，就新建一个），在后面输入set nohls，保存。以后再打开所有的文件都不会有烦人的黄色空格了。

######映射L到End键######
xmodmap -e "keycode 115 = End NoSymbol End"        #restore End key
xmodmap -e "keycode 115 = l"                                    #remap End key to l
报什么display错误时，
添加如下语句到.bashrc,然后source .bashrc
if [ -n “${DISPLAY+x}”];then       #x是小写？
     xmodmap -e "keycode 115 = l" #最后的字符时字母L的小写
fi

xmodmap -pke #显示所有键盘映射

###### 映射L到End键######

+++++读取文件到数组的shell script++++
++++++start++++++++++++++++
====vim编辑替换时候的转意字符start===========
必须转意：～空格 [ ]= $(字符，非结尾标志) \
不必转意：@ > : - （) {
随意：/}
成功的示意:
:%s:now\=:\=:g 转意=
:%s#Michael@linux-gzbl:\~>##g            //仅仅转意～
:%s:\[root@RD-CD-SVN-BAK-1\ xml\]::g  //-没有转意
====vim编辑替换时候的转意字符end===========

+++++读取文件到数组的shell script++++
++++++start++++++++++++++++
#!/bin/bash
declare -a myarray

# Load file into array.
mapfile myarray < /tmp/file.txt
#readarray myarray < /tmp/file.txt

# Explicitly report array content.
let i=0
while (( ${#myarray[@]} > i )); do
printf "${myarray[i++]}"
done
+++++读取文件到数组的shell script++++
++++++end++++++++++++++++

++++++rsync with ssh++++++
+++++++start+++++++++++++
#first upload CA to remoteHost
rsync -avz -e ssh remoteuser@remoteHost:/remotefiles /localDir
+++++++++rsync with ssh++++
++++++++end++++++++++++++

rsync +inotify
Server 源端 192.168.1.91
> sudo yum install inotify-tools
[leo@linux-vps~]$ vim inotify-example
while true$>run indefinitely
do
inotifywait -r -e modify,attrib,close_write,move,create,delete \
/path/2/dir && /bin/bash backup-script
done
$>cat backup-script
#!/bin/bash
rsync -avz /source/dir 192.168.1.92::website --delete
[root@www ~]# yum -y install rsync

Backup目的端
[root@dlp ~]# yum -y install rsync xinetd
[root@dlp ~]# vi /etc/xinetd.d/rsync
# default: off
# description: The rsync server is a good addition to an ftp server, as it \
# allows crc checksumming etc.
service rsync
{
disable= n$> change
flags= IPv6
socket_type= stream
wait= no
user= root
server= /usr/bin/rsync
server_args= --daemon
log_on_failure+= USERID
}
[root@dlp ~]# /etc/rc.d/init.d/xinetd start
Starting xinetd:[ OK ]
[root@dlp ~]# chkconfig xinetd on
[root@dlp ~]# mkdir /home/backup
[root@dlp ~]# vi /etc/rsyncd.conf
# any name you like
[website]
# destination directory
path = /home/backup
# Hosts you allow to copy (specify source Host)
hosts allow = 192.168.1.91
hosts deny = *
list = true
uid = root
gid = root
read only = false

执行
[root@ha1 home]# ./inotify_trigger.sh &
[1] 3935
[root@ha1 home]# Setting up watches. Beware: since -r was given, this may take a while!
Watches established.

通过监控某一文件的值做对应的操作，
用于系统第一次启动按照软件;之后不在安装
shell> cat getVar.sh
#!/bin/bash
isFstBt=$(cat c.txt)
case $isFstBt in
1)
  echo "Install something"
  isFstBt=0
  echo "$isFstBt" >c.txt #用0覆盖c.txt中的1
  ;;
0)
  echo "Done"
  ;;
*)
  echo "something worong"
esac

shell> echo 1 >c.txt
shell> ./getVar.sh
Install something
shell> cat c.txt
0
shell> echo e >c.txt
shell> ./getVar.sh
something worong

 LVM相关
1 fdisk /dev/sdb /dev/sdc -->logical partition-->type 8e
2 vgcreate vg_web /dev/sd{b5,c5}
3 vcreate -L 8G -n lv_web vg_web
4 mkfs.ext4 /dev/vg_web/lv_web
5 mkdir -p /data
6 mount -t ext4 /dev/vg_web/lv_web /data
7 echo "/dev/mapper/vg_web-lv_web ext4 defaults 1 1" >>/etc/fstab
8 lvresize -L +500M /dev/vg_web/lv_web
9 ## display correct partion info on df -hT command
10 umount /db
11 e2fsck -f /dev/mapper/vg_web-lv_web
12 resize2fs /dev/mapper/vg_web-lv_web
13 mount -t ext4 e2fsck -f /dev/mapper/vg_web-lv_web /data

####iptables-save centos6

iptables-save | sudo tee /etc/sysconfig/iptables

The iptables configuration file on CentOS is located at /etc/sysconfig/iptables. The above command saved the rules we created into that file. Just to make sure everything works, we can restart the firewall:

service iptables restart

####iptables-save centos6

####firewalld centos7
# firewall-cmd --list-ports
1235/tcp

# firewall-cmd --get-active-zone
public
  interfaces: enp0s3

# firewall-cmd --add-port 1236/tcp --permanent
success

# firewall-cmd --add-service https
success

# firewall-cmd --list-services
dhcpv6-client ssh https

# systemctl enable firewalld
# systemctl restart firewalld

[root@localhost ~]# firewall-cmd --add-service telnet
success
[root@localhost ~]# firewall-cmd --list-service
dhcpv6-client ssh http telnet
[root@localhost ~]# firewall-cmd --add-service https
success
[root@localhost ~]# firewall-cmd --list-service
dhcpv6-client ssh http telnet https
[root@localhost ~]# firewall-cmd --add-service dns
success
[root@localhost ~]# firewall-cmd --list-service
dhcpv6-client ssh http telnet https dns
[root@localhost ~]# firewall-cmd --reload
success
[root@localhost ~]# firewall-cmd --zone=public --remove-service=http --permanent
Warning: NOT_ENABLED: http
success

####firewalld centos7

DNAT
iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j DNAT \
--to 172.31.0.23:80
iptables -A FORWARD -i eth0 -p tcp --dport 80 -d \
172.31.0.23 -j ACCEPT #开启Forward允许策略

端口重定向 port forward
iptables -t nat -I PREROUTING -i eth0 -p tcp \
--dport 88 -j REDIRECT --to-ports 3306
[root@lnmp ~]# mysql -uroot -P 88 -p #注意端口是88

 ssh自动输入密码 StrictHostKeyChecking=no 不要求输入yes
sshpass -p "PASS" ssh -o StrictHostKeyChecking=no USER@host:[port]
没有sshpass就yum
sshpass -p You_Pwd ssh-copy-id -i Your_Pub_key user@host    ##互信设置

find正则类型 posix-awk, posix-basic, posix-egrep and posix-extended
#命令执行方法，-regex区分大小写，-iregex不区分大小写
# find / -regextype posix-extended -regex ".*\.conf$"
/etc/latrace.d/libio.conf
/etc/latrace.d/mman.conf
/etc/latrace.d/stdlib.conf
/etc/latrace.d/inet.conf
/etc/latrace.d/typedefs.conf

EC2 AMI 登入方式及切換 root 權限

ssh -i AWS_KEY.pem ubuntu@ec2-52-69-88-159.ap-northeast-1.compute.amazonaws.com aws云服务器

去掉windows下的回车符 （注意^M 在linux 下写法 按^M 是回车换行符,输入方法是按住CTRL+v,松开v,按m)
sed -i 's/^M//g' filename

2) 在vim下类似

:%s/^M//g

$ find /home -name test > list_right 2>&1

$ cat local2 >>/dev/null
cat: local2: 是一个目录 //有错误信息显示
$ cat local2 >>/dev/null 2>&1  #也可以使用>>/dev/null &>
//错误信息也被丢弃了

2 $ locate i18n|grep i18n$|xargs grep -nvH '\#' 2>/dev/null | grep -v "匹配"
找出所有的i18n文件，打印其文件名字行号及内容，丢弃错误信息，并去掉有“匹配”字样的行

3 $ grep .* `locate -r '^/etc.*conf$'` 2>/dev/null |grep nameserver |grep -v '\#'
/etc/resolv.conf:nameserver 121.40.144.82
/etc/resolv.conf:nameserver 123.56.46.123

达到2一样的效果，注意2>/dev/null的位置要放在产生错误的语句的后面而不是最后面

4 $ grep -Hn .* `locate -r '^/etc.*conf$'` 2>/dev/null |grep nameserver |grep -v '\#' | sed 's/^.*ver//'
121.40.144.82
123.56.46.123

从3中只取IP，注意sed的用法

5 GREP 或 or 操作
$ netstat -np|grep -E 'PID|mysql'
Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name
tcp 0 0 192.168.1.104:38635 192.168.1.104:3306 ESTABLISHED 3420/mysql
tcp 0 0 192.168.1.104:3306 192.168.1.104:38635 ESTABLISHED 2342/mysqld
Proto RefCnt Flags Type State I-Node PID/Program name Path

6 HowTo: Flush nscd dns cache

Nscd caches libc-issued requests to the Name Service. If retrieving NSS data is fairly expensive, nscd is able to speed up consecutive access to the same data dramatically and increase overall system performance. Just restart nscd:
$ sudo /etc/init.d/nscd restart
OR
# service nscd restart
OR
# service nscd reload

7 目录hard link

shel $ mount --bind /home /tmp
shel $ ls -lid /home /tmp
64 drwxr-xr-x 4 root root 36 3月 25 12:28 /home
64 drwxr-xr-x 4 root root 36 3月 25 12:28 /tmp
shel $ umount /tmp
shel $ ls -lid /home /tmp
64 drwxr-xr-x 4 root root 36 3月 25 12:28 /home
256 drwxrwxrwt 1 root root 12656 6月 6 18:03 /tmp

8 nc探测主机开放的端口（同时nc是一个简单的网络通信程序，man中有例子）
shel $ nc -vz 192.168.1.1 80
Connection to 192.168.1.1 80 port [tcp/http] succeeded!
shel $ nc -vuz 192.168.1.1 53

$ cat ep
Iraq fight

awk RS 匹配正则表达式，record seperate？

9 $ cat ep
Iraq fight

oextuse mma
exque cctv
exqtes mmd
occ eec

mmd mt
lsct

qqtvm
cmde
wo
flortt
$ awk 'BEGIN {RS = ""} {print $3}' ep

exque
lsct
wo

$ awk '$2 ~ /mmd/' ep
exqtes mmd
$ awk 'BEGIN {RS = ""} {print $3}' ep //注意这个$3的结果

exque
lsct
wo
$ awk 'BEGIN {RS = ""} {print $2}' ep
fight
mma
mt
cmde

$ awk '/mmd/' ep
exqtes mmd
mmd mt

10 awk 统计 分类汇总

$ cat courty
asia china 140000
american usa 30000
europe uk 6000
asia japan 20000
american mexcia 5000
europe french 7000
asia india 130000

$ cat prep3
pass == 1{
pop[$1]+=$3
}
pass == 2{
print $1 " " pop[$1]| "sort | uniq" /调用系统命令的方法/
}

$ awk -f prep3 pass=1 courty pass=2 courty /传入变量值的方法
american 35000
asia 290000
europe 13000

11 AWK实现EXCEL vlookup的方法

$ cat f1.txt f2.txt
ls 34 b4
zs 23 a3
yq 57 f7
we 62 e2
mz 85 d5
zs 3 3333
ls 4 4444
we 2 2222
yq 6 7777
mz 5 5555
# awk 'FNR==NR{map[$1]=$3;map2[$1]=$2;next}{print $1,$2,$3 "," map[$1] ","map2[$1]}' f2.txt f1.txt /理解数组的表示的含义，数组中不仅可以用下标表示，还可以表示为别名，如map[ls]等
ls 34 b4,4444,4
zs 23 a3,3333,3
yq 57 f7,7777,6
we 62 e2,2222,2
mz 85 d5,5555,5

12 sed替换特殊字符的方法，注意sed后面的表示方法

处理前

$ find .
.
./.bash_history
./bin
./.gnupg
./.dbus
./.dbus/session-bus
./.dbus/session-bus/4ed603cd18304c8d9216b69334cdeb3a-0
。。。。。。

处理后

# find . | sed -r s/"^\."/"\/root"/g
/root
/root/.bash_history
/root/bin
/root/.gnupg
/root/.dbus
/root/.dbus/session-bus
/root/.dbus/session-bus/4ed603cd18304c8d9216b69334cdeb3a-0
。。。。。。

13 在SED中处理包含特殊字符的变量的应用

$ echo $PWD
/root

本是用sed s///g,因为$PWD中含有\字符，所以替换为;

（实际上可以替换为$PWD中不含的任意特殊字符，

比如 $！等都可以哦）

$ find .|sed -r "s;^\.;$PWD;g"
/root
/root/.bash_history
/root/bin
.路径被/root替换了
..............

14 find & exec

This command moves a set of files into an archive directory:

find /foo -maxdepth 1 -atime +366 -exec mv {} /archive \;

However, this will only move one file at a time. We cannot in this
case use `-exec ... +' because the matched file names are added at the
end of the command line, while the destination directory would need to
be specified last. We also can't use `xargs' in the obvious way for
the same reason. One way of working around this problem is to make use
of the special properties of GNU `mv'; it has a `-t' option that allows
the target directory to be specified before the list of files to be
moved. However, while this technique works for GNU `mv', it doesn't
solve the more general problem.

15 info 指令

s 向前搜索指定的字符串。
{ 查找上一个出现点。
} 查找下一个出现点。

[ 上一个节点

] 下一个节点

h 打开帮助文档

16 find exec 安全问题

cd /var/tmp && find stuff -mtime +90 -exec /bin/rm {} \+

might actually issue the command:

/bin/rm stuff/A stuff/B stuff/passwd

If an attacker can rename `stuff' to something else (making use of
their write permissions in `/var/tmp') they can replace it with a
symbolic link to `/etc'. That means that the `/bin/rm' command will be
invoked on `/etc/passwd'. If you are running your `find' command as
root, the attacker has just managed to delete a vital file. All they
needed to do to achieve this was replace a subdirectory with a symbolic
link at the vital moment.

There is however, a simple solution to the problem. This is an
action which works a lot like `-exec' but doesn't need to traverse a
chain of directories to reach the file that it needs to work on. This
is the `-execdir' action, which was introduced by the BSD family of
operating systems. The command,

find /var/tmp/stuff -mtime +90 -execdir /bin/rm {} \+
这样才好？

might delete a set of files by performing these actions:

1. Change directory to /var/tmp/stuff/foo

2. Invoke `/bin/rm ./file1 ./file2 ./file3'

3. Change directory to /var/tmp/stuff/bar

4. Invoke `/bin/rm ./file99 ./file100 ./file101'

This is a much more secure method. We are no longer exposed to a
race condition. For many typical uses of `find', this is the best
strategy. It's reasonably efficient, but the length of the command
line is limited not just by the operating system limits, but also by
how many files we actually need to delete from each directory.

Is it possible to do any better? In the case of general file
processing, no. However, in the specific case of deleting files it is
indeed possible to do better.

17 awk替换和条件判断

# cat f1.txt
ls 34 b4
zs 23 a3
yq 57 f7
we 62 e2
mz 85 d5
19899951
223667
abc12345
19230815a
5561826
511121193303032551
510122192308152652
510671201209011952
610311199009192512
要求是把上面的文本中每一列包含7个到结尾的数字，替换最3个数字为-xxx
# awk '$0 ~/[0-9]{7}$/{sub(/[0-9]{3}$/,"-xxx");print $0;next}{print $0}' f1.txt
ls 34 b4
zs 23 a3
yq 57 f7
we 62 e2
mz 85 d5
19899-xxx
223667
abc12345
19230815a
5561-xxx
511121193303032-xxx
510122192308152-xxx
510671201209011-xxx
610311199009192-xxx

18 lsblk -o +uuid 显示设备名，挂载点与uuid

19 mysql -e "select * ..." Dbname 在shell执行sql语句

20 centOS 安装完成后ifconfig只有lo网卡

A ifup eth0 试试是否可以看到eth0，
B lsmod 查找网卡的mod，再用modinfo确认是否是正确的网卡

以上确认后编辑ifcfg-eth0这个配置文件，使网卡启动时自动加载
下面是这个配置文件的正确方式

shel $ cat /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0
HWADDR=08:00:27:B9:B3:5C
TYPE=Ethernet
UUID=0179cbdb-4c64-4ecb-a9ff-d331baf1a178
ONBOOT=yes
NM_CONTROLLED=yes
IPADDR=192.168.1.2
GATEWAY=192.168.1.1
PREFIX=24
NETMASK=255.255.255.0
DNS=61.139.2.69

21
nginx SSL配置
生成证书
$ cd /usr/local/nginx/conf
$ openssl genrsa -des3 -out server.key 1024
$ openssl req -new -key server.key -out server.csr
$ cp server.key server.key.org
$ openssl rsa -in server.key.org -out server.key
$ openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt
编辑 nginx.conf
server {
server_name YOUR_DOMAINNAME_HERE;
listen 443;
ssl on;
ssl_certificate /usr/local/nginx/conf/server.crt;
ssl_certificate_key /usr/local/nginx/conf/server.key;
}

22 svn多目录配置
[root@localhost conf]# grep -v ^# authz
[aliases]
[groups]
[/] $这里只能是根路径，不然授权出错
uw = rw

[root@localhost conf]# grep -v ^# passwd
[users]
uw=uwmima

[root@localhost conf]# grep -v ^# svnserve.conf
[general]
anon-access = read
auth-access = write
password-db = passwd
authz-db = authz
realm = www

23 LVS 配置 Server
[root@localhost ~]# cat dr.sh
service iptables stop
ifconfig eth0:0 192.168.1.10 broadcast 192.168.1.10 netmask 255.255.255.255 up
route add -host 192.168.1.10 dev eth0:0
ipvsadm -C
ipvsadm -A -t 192.168.1.10:80 -s rr
ipvsadm -agt 192.168.1.10:80 -r 192.168.1.11:80
ipvsadm -agt 192.168.1.10:80 -r 192.168.1.12:80

[root@localhost ~]# cat tunl.sh
service iptables stop
ifconfig tunl0 192.168.1.10 netmask 255.255.255.255 up
route add -host 192.168.1.10 dev tunl0
ipvsadm -C
ipvsadm -A -t 192.168.1.10:80 -s rr
ipvsadm -a -t 192.168.1.10:80 -r 192.168.1.11:80 -i
ipvsadm -a -t 192.168.1.10:80 -r 192.168.1.12:80 -i

CLIENT
anaconda-ks.cfg dr.sh install.log install.log.syslog start.sh
[root@localhost ~]# cat dr.sh
service httpd start
service iptables stop
ifconfig lo:0 192.168.1.10 broadcast 192.168.1.10 netmask 255.255.255.255 up
route add -host 192.168.1.10 dev lo:0
echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
echo 1 > /proc/sys/net/ipv4/conf/all/arp_announce
echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce

[root@localhost ~]# cat start.sh
service httpd start
service iptables stop
ifconfig tunl0 192.168.1.10 netmask 255.255.255.255 up
route add -host 192.168.1.10 dev tunl0
echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
echo 1 > /proc/sys/net/ipv4/conf/tunl0/arp_ignore
echo 1 > /proc/sys/net/ipv4/conf/all/arp_announce
echo 2 > /proc/sys/net/ipv4/conf/tunl0/arp_announce

24
rsync配置

rsyncd.conf rsyncd.secrets
[root@localhost rsyncd]# cat rsyncd.conf
uid = root
gid = root
use chroot = no
read only = no
write only = no
host allow =192.168.1.0/255.255.255.0
max connection = 3
pid file = /var/run/syncd.pid
log file = /var/log/rsyncd.log
secrets file = /etc/rsyncd/rsyscd.secrets
log format = %t %a %m %f %b
time out = 300
strict mode = false

[shares]
path = /home/rsync
list = yes

start
# rsync --daemon --config=/etc/rsyncd/rsyncd.conf

客户端
list
$>rsync -avzP root@192.168.1.2::shares

sync
$>rsync -v ./* root@192.168.1.2::shares

26
tar.bz 安装时注意./configure 后面的参数，有时候错了不会有提示，但会失败;用 ./configure --help|grep 查找需要的参数，仔细核对输入，注意大小写，横线，单字的拼写;libdir 和includedir的值一定要正确，如果使用yum等自动安装找不到include和lib，使用tar源码手动安装

coreseek 段错误是词典路径不正确

coreseek 一定使用UTF8编码

27
diff
26c26
左边文件的26行与又边26行不同

26d
26行删除了

#空格高亮黄色
set nohls取消搜索的高亮关键字。
######End linux.memo #######
######Endmemoof linux.memo #######
######Startmemoof azure.memo #######
######Start azure.memo #######
####set fixed public for cloud service##

--10 service must have least one vm 

--20 powershell cmd

>New-AzureReservedIP -ReservedIPName "your-name-reservedIP" -Location "China East" -ServiceName "your-service"

>Set-AzureReservedIPAssociation -ReservedIPName your-name-reservedIP -ServiceName your-service

>Get-AzureSubscription

Select-AzureSubscription -SubscriptionName "your-scubscription"

####set fixed public for cloud service##
######End azure.memo #######
######Endmemoof azure.memo #######
######Startmemoof bash-script.memo #######
######Start bash-script.memo #######


####source in same process and set default var##
--10 script
$> cat var-in-same-process.sh 
#!/bin/bash
set -u            ##if var not exist ,exit
result_old=${result_old:=0}  ##if not exist,set to 0,or keep orgin
result_new=${result_new:=0}  ##if not exist,set to 0,or keep orgin
while(true)
sleep 1s
do
        echo "result_old is $result_old"
        printf "result_new is $result_new"
        printf "\n"
        
        if ! ls f2 &>/dev/null
        then
                result_new=1
        else
                result_new=0
        fi

        if [[ "$result_new" -ne "$result_old" ]]
        then  
               echo "result change from $result_old to $result_new"
               result_old="$result_new"
        fi
done

--20 initial and call
$> unset result_old
$> unset result_new
$> echo $result_old
-bash: result_old: unbound variable
$> echo $result_new
-bash: result_new: unbound variable   ###initial completely
$> source var-in-same-process.sh
result_old is 0                      ###var value from ${result_old:=0}
result_new is 0                      ###var value from ${result_new:=0}  
result change from 0 to 1            ###f2 not exist,status change to 1
result_old is 1
result_new is 1
......

Ctrl+c                              ####end it 


--25 view vars,result saved in vars
$> echo $result_old                                                                                   
1
$> echo $result_new
1


--30 swith 
$> mv f3 f2                       ###f2 exist now

--40 swith result
$> source var-in-same-process.sh
result_old is 1
result_new is 1                 ####last saved vars
result change from 1 to 0       ###status changed,so result change
result_old is 0
result_new is 0

####source in same process and set default var##



####calculate how many days no data####

--10 script
$> cat calculate-how-many-days-backup-file-not-received.sh 
#!bin/bash
bak_path_list_file=backup_list
while IFS= read -r backup_item
do
        if echo "$backup_item"|grep '#' &>/dev/null
        then
           continue
        fi
        
        item_name=$(echo "$backup_item" |awk '{print $1}')
        item_path=$(echo "$backup_item" |awk '{print $2}')
        item_max_days=$(echo "$backup_item" |awk '{print $3}')

        file_timestamp=$(find "$item_path" -type f -printf '%T@ %p\n' | sort -nr |head -1| cut -f1- -d" "|awk '{print $1}'|awk -F. '{print $1}')
        current_timestamp=$(date +%s)
        diff_timestamp_in_days=$((($current_timestamp-$file_timestamp)/86400))
        if (("$diff_timestamp_in_days" > "item_max_days"))
        then
            echo "$item_name" has "$diff_timestamp_in_days" days no date.
        fi
done <"$bak_path_list_file"

--20 config file
$> cat backup_list 
###name         path               max-days########
web-db         /backup/web             3
web-image      /backup/image/          3
app22-db       /backup/app22db         2
app2-mong      /backup/app2            2
App2-db        /backup/App2db          2
App2-mongo     /backup/App2mongo       2
App-mongo      /backup/App             2
App-db         /backup/App             2

--30 running result 
$> sh calculate-how-many-days-backup-file-not-received.sh 
App-mongo has 16 days no date.
App-db has 16 days no date.

####calculate how many days no data####


#########calculate#########
--10 code
#> cat calculate.sh 
#!/bin/bash
varA=10
varB=20
varC=4
result=""
result=$((($varA+$varB)/$varC))
echo $result

--20 result 
#> sh calculate.sh 
7

#########calculate#########


######detect web status###########
--10 script-A.sh      ###use temp file save mid values
set -u
var_orgin=""
var_new="new_var"
saved_var_file="saved_var"
[ -e "$saved_var_file" ] || touch "$saved_var_file" 
[ -e "$var_new" ] || touch "$var_new" 
while(true)
do
var_orgin=$(cat "$saved_var_file")    
parallel -a websites -j 4 -k 'curl -sL --connect-timeout 2 \ 
        -w "%{url_effective} %{http_code}\n"  \ 
        {} -o  /dev/null' >"$var_new" 
awk -v af="new_var" -v bf="saved_var" 'FNR==NR{temp[$1]=$2}
     FNR!=NR{
     if(temp[$1]!=$2)
             {system("cp new_var saved_var")}
     }' "$var_new" "$saved_var_file"      
done

--or script-B    ####use variables save mid values,call by issue source script-B 

#!/bin/bash
set -u
result_old=${result_old:=""}
result_new=${result_new:=""}

while(true)
do
        result_new=$(parallel -a websites -j 4 -k \
        'curl -sL --connect-timeout 2 \
        -w "%{url_effective} %{http_code}\n"  \
        {} -o  /dev/null')

                
        awk 'FNR==NR{
        temp[$1]=$2
            }

        FNR!=NR{
        if(temp[$1]!=$2)
             {
               print strftime("%H:%M-%m%d-%Y",systime()),"FATAL ERROR:",$1,"status changed from",$2,"to",temp[$1] >"/path/2/log/file"
             }
        }' <(echo -e "$result_new") <(echo -e "$result_old")               


        if [[ "$result_new" != "$result_old" ]]
        then
            result_old="$result_new"
        fi

        sleep 2s
done

--20 websites content
www.abc.com
www.abc.com:8080


--30 call
sh script.sh
or 
source script.sh ####use var save mid values

--40 result
12:18-0215-2012 FATAL ERROR: HTTP://www.abc.com/ status changed from 404 to 200
######detect web status###########


######auto create data partition###################
#> cat auto-partition.sh 
--10 requirement
--1 1GB disk in /dev/sdc,fdisk to ext4,mount on /data

--20 bash script
#!/bin/bash
set -u
devicePath="/dev/sdc"
filePath="/data"
devicePartition="/dev/sdc5"
fstabFile="/etc/fstab"
fileType=ext4
sed -e 's/\s*\([\+0-9a-zA-Z]*\).*/\1/' <<eof |fdisk "$devicePath"    ####fdisk operation
n #new
e #extend
  # space
  # space
  # space
n #logical
l #logical
  # space
  # space
w #
eof


[[ -d "$filePath" ]] || mkdir -p "$filePath"
mkfs."$fileType" "$devicePartition"
deviceUUID=$(blkid|grep "$devicePartition"|awk '{print $2}'|sed  's:"::g')

cp "$fstabFile" /tmp/                                          ###backup && write to fstab             
echo "$deviceUUID    $filePath    "$fileType"     defaults       0 0" >>"$fstabFile"

mount -a

######auto create data partition###################



##########detecv port status V4####################
----10 main prog
#cat /data/backup/detectServiceStatusV4.mon01.sh

#!/bin/bash
PATH="/usr/local/bin:/usr/bin:/bin"
export PATH
managedServiceFile="/data/backup/managedServiceListMon01"
logFile="/var/log/serviceStatusLogs/serviceStatusLog"
operationDate=$(date +%Y%m%d-%H%M)
echo -n "$operationDate:">"$logFile"
###每次的操作输入到一个文件，多个错误拼接到一行
while IFS= read -r managedServiceItem
do(
        if echo "$managedServiceItem"|grep '#' &>/dev/null
        then
           continue
        fi

        host=$(echo "$managedServiceItem"|awk '{print $1}')
        port=$(echo "$managedServiceItem"|awk '{print $2}')
        name=$(echo "$managedServiceItem"|awk '{print $3}')
        if ！ nc -w 2 "$host" "$port" < /dev/null &>/dev/null
                echo -n "WRONG $name ">>"$logFile"
        fi)&
done <"$managedServiceFile"
wait
echo "">>"$logFile"              ##打印换行
sed -i 's# WRONG##g' "$logFile"  ##删除多余的WRONG字符

----20 cfg
# cat managedServiceListMon01
192.168.2.56        3307        haproxy1
192.168.2.57        3307        haproyx2
192.168.2.56        3306        mysql2

----30 output
##输出格式：2017xxxx：WRONG HOST1 HOST2  .....
##########detecv port status V4 END侦测端口开启状态 ####################
######End bash-script.memo #######
######Endmemoof bash-script.memo #######
######Startmemoof temp.memo #######
######Start temp.memo #######
https://support.hpe.com/hpsc/doc/public/display?docId=emr_na-sg419en_us&docLocale=en_US where to download megaraid management software
https://www.supermicro.com/manuals/other/LSI_2108_2208_SAS_MegaRAID_Configuration_Utility.pdf  
https://www.zybuluo.com/ncepuwanghui/note/953929 使用kubeadm在CentOS 7上安装Kubernetes 1.8
https://www.linuxtechi.com/install-kubernetes-1-7-centos7-rhel7/  How to Install Kubernetes (k8s) 1.7 on CentOS 7 / RHEL 7
https://blog.csdn.net/aixiaoyang168/article/details/78411511 国内使用 kubeadm 在 Centos 7 搭建 Kubernetes 集群

iis asp cd/ci
https://stackoverflow.com/questions/20118783/web-deploy-from-visual-studio-2012-to-a-remote-iis-8-server
 30
down vote
accepted

OK I found the solution but it took me a whole day to get it working! Basically the steps are as follows. This is very sketchy but see the detailed guides below which helped me.

    Enable the IIS Web Management role feature.
    Install Web Deploy 3.0 (or higher). Make sure to customise the install to include the handlers (See notes below). If you're not presented with this option go to add/remove programs, find webdeploy, right click and select "change" option.
    In IIS click on the server node and find the "Management Service" icon. Enable remote access and configure a dedicated IIS User for remote deployment (These will be the credentials that will go in the user name and password boxes).
    At the site level in IIS assign this user to manage the website.
    Make sure port 8172 is open on the web server (you can check this port here).
    Try reconnecting from Visual Studio. There was some trial and error here for me but the error messages do link to a MS guide for decoding :)
    Even after connecting successfully I had to wrangle with permissions, so my IIS user had sufficient privileges to create the app pool, directories and general file management jobs.

The following links really helped!

Configuring the handler on the web server:

http://www.iis.net/learn/publish/using-web-deploy/configure-the-web-deployment-handler

Connecting via Visual Studio:

http://msdn.microsoft.com/en-us/library/dd465337(v=vs.110).aspx

NOTES:

To ensure the handler is running, login into your IIS server and point your browser to the following URL.

https://<servername>:8172/MsDeploy.axd

F12 to open up the dev tools to see the HTTP response. Also MsDeploy also creates IIS logs in inetpub/logs which should give you some clue if you're having connectivity problems.


openldap with webmin
https://doxfer.webmin.com/Webmin/LDAP_Server
https://www.virtualmin.com/documentation/installation/ldap

postfix with gui
http://www.trustfm.net/ebooks/DedicatedServer.php?page=Email
http://www.trustfm.net/ebooks/DedicatedServer.php?page=EmailAccounts
https://github.com/postfixadmin/postfixadmin/tree/master/DOCUMENTS
https://www.techrepublic.com/blog/tr-dojo/administer-postfix-with-this-web-based-tool/


www.spamhelp.org/shopenrelay/shopenrelaytest.php                SMTP Open Relay Test
postfix.state-of-mind.de/patrick.koetter/smtpauth/smtp_auth_mailclients.html                      12. SMTP Authentication for Mail clients
http://www.adeptus-mechanicus.com/codex/smtprly/smtprly.php         SMTP Relay Authentication - Postfix
https://www.linode.com/docs/email/postfix/postfix-smtp-debian7      Configure Postfix to Send Mail Using an External SMTP Server
http://postfix.state-of-mind.de/patrick.koetter/smtpauth/smtp_auth_mailservers.html        16. SMTP Authentication for Mail servers
https://anothersysadmin.wordpress.com/2009/02/06/postfix-as-relay-to-a-smtp-requiring-authentication/        Postfix as relay to a SMTP requiring authentication
keyword:postfix relay auth
http://www.berlinix.com/net/postfix.php

https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-compose-on-centos-7  How To Install and Use Docker Compose on CentOS 7  
http://geekyplatypus.com/dockerise-your-php-application-with-nginx-and-php7-fpm/ Dockerise your PHP application with Nginx and PHP7-FPM
https://github.com/mikechernev/dockerised-php
https://yeasy.gitbooks.io/docker_practice/content/ Docker — 从入门到实践
https://www.tecmint.com/mysql-mariadb-performance-tuning-and-optimization/  15 Useful MySQL/MariaDB Performance Tuning and Optimization Tips 有调优建议脚本

https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/ MySQL 5.7 Performance Tuning Immediately After Installation
######End temp.memo #######
######Endmemoof temp.memo #######
######Startmemoof IIS.memo #######
######Start IIS.memo #######
#####install certificate
link:
https://knowledge.geotrust.com/support/knowledge-base/index?page=content&id=SO22115&actp=search&viewlocale=en_US&searchid=1481962109651
https://www.digicert.com/csr-ssl-installation/iis-8-and-8.5.htm

Windows 2012 IIS 8.5 Install Certificate
This manual prevent Error "0x80070520 A specified logon session does not exist" when assign cert to sites
and disable user export pfx file from server certificte,survived after reboot.
10 convert pfx from crt
openssl pkcs12 -export -out certificate.pfx -inkey privateKey.key -in certificate.crt -certfile CACert.crt

20
delete all user cert and install computer cert in windows 2012
MMC-->ADD SNIP-->ADD CERTIFICATE-->ADD USER-->ADD COMPUTER-->OK

With the MMC and the Certificates snap-in open, expand the Personal > Certificates folder.
	1. Right click on the certificate > Delete
	2. Click Yes


Step 3: Re-import certificate (.pfx) file using Microsoft Management Console (MMC) Snap-in for managing certificates

	1. With the MMC and the Certificates snap-in open, double click on Certificates (Local Computer) in the center window.
	2. Right click on the Personal Certificates Store (folder)
	3. Choose > ALL TASKS > Import
	4. Follow the Certificate Import Wizard to import your .pfx file. You will need to browse for .pfx file.
	5. Enter the password that was used when exporting the certificate to a .pfx file.
	6. If desired, check the box to "Mark this key as exportable."--UNCHECK
	7. When prompted, choose to automatically place the certificates in the certificate stores based on the type of the certificate.
	8. Click Finish to close the certificate wizard.
	9. Close the MMC console. In the case that you are prompted, it is not necessary to save the changes made to the MMC console.

30 IIS set
Step 4: Binding certificate to the web site

	1. Click Start > Administrative Tools > Internet Information Services (IIS) Manager
	2. Browse to your server name > Sites > Your SSL-based site
	3. In the Actions pane, click Bindings...

In the Site Bindings window, If there is no existing https binding, choose Add and change Type from HTTP to HTTPS.
Note: If there is already a https binding, select it and click Edit.

From the {SSL} Certificate drop down, Select the Friendly Name for the SSL certificate that will be used for this site.


40 Verify Certificate in IIS

	1. Click Start > Administrative Tools > Internet Information Services (IIS) Manager
	2. Click IIS server >double click Server Certifcate >The Certificate listed >Verify Certificate domain,expire date,hash,Store is in Person
#####install certificate
######End IIS.memo #######
######Endmemoof IIS.memo #######
######Startmemoof QA.memo #######
######Start QA.memo #######
###update testlink version:database update

Okay, finally I understand how to update the db schame. Here is the way:

# mysql -u root -p
MariaDB [(none)]> use testlink;
MariaDB [testlink]> source /opt/lampp/htdocs/testlink/install/sql/alter_tables/1.9.14/mysql/DB.1.9.14/step1/db_schema_update.sql
MariaDB [testlink]> source /opt/lampp/htdocs/testlink/install/sql/alter_tables/1.9.14/mysql/DB.1.9.14/stepZ/z_final_step.sql
MariaDB [testlink]> source /opt/lampp/htdocs/testlink/install/sql/alter_tables/1.9.15/mysql/DB.1.9.15/step1/db_schema_update.sql
MariaDB [testlink]> source /opt/lampp/htdocs/testlink/install/sql/alter_tables/1.9.15/mysql/DB.1.9.15/stepZ/z_final_step.sql
DONE!

The truth is, want to upgrade a lower version testlink to a higher version, then it should be execute the /opt/lampp/htdocs/testlink/install/sql/alter_tables/**/step1/db_schema_update.sql and /opt/lampp/htdocs/testlink/install/sql/alter_tables/**/stepZ/db_schema_update.sql step by step. For example, if want to upgrade testlink from 1.9.10 to 1.9.15, then the db schema should be upgrade as below:

1.9.10 -> 1.9.11
1.9.11 -> 1.9.12
1.9.12 -> 1.9.13
1.9.13 -> 1.9.14
1.9.14 -> 1.9.15

Tips:Windows operation in mysql
source d:/1.9.13/mysql/DB.1.9.13/step1/db_schema_update.sql;
source d:/1.9.13/mysql/DB.1.9.13/stepZ/z_final_step.sql;
source d:/1.9.14/mysql/DB.1.9.14/step1/db_schema_update.sql;
source d:/1.9.14/mysql/DB.1.9.14/stepZ/z_final_step.sql;
######End QA.memo #######
######Endmemoof QA.memo #######
######Startmemoof powershell.memo #######
######Start powershell.memo #######
###powershell manangement iis####


1. server level
用法:

iisreset [计算机名]



    /RESTART            停止并重新启动所有 Internet 服务。

    /START              启动所有 Internet 服务。

    /STOP               停止所有 Internet 服务。

    /REBOOT             重新启动计算机。

    /REBOOTONERROR      如果启动、停止或重新启动 Internet 服务时

                        发生错误，则重新启动计算机。

    /NOFORCE            尝试正常停止 Internet 服务失败时

                        不进行强制终止。

    /TIMEOUT:val        指定等待成功停止 Internet 服务的超时值(秒)。

                        如果指定了 /REBOOTONERROR 参数，

                        则超过超时期限后会重新启动计算机。

                        重新启动服务、停止服务和重新启动计算机的默认值

                        分别是 20 秒、60 秒和 0 秒。

    /STATUS             显示所有 Internet 服务的状态。

    /ENABLE             启用本地系统上 Internet 服务的重新启动。

    /DISABLE            禁用本地系统上 Internet 服务的重新启动。


2. website level


[WebServer]: PS C:\Users\user\Documents> get-website

Name             ID   State      Physical Path                  Bindings                                                                                                                               
----             --   -----      -------------                  --------                                                                                                                               
OpeningPortal    1    Started    C:\Site\OpenningPortal         http *:80:                                                                                                                             
......


[WebServer]: PS C:\Users\user\Documents> Stop-Website "OpeningPortal"

[WebServer]: PS C:\Users\user\Documents> get-website

Name             ID   State      Physical Path                  Bindings                                                                                                                               
----             --   -----      -------------                  --------                                                                                                                               
OpeningPortal    1    Stopped    C:\Site\OpenningPortal         http *:80:                                                                                                                             
......

[WebServer]: PS C:\Users\user\Documents> Start-Website "OpeningPortal"

[WebServer]: PS C:\Users\user\Documents> get-website

Name             ID   State      Physical Path                  Bindings                                                                                                                               
----             --   -----      -------------                  --------                                                                                                                               
OpeningPortal    1    Started    C:\Site\OpenningPortal         http *:80:              

###powershell manangement iis####



Get-ChildItem -Path e:\path -Recurse -file|Get-ItemProperty -Name lastwritetime|ft pspath,lastwritetime


Get-ADUser -Filter 'name -like "username"' -Properties CN,TITLE,proxyAddresses


###########remote powershell######
1
登录您的Windows 2012 服务器，开启WinRM服务。以管理员权限打开PowerShell控制台，运行命令Enable-PSRemoting：

所有确认选择Y


2
Windows2012需要使用HTTPS连接，需要一个ssl自签名证书。
ssl自签名证书一般有三种途径生成：
•	使用第三方工具
•	使用visual studio tool
•	使用IIS
我这里安装IIS


安装role service-->centralized ssl certificate support
click server certifcates
click create self-signed certificate
generate cert

or powershell>$Cert = New-SelfSignedCertificate -CertstoreLocation Cert:\LocalMachine\My -DnsName "myHost"

3 

powershell> ls Cert:\LocalMachine\My\

PS C:\Users\Administrator> ls Cert:\LocalMachine\My\


    目录: Microsoft.PowerShell.Security\Certificate::LocalMachine\My


Thumbprint                                Subject
----------                                -------
CEA9F345AE37D3D313F954F0C1B49FD1579AD7DA  CN=your-host-name



4
使用管理员打开CMD执行如下命令：
////注意主机名和证书指纹替换为生成的信息。
c:\>winrm create winrm/config/Listener?Address=*+Transport=HTTPS @{
Port="5986" ;Hostname="your-host-name" ;CertificateThumbprint="CEA9F345AE37D3D313F954F0C1B49FD1579AD7DA"}

c:\>netstat -an|findstr "5986"
TCP    0.0.0.0:5986           0.0.0.0:0              LISTENING
TCP    [::]:5986              [::]:0                 LISTENING


5
enable 5986 port on server and security group on nat map(omit...)


6
client connect
在客户端您只需要使用命令链接就可以了：
Enter-Pssession -ComputerName IP-or-dns -port 5986 -Credential your-user-name -UseSSL -SessionOption (New-PSSessionOption -SkipCACheck -SkipCNCheck)


7
powershell copy file
•	PS C:\Windows\system32> $TargetSession = New-PSSession -ComputerName your-ip -Port  5986  -Credential your-user-name -UseSSL -SessionOption (New-PSSessionOption -SkipCACheck -SkipCNCheck)
•	PS C:\Windows\system32> Copy-Item  -ToSession $TargetSession -Path "C:\temp\localfile.txt"  -Destination "C:\azurevm\"  -Recurse
•	PS C:\Windows\system32> Enter-PSSession  -ComputerName your-ip -Port  5986  -Credential  your-user-name


tips
 windows 8.1 only support Administrator use enter-pssession ???
###########remote powershell######




=======if public ip changed send mail===============
$Username = "mail_user@mail.com";
$Password = "mail_password";


$orgin_ip = "";


function Send-ToEmail([string]$email){

    $message = new-object Net.Mail.MailMessage;
    $message.From = "your-send-title@a.com.cn";
    $message.To.Add($email);
    $message.Subject = "your-send-title@$ip";
    $message.Body = "$ip";
 
    $smtp = new-object Net.Mail.SmtpClient("mail.com", "25");
    $smtp.Credentials = New-Object System.Net.NetworkCredential($Username, $Password);
    $smtp.send($message);
 }

 while(1)
 {
 $ip=Invoke-RestMethod -Uri https://www.example.com/ip.php;
 if ($orgin_ip -ne $ip){
    Send-ToEmail  -email "your-name@example.com";
    start-sleep -Seconds 300;
    Send-ToEmail  -email "your-name@example.com";
    start-sleep -Seconds 300;
    Send-ToEmail  -email "your-name@example.com";
    $orgin_ip = $ip;
    start-sleep -Seconds 3;
    }
 }


=======if public ip changed send mail===============

###detect service status 
[array] $Services = "zabbix agent","EFS","BITS";


while(1){
    foreach($srv in $Services)
    {
        if(get-service -name $srv |findstr  "Running")
        {
            #write-host "$srv ok"                           //output to console
            write-output "error $Srv Running">>c:\s.txt     //output to file
        }
    }
    start-sleep -Seconds 30
}

###detect service status to file 


############get newest file in a folder
$dir = "f:\"
$latest = Get-ChildItem -Path $dir -Recurse -file | Sort-Object LastAccessTime -Descending| Select-Object -First 1
$latest.name
############get newest file in a folder

##########返回值 return value  exit code######################
> ping 127.0.0.1 -n 1

正在 Ping 127.0.0.1 具有 32 字节的数据:
来自 127.0.0.1 的回复: 字节=32 时间<1ms TTL=128

127.0.0.1 的 Ping 统计信息:
    数据包: 已发送 = 1，已接收 = 1，丢失 = 0 (0% 丢失)，
往返行程的估计时间(以毫秒为单位):
    最短 = 0ms，最长 = 0ms，平均 = 0ms
> $lastexitcode
0
> $?
True
> ping 192.168.1.1 -n 1

正在 Ping 192.168.1.1 具有 32 字节的数据:
请求超时。

192.168.1.1 的 Ping 统计信息:
    数据包: 已发送 = 1，已接收 = 0，丢失 = 1 (100% 丢失)，
> $?
False
> $lastexitcode
0
###########返回值 return value  exit code END##################



##########日期时间的操作####################
> $td=(get-date).adddays(-1).date  ##昨天
> echo $td

2017年3月19日 0:00:00


> $td=(get-date).adddays(0).date ##今天，注意写法
> echo $td

2017年3月20日 0:00:00
##########日期时间的操作END#################

####获取目录中文件的hash值###################
>  Get-ChildItem -Recurse -path F:\bak |Where-Object
{$_.LastWriteTime -ge $yd -and $_.LastWriteTime  
-le $td} |%{Write-Host $_.FullName}  #昨天写入的文件
F:\bak\20170319
F:\bak\20170319\project20170319.rar
F:\bak\20170319\project_redirect20170319.rar
>  Get-ChildItem -Recurse -path F:\bak |Where-Object
{$_.LastWriteTime -ge $yd -and $_.LastWriteTime   #包含完整目录的昨天写入的文件
-le $td} |%{$_.FullName}
F:\bak\20170319
F:\bak\20170319\project20170319.rar
F:\bak\20170319\project_redirect20170319.rar


PS F:\>  Get-ChildItem -Recurse -path F:\bak |Where-Object
{$_.LastWriteTime -ge $yd -and $_.LastWriteTime -le $td}
 |Where-Object {$_.Mode -eq "-a---"}   |%{d:\fciv.exe $_.FullName} ##调用外部命令，Mode只处理文件，丢弃目录
//
// File Checksum Integrity Verifier version 2.05.
//
8eddc3891ed145fbd0a18da0f6151f5a f:\bak\20170319\project20170319.rar
//
// File Checksum Integrity Verifier version 2.05.
//
d214f260bf1d7da605573eabcb3f045b f:\bak\20170319\project_redirect20170319.rar



PS F:\>  Get-ChildItem -Recurse -path F:\bak |Where-Object
{$_.LastWriteTime -ge $yd -and $_.LastWriteTime -le $td}
 |Where-Object {$_.Mode -eq "-a---"}   |%{d:\fciv.exe $_.FullName}
|Select-string -Pattern "/" -NotMatch   ##将输出中的/删除？？？

支持中文字符的hash计算
> Get-ChildItem -Recurse .\ |Where-Object {$_.Mode -eq "-a---"}|%{certutil
-hashfile $_.FullName md5}|Select-String -Pattern "CertUtil: -hashfile 命令成功完成" -NotMatch


文本规范化处理命令
cat 1.txt |sed -e ':a;N;$!ba;s/\n/ /g' -e 's/MD5 哈希(文件 /\n/g' -e 's/ //g' -e 's/):/ /g' >12.txt
换行替换未空格，再“MD5 哈希(文件 ”替换未换行；再将“）：”替换为空格

文本规范化处理前文本
MD5 哈希(文件 C:\20170209\f35b6f8a-1c0c-4d8d-baae-501bf9e05dcb-荣誉证书.jpg):
88 b9 c9 00 23 e5 a7 88 47 67 7a fa ad c1 da 03
MD5 哈希(文件 C:\20170209\fe2f6c8c-fffd-4317-8d8a-0fd8e6f57d90-105715370058673088
.jpg):
c2 51 2b a5 9e 0d 97 97 d2 7a 91 85 43 6f 7e 1d
MD5 哈希(文件 C:\20170209\fea70a73-0279-460a-9538-faac2a42e4f2-营业执照最新.pdf):
f4 f5 d9 15 3d f3 7a 8b 7f 47 05 62 4d 20 f3 ac
MD5 哈希(文件 C:\20170310\a529a4a4-4d52-4805-aa11-defe69dc22d3-Scan1.pdf):
c2 e7 fe c2 67 e6 88 95 3a 52 88 ff 3c a8 25 8b
MD5 哈希(文件 C:\20170327\04c0cc85-b568-42d4-bc9d-59a286e23fbb-QQ图片20170104150028
.jpg):
d0 96 09 b9 de d4 7b cb 47 46 a9 d5 ad 71 ad fb
MD5 哈希(文件 C:\20170327\53ca258b-f25f-488c-b70e-ed089ced32b4-QQ图片20160705104140
.jpg):
4b 43 08 e3 71 5d 86 4a f4 ac 1f c8 80 e4 04 ab


文本规范化处理后文本
C:\20170209\f35b6f8a-1c0c-4d8d-baae-501bf9e05dcb-荣誉证书.jpg 88b9c90023e5a78847677afaadc1da03
C:\20170209\fe2f6c8c-fffd-4317-8d8a-0fd8e6f57d90-105715370058673088.jpg c2512ba59e0d9797d27a9185436f7e1d
C:\20170209\fea70a73-0279-460a-9538-faac2a42e4f2-营业执照最新.pdf f4f5d9153df37a8b7f4705624d20f3ac
C:\20170310\a529a4a4-4d52-4805-aa11-defe69dc22d3-Scan1.pdf c2e7fec267e688953a5288ff3ca8258b
C:\20170327\04c0cc85-b568-42d4-bc9d-59a286e23fbb-QQ图片20170104150028.jpg d09609b9ded47bcb4746a9d5ad71adfb
C:\20170327\53ca258b-f25f-488c-b70e-ed089ced32b4-QQ图片20160705104140.jpg 4b4308e3715d864af4ac1fc880e404ab

8eddc3891ed145fbd0a18da0f6151f5a f:\bak\20170319\project20170319.rar
d214f260bf1d7da605573eabcb3f045b f:\bak\20170319\project_redirect20170319.rar
####获取目录中文件的hash值END################





 多行注释
<#
sed -i "s/^!/Erase/g" $svn_log_file
sed -i "s/^D/Erase/g" $svn_log_file
#>
单行注释
#del sed*

#变量前后添加双引号，注意行首的M“和行尾的“是添加的，$($Matches[1])是第一个反向匹配，三个双引号
svn status $svn_directory| ? { $_ -match '^!\s+(.*)' } | % { Write-Output """$($Matches[1])"""}
"D:\test\add\del\新建文本文档 (4)- = ' ; `.txt"
"D:\test\add\del\新建文本文档.txt"
https://blogs.technet.microsoft.com/heyscriptingguy/2010/07/28/writing-double-quotation-marks-to-a-text-file-using-windows-powershell/
#其他各种姿势，其他特殊符号
svn status $svn_directory| ? { $_ -match '^!\s+(.*)' } | % { Write-Output ""?""$($Matches[1])"\?"k}
svn status $svn_directory| ? { $_ -match '^!\s+(.*)' } | % { Write-Output ""!""$($Matches[1])"@"}
svn status $svn_directory| ? { $_ -match '^!\s+(.*)' } | % { Write-Output ""/""$($Matches[1])"￥"}

svn status $svn_directory| ? { $_ -match '^!\s+(.*)' } | % { Write-Output "‘"$($Matches[1])"’"} #通不过




++++++string scrap++++++++
++++++++++start+++++++++
https://technet.microsoft.com/en-us/library/ee692804.aspx

$op_time=get-date -format yyyyMd-HHmm
$op_time.substring(0,8)
++++++string scrap++++++++
++++++++++end+++++++++




+++++++++++++++++++++
变量与时间定义

 #define variables
$op_src="d:\site"
$op_dst="Z:\waasiisbak"
$op_time=get-date -format yyyyMd-HHmm
$op_log="$op_dst\rc-$op_time.log"
write-output "$op_src,$op_dst,$op_time,$op_log"

结果如下

 PS C:\Users\someuser\Desktop> C:\Users\someuser\Desktop\bak-waas-iis.ps1
d:\site,Z:\waasiisbak,20161130-1456,Z:\waasiisbak\rc-20161130-1456.log
++++++++++++++++++++++++++++++



===========与计划任务互操作==================
#define variables
$op_src="C:\site"
$op_log_pos="D:\log"
$op_dst="\\172.16.100.13\image_bak\bak"  #不可以使用网络映射的驱动器方式，只能用UNC方式
$op_time=get-date -format yyyyMd-HHmm
$op_log="$op_log_pos\rc-$op_time.log"
#write-output "$op_src,$op_dst,$op_time,$op_log" #验证变量



#Backup with robocpy & Log
robocopy $op_src $op_dst /copy:dt /e /log:$op_log /purge /r:5 /w:5 


+++++++++++PATT++++++++++
taskschd set 任务计划的设置
program:%SystemRoot%\system32\WindowsPowerShell\v1.0\powershell.exe #powshell路径
add parameter:-File D:\shell\bak-waas-iis.ps1 #脚本路径加上前缀写到附加参数中
++++++++++++++++++++++++++

===========计划任务互操作结束===========

 
#blank line 空行
write-output "`n"

 where-object filter (? is alias):
% is an alias for foreach-object):
This is the variable for the current value in the pipe line.

1,2,3 | %{ write-host $_ } 
For example in the above code the %{} block is called for every value in the array. The $_ variable will contain the current value.



#类似XARGS 重定向 错误和正常输出到文件
 Get-Content 5.txt |% {dir $_} 2>&1 >6.txt
Get-Content 5.txt |% {svn status $_} 2>&1 >6.txt

#bat文件中调用powershell
Powershell.exe -executionpolicy remotesigned -File C:\Users\SE\Desktop\ps.ps1

#正则文件内替换
Get-Content .\svn_log.txt | % {$_ -replace "^svn.*$","MMTV"}|Set-Content .\svn_log_done.txt
#各种替换姿势
Get-Content .\svn_ADD.txt | % {$_ -replace "^!\s+",""}|Set-Content 1.txt
Get-Content 1.txt | % {$_ -replace "^",'"'}|Set-Content 2.txt
Get-Content 2.txt | % {$_ -replace "$",'"'}|Set-Content 3.txt
 Get-Content 2.txt | % {$_ -replace "$",'"'} > 5.txt

#文件内替换
(Get-Content .\demo.txt).Replace('ma','999') |Set-Content .\demo.txt

#replace
PS C:> 'no alarms and no surprises' -replace '^no',''
alarms and no surprises
(Get-Content Input.json) `
  -replace '"(\d+),(\d{1,})"', '$1.$2' `
  -replace 'second regex', 'second replacement' |
  Out-File output.json


Get-Content -path "Input.json" | % { $_ -Replace '"(\d+),(\d{1,})"', '$1.$2' }

#permit run powershell script
Set-ExecutionPolicy Unrestricted
Set-ExecutionPolicy RemoteSigned

#$a=get-date 时间付给变量

#ouput with variable
PS D:\> $op_date=date
PS D:\> Write-Output "test1 & $op_date"
test1 & 09/04/2016 13:59:24
PS D:\> Write-Output "test1 $op_date";
test1 09/04/2016 13:59:24


#redirection
& myjob.bat 2>&1 >> C:\yLog.txt
~
 PowerShell CheatSheet – Regular Expressions
Fab 09/10/2012 News
Here is a regular expression list

. matches any character except newline
\ escape character
\w word character [a-zA-Z_0-9]
\W non-word character [^a-zA-Z_0-9]
\d Digit [0-9]
\D non-digit [^0-9]
\n new line
\r carriage return
\t tabulation
\s white space
\S non-white space
^ beginning of a line
$ end of a line
\A beginning of the string (multi-line match)
\Z end of the string (multi-line match)
\b word boundary, boundary between \w and \W
\B not a word boundary
\< beginning of a word
\> end of a word
{n} matches exaclty n times
{n,} matches a minimum of n times
{x,y} matches a min of x and max of y
(a|b) ‘a’ or ‘b’
* matches 0 or more times
+ matches 1 or more times
? matches 1 or 0 times
*? matches 0 or more times, but as few as possible
+? matches 1 or more times, but as few as possible
?? matches 0 or 1 time


解除powershell脚本允许限制，使用管理账户运行
 PS C:\WINDOWS\system32> Set-ExecutionPolicy Unrestricted
PS C:\WINDOWS\system32> Get-ExecutionPolicy
Unrestricted


###########batch update multiple proxyAddress#####
Import-CsvC:\Users\someone\Desktop\user20171205.csv|
foreach{
##set SMTP
$user=get-aduser $_.username -Properties mail,department,ProxyAddresses
$user.ProxyAddresses = 'SMTP:' + $_.username + '@example.com'
set-aduser -instance $user
##SET multiple smtp
get-aduser $_.username |Set-ADUser -add @{Proxyaddresses="smtp:" + $_.username + "@eg2.com" }
##view user ProxyAddresses
get-aduser $_.username -Properties mail,department,ProxyAddresses
}
###########batch update multiple proxyAddress#####



######batch update proxyAddress of AD user                               
Import-Csv C:\Users\user\Desktop\usertxt.csv |
foreach{
$user=get-aduser $_.username -Properties mail,department,ProxyAddresses
$user.ProxyAddresses = 'SMTP:' + $_.username + '@example.com'
set-aduser -instance $user
}

######batch update proxyAddress of AD user                               


#######batch deploy linux Azure vm use csv
方法0 使用CSV格式(推荐)
需要I:\batch_deploy_vm.csv这个文件,
列名分别是myvmname和myipaddr,
值分别是
Jia    10.0.0.21
Yi     10.0.0.29
都不用引号



$MYSIZE="Small"
$myimage="zxc-centos"
$myuser="zhangsan"
$mypass="password"
$mycloud="my-cloud"
$mynet="my-net"
$mysubnet="subnet-1"

Import-Csv I:\batch_deploy_vm.csv |
foreach{
New-AzureVMConfig -name  $_.myvmname -InstanceSize $MYSIZE -ImageName $myimage |
Add-AzureProvisioningConfig -Linux -LinuxUser $myuser -Password $mypass |
Set-AzureSubnet $mysubnet |
Set-AzureStaticVNetIP $_.myipaddr |
New-AzureVM -ServiceName $mycloud -VNetName $mynet
}

######End powershell.memo #######
######Endmemoof powershell.memo #######
######Startmemoof pythondemo.py #######
######Start pythondemo.py #######
http://ginstrom.com/scribbles/2009/09/14/easy-sftp-uploading-with-paramiko/ Easy SFTP uploading with paramiko

https://paramiko-docs.readthedocs.io/en/1.15/api/sftp.html 
https://www.liaoxuefeng.com/ python教学


#########sftp update file#####
1 link
http://mingxinglai.com/cn/2015/06/paramiko/
https://paramiko-docs.readthedocs.io/en/1.15/api/sftp.html


2 code

# -*- coding:utf-8 -*-
import paramiko
ssh = paramiko.SSHClient()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
ssh.connect("ip-or-host" ,port_number , "user", "passwd")

sftp = paramiko.SFTPClient.from_transport(ssh.get_transport())
sftp = ssh.open_sftp()
sftp.chdir('operation_dir')
sftp.put('/exact/path/2/local_file', 'remote_file')


#########sftp update file#####






####read staff from stdin to var,stdout to file

#-*- coding:utf-8 -*-
import os
def main():
    file_handle = open("1.txt","a")                              ###define open file's handle,append style,"w" is rewrite style
    name = raw_input("waht's your name:")                        ###keyboard input to name var
    print >>file_handle, ("Nice to meet you " + name +"!")       ###Output to file,not support '>' operation
    file_handle.close()
if __name__ == '__main__':
    main()

####read staff from stdin to var,stdout to file

#####call system cmd and get return code,suppress stdout and errout
# -*- codingi:utf-8 -*-
import os
import subprocess
def ping_check(var_hostname):                                                                     ####can not use - to link 
    devnull = open(os.devnull,'w')                                                                ####link to /dev/null
    response = subprocess.call \                                                                  ####use \ span lines
    (["ping","-c","1",var_hostname],stdout=devnull,stderr=devnull)                                ####PATT CMD PARA var
    return response

def main():
    flag = ping_check("192.168.5.3")
    print flag

if __name__ == '__main__':
    main()    
#####call system cmd and get return code,suppress stdout and errout


#########function call and return 
# -*- codingi:utf-8 -*-

def main():
    sum = add(3,5)                                                                                                                                                       
    print sum
def add(foo,bar):
    res = foo + bar
    return res

if __name__ == '__main__':
    main()

#########function call and return 






# -*- coding: utf-8 -*-
# 给 Python 初学者的超快速脚本解说

import os

def main(): 
    print '你好, 世界!'
    print "单引号，双引号，其实是一码事"
    print '字符串内的引号需被转义(如 O\'Neil)'
    print "换个不同的引号就无需转义了(看 O'Neil)"
    
    print """三引号（亦可以是三个单引号）可以安全地处理单双引号混用，例如：
    O'Neil 说: "姚明太瘦。"
    姚明说: "O'Neil 太老。"
而且还能跨行，跨行后的格式也能被保留。
"""
    
    print '=' * 10
    print '这将直接执行', os.getcwd()
    
    add(5, 10)

    counter = 0
    counter += 1

    food = ['苹果', '杏子', '李子', '梨']
    for i in food:
        print '俺就爱整只: %s' % i

    print '从0数到9'
    for i in range(10):
        print i




def add(param1, param2):
    """做了点加法.
喔，其实还胡乱判断了一气。
    """
    # 这也是一个注释。
    res = param1 + param2
    print '%s + %s = %s' %(param1, param2, res)
    
    if res < 50:
        print '这个这个'
    elif res >= 50 and (param1 == 42 or param2 == 24):
        print '那个那个'
    else:
        print '嗯哼...'
        
    return r es      # 注释还可以像这样直接跟在一句代码的后面

if __name__ == '__main__':
    main()

###########call linux command in python##########
$>cat dp.py   ##code
# -*- coding: utf-8 -*-

import subprocess

def main():
    subprocess.call("date")
    subprocess.call(["ls","-l","/home/Michael/dp.py"])

if __name__ == '__main__':
    main()


$> python dp.py  ####run 
Tue Jan 16 15:19:08 CST 2018
-rwxr-xr-x 1 Michael users 178 Jan 16 15:18 /home/Michael/dp.py

###########call linux command in python##########



#####文件中添加行
####https://stackoverflow.com/questions/10507230/insert-line-at-middle-of-file-with-python
def add_line_in_file(index,value):
    file_handler = open("file","r")
    content = file_handler.readlines()
    file_handler.close

    content.insert(index,"value\n")
    file_handler = open("file","w")
    content = "".join(content)
    file_handler.write(content)
    file_handler.close()


##refer to
##http://cmdlinetips.com/2011/08/three-ways-to-read-a-text-file-line-by-line-in-python/
# -*- coding: utf-8 -*-
import os

def read_a_file_line_by_line():
    file_hander = open('file','r+')
    for line in iter(file_hander):
        print line
    file_hander.close()





##########regex replace file for all line in a file
#########https://stackoverflow.com/questions/18935626/regex-re-sub-list-in-a-file
def replace_in_place_in_file():
        output = open("regex_replace_out_file","w")
        input = open("regex_replace_file","r")

        for line in input:
            output.write(re.sub("regex_pattern","will_be_replaced_string", line))                                       
        input.close()
        output.close()
        os.remove("regex_replace_file")  ###不优雅
        os.rename("regex_replace_out_file","regex_replace_file")



####http://pythontesting.net/python/regex-search-replace-examples/
######regex replace file for all line in a file###
#######PERFECT###############
####and https://pymotw.com/2/fileinput/ common replace
####call by
######python regex_replace_in_file.py example.txt
import fileinput,re
def replace_in_place_in_file():

        for line in fileinput.input(inplace=1, backup='.bak'):
            line = re.sub('regex_pattern','will_be_replaced_string', line.rstrip())
            print(line)
###The fileinput module takes care of the stream verses filename input handling.
###The re (regex, regular expression) module has sub which handles the search/replace.
###The ‘rstrip’ is called on the input just to strip the line of it’s newline, since the next ‘print’ statement is going to add a newline by default.
###If you leave the ‘backup’ flag out, no backup will be made.
###As I’ve shown it with backup=’.bak’, an example.txt.bak file will be created.



###########detect port if open
###https://stackoverflow.com/questions/19196105/python-how-to-check-if-a-network-port-is-open-on-linux
# -*- coding: utf-8 -*-
import socket 
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
result = sock.connect_ex(('ip_or_host',port_number))
if result == 0:
    print "Port is open"
else:
    print "Port is not open"




##############mysql operation
############http://www.runoob.com/python/python-mysql.html
import MySQLdb
# 打开数据库连接
db = MySQLdb.connect("server_ip_or_host","user","pwd","DB_name" )

# 使用cursor()方法获取操作游标 
cursor = db.cursor()

# 使用execute方法执行SQL语句
cursor.execute("SELECT VERSION()")

# 使用 fetchone() 方法获取一条数据库。
data = cursor.fetchone()

print "Database version : %s " % data




cursor.execute("DROP TABLE IF EXISTS EMPLOYEE")

# 创建数据表SQL语句
sql = """CREATE TABLE EMPLOYEE (
         FIRST_NAME  CHAR(20) NOT NULL,
         LAST_NAME  CHAR(20),
         AGE INT,  
         SEX CHAR(1),
         INCOME FLOAT )"""

cursor.execute(sql)


# SQL 插入语句
sql = """INSERT INTO EMPLOYEE(FIRST_NAME,
         LAST_NAME, AGE, SEX, INCOME)
         VALUES ('Mac', 'Mohan', 20, 'M', 2000)"""
try:
   # 执行sql语句
   cursor.execute(sql)
   # 提交到数据库执行
   db.commit()
except:
   # Rollback in case there is any error
   db.rollback()

# SQL 查询语句
sql = "SELECT * FROM EMPLOYEE \
       WHERE INCOME > '%d'" % (1000)
try:
   # 执行SQL语句
   cursor.execute(sql)
   # 获取所有记录列表
   results = cursor.fetchall()
   for row in results:
      fname = row[0]
      lname = row[1]
      age = row[2]
      sex = row[3]
      income = row[4]
      # 打印结果
      print "fname=%s,lname=%s,age=%d,sex=%s,income=%d" % \ 
             (fname, lname, age, sex, income )
except:
   print "Error: unable to fecth data"


# SQL 更新语句
sql = "UPDATE EMPLOYEE SET AGE = AGE + 1 WHERE SEX = '%c'" % ('M')
try:
   # 执行SQL语句
   cursor.execute(sql)
   # 提交到数据库执行
   db.commit()
except:
   # 发生错误时回滚
   db.rollback()


# SQL 删除语句
sql = "DELETE FROM EMPLOYEE WHERE AGE > '%d'" % (20)
try:
   # 执行SQL语句
   cursor.execute(sql)
   # 提交修改
   db.commit()
except:
   # 发生错误时回滚
   db.rollback()

# 关闭数据库连接
db.close()                     
######End pythondemo.py #######
######Endmemoof pythondemo.py #######
######Startmemoof screen.memo #######
######Start screen.memo #######
########screen config 20170320######
###prex-key(ie Ctrl+a) + Esc and up row scroll
hardstatus on
hardstatus alwayslastline
hardstatus string "%{.bW}%-w%{.rW}%n %t%{-}%+w %=%{..G} %H %{..Y} %m/%d %C%a "
defscrollback 2048
##bind shorcut Fn to switch screen
##f10-->k; select 0
##f11-->F1 monitor
##f12-->F2 kill
##f7--->k7 new screen
##f8--->k8 title screen
bindkey -k k1 select 1
bindkey -k k2 select 2
bindkey -k k3 select 3
bindkey -k k4 select 4
bindkey -k k5 select 5
bindkey -k k6 select 6
bindkey -k k7 screen
bindkey -k k8 title
bindkey -k k9 time
bindkey -k k;  select 0
bindkey -k F1  monitor
bindkey -k F2  kill
##initial named session
screen -t cfg 1 bash
screen -t run 1 bash
screen -t log 1 bash
screen -t dbg 1 bash
screen -t misc 1 bash
##initail screen from 1
bind c screen 1
bind ^c screen 1
bind 0 select 10
screen 1
########screen config 20170320 END######

hardstatus on
hardstatus alwayslastline
hardstatus string "%{.bW}%-w%{.rW}%n %t%{-}%+w %=%{..G} %H %{..Y} %m/%d %C%a "
##scroll 2048 line
defscrollback 2048
##bind shorcut Fn to switch screen
bindkey -k k1 select 1
bindkey -k k2 select 2
bindkey -k k3 select 3
bindkey -k k4 select 4
bindkey -k k5 select 5
##initial named session
screen -t config 1 bash
screen -t debug 1 bash
screen -t test 1 bash
screen -t misc 1 bash
##initail screen from 1
bind c screen 1
bind ^c screen 1
bind 0 select 10
screen 1
termcapinfo xterm* ti@:te@

#############################
#############split view#########
http://unix.stackexchange.com/questions/7453/how-to-split-the-terminal-into-more-than-one-view
You can do it in screen the terminal multiplexer.
here ctrla is press Ctrl + a
To split vertically: ctrla then |.
To split horizontally: ctrla then S (uppercase one).
To unsplit: ctrla then Q (uppercase one).
To switch from one to the other: ctrla then tab
Note: After splitting, you need to go into the new region and start a new session via ctrla then c before you can use that area.

EDIT, basic screen usage:

New terminal: ctrla then c.
Next terminal: ctrla then space.
Previous terminal: ctrla then backspace.
N'th terminal ctrla then [n]. (works for n∈{0,1…9})
Switch between terminals using list: ctrla then " (useful when more than 10 terminals)
Send ctrla to the underlying terminal ctrla then a.

#############################
###split view end###

for centos 7 title
I am using bash and GNU screen on centos7. I notice that if I ssh to another server, change the title (via ctrl+a+A), and log out of the server that my new title gets overwritten by USER@HOST:~. How can I stop it from doing this?

As documented in the man page, screen looks for a null title-escape-sequence. bash sends this sequence via the PROMPT_COMMAND environment variable (for example, mine defaults to printf "\033k%s@%s:%s\033\\" "${USER}" "${HOSTNAME%%.*}" "${PWD/#$HOME/~}".

To disable this feature for a particular window, I just run unset PROMPT_COMMAND from that window. Of course, one could just add this to their ~/.bashrc or to a specific environment file to make it more persistent.
shareimprove this answer

add unset PROMPT_COMMAND  TO ~/.bashrc end or /etc/profile end

If $PROMPT_COMMAND is empty, check $PS1. – choroba Oct 22 '14 at 22:44
######End screen.memo #######
######Endmemoof screen.memo #######
######Startmemoof tmux.memo #######
######Start tmux.memo #######
tmux.conf
set -g prefix M-q  

#设置前缀为Ctrl + x
#set -g prefix C-x

#解除Ctrl+b 与前缀的对应关系
unbind C-b

#将r 设置为加载配置文件，并显示"reloaded!"信息
bind r source-file ~/.tmux.conf \; display "Reloaded!"

#copy-mode 将快捷键设置为vi 模式
setw -g mode-keys vi

# zoom pane <-> window
#http://tmux.svn.sourceforge.net/viewvc/tmux/trunk/examples/tmux-zoom.sh
bind ^z run "tmux-zoom"
##

switch  sesseion               Prex + s
detatch sesseion               Prex + z
enter copy mode                Prex + [
paste recently                 Prex + ]
chosse paste                   Prex + =
delete paste buffer            Prex + -
create horizontally            Prex + %
create vertically              Prex + "
switch pane                    Prex + Array
swith windows                  Prex + Windows number
name  session                  Prex + $
name  window                   Prex + ,
create window                  Prex + c
create sesseion                tmux
link to named session          tmux a -t session-name
create session                 tmux new-session -s session-name
scroll                         Prex + [ or Prex + PageUP //input 'q' exit scroll 




######End tmux.memo #######
######Endmemoof tmux.memo #######
######Startmemoof favourite.memo #######
######Start favourite.memo #######
https://superuser.com/
https://stackoverflow.com/
https://www.quora.com
https://unix.stackexchange.com/questions/ask
https://github.com/alexanderzobnin/grafana-zabbix/wiki/Usage 
 https://www.freedesktop.org/wiki/Software/systemd/
http://0pointer.de/blog/projects/systemd.html

https://google.github.io/styleguide/shell.xml google shell style

http://apprize.info/programming/awk/16.html   awk debug

www.msdmanuals.com  默沙东诊疗手册  优秀的医疗手册
美国新泽西州凯尼尔沃思 Merck and Co., Inc.（美加以外地区称为默沙东）
是努力改善全球福祉的健康护理引领者。从开发治疗和预防疾病的新疗法，
到满足人们需求，我们致力于改善全世界人们的健康和福祉。 本手册于 1899 年
作为一项社区服务首次出版。 此宝贵资源将继续传承下去，在美加拿大地区被称
作《默克诊疗手册》，在世界其余地区被称作《默沙东诊疗手册》。详细了解
我们对全球医学知识的承诺。

https://www.ssavr.com/  copy file/txt message on LAN 


Meltdown and Spectre linux
https://medium.com/@mattklein123/meltdown-spectre-explained-6bc8634cc0c2 
https://forums.opensuse.org/showthread.php/528929-CPU-critical-bugs-Meltdown-and-Spectre   Thread: CPU critical bugs Meltdown and Spectre
https://www.cyberciti.biz/faq/patch-meltdown-cpu-vulnerability-cve-2017-5754-linux/
https://www.cyberciti.biz/faq/install-update-intel-microcode-firmware-linux/
https://www.howtogeek.com/338801/how-to-check-if-your-pc-is-protected-against-meltdown-and-spectre/
https://www.windowscentral.com/how-check-if-your-pc-still-vulnerable-meltdown-and-spectre-exploits
https://www.ostechnix.com/check-meltdown-spectre-vulnerabilities-patch-linux/
https://www.cyberciti.biz/faq/check-linux-server-for-spectre-meltdown-vulnerability/


https://blog.scottlowe.org/2013/09/04/introducing-linux-network-namespaces/   Introducing Linux Network Namespaces


https://www.percona.com/blog/2015/07/01/using-cgroups-to-limit-mysql-and-mongodb-memory-usage/           Using Cgroups to Limit MySQL and MongoDB memory usage


http://www.techpaste.com/2016/04/limit-mongodb-memory-usage/

http://colobu.com/2015/07/23/Using-Cgroups-to-Limit-MongoDB-memory-usage/   使用cgroups限制MongoDB的内存使用

http://www.cnblogs.com/sparkdev/p/7258507.html PowerShell 脚本中的密码加密
###jenkins gitlab
https://hub.docker.com/r/jenkins/jenkins/
https://github.com/jenkinsci/docker/blob/master/README.md
rttps://docs.gitlab.com/omnibus/docker/README.html


https://yeasy.gitbooks.io/docker_practice/content/ Docker — 从入门到实践

http://mingxinglai.com/cn/2014/03/copy-file-in-linux/  Linux下常用的文件传输方式介绍与比较
http://learnvimscriptthehardway.stevelosh.com/ vim tuitor very beautiful

<<<<<<< HEAD
=======
https://www.percona.com/blog/2014/08/26/mysqld_multi-how-to-run-multiple-instances-of-mysql/ 

>>>>>>> 97625a5b5b4fe93d909d859343b9da7bf9632991
https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/00138683229901532c40b749184441dbd428d2e0f8aa50e000  python教材

http://harttle.com/2015/11/04/vim-ide.html 如何用Vim搭建IDE？

http://harttle.com/2015/11/06/tmux-startup.html 优雅地使用命令行：Tmux 终端复用

site:115.com |site:pan.baidu.com |site:dbank.com |site:vdisk.weibo.com |site:weiyun.com
vim pattern
http://vimdoc.sourceforge.net/htmldoc/pattern.html#/%5C%25c

https://www.tecmint.com/sftp-command-examples/https://www.tecmint.com/sftp-command-examples/ 10 sFTP Command Examples to Transfer Files on Remote Servers in Linux
https://www.digitalocean.com/community/tutorials/how-to-enable-sftp-without-shell-access-on-centos-7 How To Enable SFTP Without Shell Access on CentOS 7
https://stackoverflow.com/questions/432385/sftp-in-python-platform-independent SFTP in Python? (platform independent) - Stack Overflow


http://mingxinglai.com/cn/ Linux c c++ mysql Chinese blog
http://mobaxterm.mobatek.net/download.html   ssh vnc telnet rdp 工具Windows版本，
免费，自带miniLinux，自动字体缩放，Linux copy&paste 风格，值得拥有
个人版仅支持10个保存的会话


bginfo systemnals.com出品，显示系统信息到桌面，RDP的好搭档
Using BgInfo to Display System Information on the Desktop




ditto windows下的高级copy工具，和Linux下的工具一样，支持搜索，热键ctrl+~
https://coyee.com 可译网 在线双语对照翻译


https://www.cs.oberlin.edu/~kuperman/help/vim/home.html vimrc 配置项目
https://leetcode.com/ your-name@h 在线编程测试，支持C/C++/PYTHON/Java等
http://www.server-world.info/en/   CentOS 7 文档
http://www.h3c.com/cn/Service/Document_Center/Switches/ 华为交换机手册
http://www.tutorialspoint.com/jenkins/ jenkins
http://kodango.com/ linux 运维开发
http://man.he.net/  在线MAN 文档齐全
https://certificatechain.io/  get ca chain 证书链
https://shaaaaaaaaaaaaa.com/   弱sha hash CA 监测 weak
https://httpsecurityreport.com/  https 测试
https://my.freenom.com/clientarea.php 免费域名管理
http://www.dot.tk/en/index.html?lang=en 免费域名注册
https://www.songsan.tk 免费域名
https://www.namecheap.com/support/knowledgebase/article.aspx/795/69/how-to-install-ssl-certificates 各平台安装ssl
https://www.leakedsource.com/ 检查网络帐号是否泄漏
http://meldmerge.org/features.html   melt 文档差异比较 用于代码编辑 跨平台
https://www.ssllabs.com/   ssl 安全测试
https://regex101.com/ 正则测试 优
http://www.regexe.com/  支持替换
http://regexr.com/ 支持替换
https://www.freeformatter.com/regex-tester.html 支持替换
http://regexstorm.net/tester 支持替换 慢啊
https://www.debuggex.com/  正则测试
https://jex.im/regulex  正则测试 图解优
http://www.regexpal.com/94055 nginx正则测试 优-
http://tool.oschina.net/regex# 中文 支持常用正则列表与替换
https://twofactorauth.org/ 检查是否支持多因子验证
https://github.com/koalaman/shellcheck脚本测试
powershell  http://www.pstips.net/powershell-online-tutorials/   
http://docs.ansible.com/ansible/ 
https://github.com/AnthoneyMichale
http://www.chartgeek.com/wp-content/uploads/2015/04/Game-of-Thrones-Character-Relationships.png
http://gameofthrones-gotseries.rhcloud.com/game-of-thrones-characters-and-relationships/    game of thrones characters relationships 权利的游戏人物关系图
http://www.cnblogs.com/gaizai/p/3644510.html MSSQL负载均衡


corosync
http://clusterlabs.org/doc/en-US/Pacemaker/1.1/html-single/Clusters_from_Scratch/
http://freeloda.blog.51cto.com/2033581/1274533
http://freeloda.blog.51cto.com/2033581/1275384
http://freeloda.blog.51cto.com/2033581/1275528
http://clusterlabs.org/doc/en-US/Pacemaker/1.1/html/Clusters_from_Scratch/ 
http://clusterlabs.org/doc/zh-CN/Pacemaker/1.1-plugin/html-single/Clusters_from_Scratch/#_quorum_and_two_node_clusters


https://awstcocalculator.com/  AWS Total Cost of Ownership (TCO) Calculator
http://calculator.s3.amazonaws.com/index.html  SIMPLE MONTHLY CALCULATOR
http://media.amazonwebservices.com/AWS_Security_Best_Practices.pdf
https://evantage.gilmoreglobal.com/#/books/100-ARC-46-EN-SG-E/recentm?,
http://www.yworks.com/downloads#yEd 拓扑图工具
http://www.gingersoftware.com/zh/grammarcheck#.VS-rjM1d601 在线语法检查
http://www.engvid.com/
https://www.voicetube.com
www.oxforddictionaries.com/us
www.engvid.com
engfluent.com/english-pronunciation-exercises-main-sounds/
Google Dictionary (by Google) 4.0.2
crxMouse Chrome Gestures 2.8.2
https://archive.apache.org/dist/lucene/solr/ref-guide/apache-solr-ref-guide-4.5.pdf
https://www.youtube.com/watch?v=irQVUlXP4y4 35：00


http://pecl.php.net/


https://wiki.wireshark.org/SampleCaptures 
如果看了这个你还是不会用Wireshark，那就来找我吧（8月6日完结）
https://community.emc.com/thread/194901


http://daily.zhihu.com/story/7428446  
一些玩物不丧志，能学到知识的游戏
http://m.shopex.cn/products/ecshop/
商派云 开源PHP B2C商城服务端


http://www.makeuseof.com/tag/watch-space-documentaries-universe/ save？


http://www.coreseek.com/ 
Coreseek开源中文检索引擎-Sphinx中文版


http://zyan.cc/tech/  我的技术文章与计算机作品汇总页 linux mysql nginx apache php


http://www.julyedu.com/index.php 七月算法


http://www.zhihu.com/roundtable/kitchen  
厨房的秘密


图文详细解析单反的用法  http://seyingwuji.lofter.com/post/d18a4_7871877


http://engfluent.com/english-pronunciation-exercises-main-sounds/ improve english pronunciation


http://www.javatpoint.com/php-form  php-formhttp://nuclearweaponarchive.org/   The Nuclear Weapon Archive https://en.wiktionary.org/wiki/Wiktionary:Main_Page  维基词源
http://cuiqingcai.com/1052.html  Python爬虫学习系列教程 http://www.slideshare.net/  ppt在线http://millionbook.net/gt/g/gaoyang/cxqz/index.html 高阳 慈禧全传Www.online-convert.com 在线格式转换http://lifehacker.com/how-to-improve-your-home-cooking-with-the-power-of-scie-511405909
How to Improve Your Home Cooking with the Power of Science


5 Must-See Documentaries About Hacking and Hackershttp://www.makeuseof.com/tag/must-see-documentaries-hacking-hackers/
XMind:超越FreeMind的思维导图软件（有中文官网啦！--看起来还不错，支持windows/linux 免费？？？http://xbeta.info/xmind.htm
51talk.com abc360.com http://www.haibian.com/
在线教育
http://www.makeuseof.com/tag/love-movies-awesome-youtube-channels-need-watch/
Love Movies? 4 Awesome YouTube Channels You Need to Watch


http://www.makeuseof.com/tag/5-sites-nature-background-sounds-white-noise-help-focus/ 
5 Sites with Nature Background Sounds & White Noise to Help You Focus


http://www.makeuseof.com/tag/10-fascinating-engineering-channels-youtube/
10 Fascinating Engineering Channels on YouTube


http://www.makeuseof.com/tag/test-home-network-security-free-hacking-tools/ How To Test Your Home Network Security With Free Hacking Tools  


滴灌卖家 绿之美 霖又多
http://hongruichun8812.taobao.com/index.htm?spm=2013.1.w5002-5389937205.2.8DBsI8&v=1
http://shop105019396.taobao.com/category-750860805.htm?spm=2013.1.w5002-10812903950.4.NHdiBD&search=y&catName=%B5%CE%B9%E0%CF%B5%C1%D0&v=1 http://www.wastewatersystems.com/bioline.html


http://www.zixue.it/    自学IT网http://www.makeuseof.com/tag/11-unbelievable-super-slow-mo-videos-record/ 超高速摄影 视频 11 Unbelievable Super Slow-Mo Videos (And How to Record Your Own)
Sublime Text 编辑器http://sphinxsearch.com/ mysql中文全文索引


http://www.etymonline.com/index.php 词源学查询网址


Speaky  http://www.gospeaky.com/  和外国人讲英语


http://qixing.8264.com/ 骑行天下 户外旅行


http://user.yeeyan.org/articles/504726/source  译言 朱贝壳


http://www.vaikan.com/  外刊IT评论


http://ping.eu/ping/  online ping


http://www.zhihu.com/question/26822388/answer/34191366 
地球上有哪些裸眼可直接观察到的，极其震撼的太空景象？


http://www.amandatastes.com/   曼食慢语


http://www.javatpoint.com/jsp-page-directive JSP 20150322


IT英文电子书下载地址
http://it-ebooks.info/


http://www.wolfexp.net/gh_e1d13f14e227/56888.html excel技巧


http://www.xfeater.com/page/SAP-BI-BW-%E9%A1%BE%E9%97%AE%E9%9D%A0%E6%89%8B   
SAP BI BW 顾问靠手


4. Urban dictionary
俚語粗話網路用語通通給你！
語言隨著時代演進，無庸置疑。中文是如此，英文亦是如此。想想現在時下年輕人常說的，很瞎很潮，你魯蛇我溫拿，在一般字典理因找不著。Urban dictionary 囊括各種很潮的英文俚語，很潮的各位一定要善用它！


SiWanYi 关于大型网站技术演进的思考（十）--网站静态化处理—动静整合方案（2）http://blog.jobbole.com/84328/


http://www.playpcesor.com/2015/02/chinese-language-learning.html


兽行种种（15）那些吊炸天的化学实验 图片有意思 没有流量了，未存


http://www.ruanyifeng.com/blog/archives.html 阮一峰博客文集目录


CSS


1、https://qqgroup.insight-labs.org
     看看别人的QQ都有哪些好友关系，嘿嘿！！


2、http://www.reg007.com
     忘记了你注册过哪些网站？一搜便知！！


4、http://diaos123.com     简洁有内涵！！无任何广告/弹窗，良心站！！！我一直设置为主页，嘿嘿


5、http://www.fanhao520.com/   番号，你懂的！！ 。。


7、http://www.flvcd.com/   想珍藏你喜欢的在线视频，又不支持下载？有了这个网站后就不在是问题了
HTTPS://www.random.org 牛哄哄的真随机数生成网http://www.mathpapa.com/ mathpapa 分步骤解决代数题目，比如方程


http://www.yiym.com/  http://onlineslangdictionary.com/ 英语俚语解释网站


在线英语字典 http://dictionary.cambridge.org/ (有发音,有中文) 
http://dictionary.reference.com/  
http://www.oxforddictionaries.com/ (牛津英语,有短语的解释,有例句发音,音节标注,推荐)
http://www.thefreedictionary.com/


http://deeplearning.cs.toronto.edu/i2t 人工智能 看图说话 图片转文字


https://zygotebody.com 人体结构 需要谷歌帐号登录 付费有精确模型


http://episte.math.ntu.edu.tw/ 数学知识网  


http://www.junyiacademy.org/ 台湾均一教育平台 数学 生物


第9阅览室 http://9yls.net/ 


https://www.youtube.com/watch?v=Gy6qC92bCCM&list=PLXH05kw-i_5JhnABOgMHXS0UOM57ysdc- 指数生成函数 GOOGLE选4任排


https://www.youtube.com/watch?v=IITw5kUaijc&index=8&list=PLXH05kw-i_5LXMMDw4Kbry-FoHsOrzWH4 统计上的负二项式分布(?)


http://www.wolframalpha.com/ 数学在线计算画图求解网站 http://mathworld.wolfram.com/  


http://blog.csdn.net/acdreamers/article/details/9314913 生成函数
http://blog.csdn.net/qq429205464/article/details/6963265 


 http://www.kikinote.com/article/30378.html    免费美国电话 语音短信 http://pinger.com/textfree/ 
http://sofree.cc/sip-iptel-ipkall/  http://www.henghengzhu.com/share/36.html 
【免費美國電話號碼】綁定LINE手機號碼 ; 可收驗證碼 / 語音簡訊 ─ Pinger TextFree 安裝教學 (Android/iOS)
http://ocw.nctu.edu.tw/course_detail_3.php?bgid=9&gid=0&nid=252&v1=67ae94cd11239d21d122ea13d6f1cfeca1f826c5 离散数学 高级计算技术(?)
http://ocw.nctu.edu.tw/course_detail_3.php?bgid=9&gid=0&nid=252&v1=e4d7203a181c2508ebf90ebec8f771f635c38c55#.VG6qbZBJOl0 离散数学 数学归纳法证明


http://ocw.nctu.edu.tw/course_detail_3.php?bgid=9&gid=0&nid=252&v1=4fefe1a913c9589544aef4fef7249e225ffe4bd6 离散数学 排列组合


http://www.vaikan.com/  http://rss.aqee.net/ 外刊IT评论 http://www.fulltextrssfeed.com/  全文RSS转换网址  http://www.wizardrss.com/ (好用一些)   http://www.wmutils.com/fulltextrss/
Full Text RSS Feed Builder
https://www.youtube.com/watch?v=8uE_Q5yXH3Y&index=3&list=PLvWQohjH8rwhbO6JvCbzX3jQ7JOcU75GI 6' 离散数学 離散數學 Discrete Mathematics http://ocw.nctu.edu.tw/course_detail_3.php?bgid=9&gid=0&nid=252


FullyFeedly - Chrome Web Store - Google rss全文阅读扩展,加载缓慢,坑爹啊


http://civil.nju.edu.tw/weng/excel/ excel高级数据数学计算 矩阵,行列式,线性规划,高次方程求解


http://blogs.technet.com/b/markrussinovich/archive/2011/02/27/3390475.aspx Windows sysinternal 应用博客
阶乘FACT,组合combin,排列permut EXCEL函数
http://barrons.blog.caixin.com/archives/54496 图解贝叶斯公式


ttps://defuse.ca/big-number-calculator.htm  在线大数相乘结果


http://mindlee.net/ 酷行天下 中文算法blog,还不错


https://www.youtube.com/watch?v=18_91wFdcW8 堆排序,印度人讲的还不错,没有字幕.


http://www.cs.princeton.edu/~wayne/cs423/demos.html 算法动画,需要java8 runtime environment


维度：数学漫步 Dimensions: A Walk Through Mathematics (2008)
http://www.dimensions-math.org/Dim_ZH_si.htm douban.com


 http://www.vmware.com/cn/products/vsphere/features vmware xsphare特性
https://my.vmware.com/cn/web/vmware/evalcenter?p=vmware-vsphere-operations&src=PaidSearch_Google_LeadGen_CN_ZH&cid=70180000000Mc5Y&mkwid=sNVzs126K&pcrid=34941696392&kw=vmware%20esxi%204.1%20download&mt=b&utm_source=google&utm_medium=cpc&utm_term=vmware%20esxi%204.1%20download&utm_content=34941696392&utm_campaign=GS_VMSMB_DESK_CN_EN_B_BPD_Esx&gclid=CjwKEAjwzqKiBRCAydTZzOLi9CISJACm3irWPnfNVabb4AGJSTe-U4_Tti5XAi62Mnn4BV93lb8-CBoCWgPw_wcB
VMWARE企业版文档
http://www.datapointed.net/visualizations/math/factorization/animated-diagrams/ 因数分解,有点意思
http://technet.microsoft.com/en-us/library/dd277323.aspx rms部署 存档 http://technet.microsoft.com/en-us/library/cc753531(v=ws.10).aspx


奥斯卡 86届 http://www.iqiyi.com/w_19rr0tg6xp.html


http://keepvid.com/ http://en.savefrom.net/ youtube 下载http://keepsubs.com/ 在线下载YOUTUBE字幕 http://mo.dbxdb.com/Yang/
http://www.yyets.com/ 电影字幕下载 电视剧字幕下载 射手网 YYETShttp://www.cnblogs.com/skywang12345/ 算法BLOG,写的很细致
 全国企业信用信息公示系统 http://gsxt.saic.gov.cn/
https://www.youtube.com/watch?v=cJOHERGcGm4&list=PLDC836E1A1076378E&index=22 算法导论25 11:15
http://sxyd.sdut.edu.cn/ 数学http://episte.math.ntu.edu.tw/ 高等数学知识 台湾网站使用http://www.earthol.com/ 包含坐标的卫星地图http://www.lcsd.gov.hk/CE/Museum/Space/EducationResource/Universe/framed_c/lecture/ch01/ch01.html 
宇宙的本质,天文学,香港网站


http://technet.microsoft.com/en-us/library/cc753354(v=ws.10).aspx
微软有线认证接入解决方案


谷歌关键字wired authentication microsoft 802.1 x 


http://technet.microsoft.com/en-us/video 微软技术视频网(technet)http://www.masterhsiao.com.tw/ExcelFinance/PMT/PMT.htm
年金 Excel 房贷计算函数 PMT 怪老子理财（台湾）


http://scn.sap.com/community/erp/manufacturing-pp/blog/2013/12/08/book-outline-production-planning-and-control-with-sap-erp 
Book Outline: Production Planning and Control with SAP ERP 一本SAP生产模块的好书,没有找到电子版
http://www.sap-press.de/download/dateien/3052/sappress_production_planning_control_sap_erp.pdf 这是一个SAMPLE
https://www.sap-press.com/production-planning-and-control-with-sap-erp_3358/


http://www.sap-press.com/products/Production-Planning-and-Control-with-SAP-ERP.html? 在线购买,支持电子版本,支持中国?
思维导图
 http://www.zhihu.com/question/19651621


http://www.nuanhuhu.net/2011/01/02/mindmap1-job-hunting/ 
手绘思维导图(1)找工作——我是怎么用思维导图找到工作的


http://freemind.sourceforge.net/wiki/index.php/Main_Page   freemind


http://help.sap.com/saphelp_46c/helpdata/en/18/22b800773211d396b20004ac96334b/content.htm Basic Concepts of ALE Technology


http://publib.boulder.ibm.com/infocenter/domhelp/v8r0/index.jsp?topic=%2Fcom.ibm.help.domino.admin85.doc%2FH_SETTING_UP_A_PERSON_DOCUMENT_FOR_THE_CLIENT_2887_STEPS.html
 ibm domino notes 文档


http://v.pptv.com/show/KWUicvSWLibzmcGuY.html
http://v.youku.com/v_show/id_XNjQ0MTc5Mjg0.html
JAVA IDE eclipse
http://ishare.iask.sina.com.cn/f/36056292.html  大话数据结构下载 page 72


双城记
http://www.techonthenet.com/index.php SQL语法 程序语法 EXCEL函数 database语法


http://npz-xuexuexue.nipponpaint.com.cn/content/Course/ScoCourse.aspx?DB=DevDB&SessionID=6b25b52f-144e-4cac-a860-763db348db41 提高记忆力


http://www.kanterwang.cn/ SAP知识


http://ocw.nctu.edu.tw/course_detail_3.php?bgid=9&gid=0&nid=252#.VGCKLpBJOl0  台湾離散數學讲解 


http://nctucs.wordpress.com/2011/08/05/cs-ocw/ IT科学在线课程合集


https://www.debuggex.com/ 正则测试
https://jex.im/regulex 正则测试
https://github.com/koalaman/shellcheck脚本测试
powershell  http://www.pstips.net/powershell-online-tutorials/   
http://docs.ansible.com/ansible/ 
https://github.com/AnthoneyMichale
http://www.chartgeek.com/wp-content/uploads/2015/04/Game-of-Thrones-Character-Relationships.png
http://gameofthrones-gotseries.rhcloud.com/game-of-thrones-characters-and-relationships/    game of thrones characters relationships 权利的游戏人物关系图
http://www.cnblogs.com/gaizai/p/3644510.html MSSQL负载均衡


 http://dl.dbank.com/c0v74y2j5t 华为网盘 还可以下载 无需注册 略牛


http://meldmerge.org/features.html   melt 文档差异比较 用于代码编辑 跨平台
https://www.debuggex.com/ 正则测试
https://jex.im/regulex 正则测试
https://github.com/koalaman/shellcheck脚本测试
powershell  http://www.pstips.net/powershell-online-tutorials/   
http://docs.ansible.com/ansible/ 
https://github.com/AnthoneyMichale
http://www.chartgeek.com/wp-content/uploads/2015/04/Game-of-Thrones-Character-Relationships.png
http://gameofthrones-gotseries.rhcloud.com/game-of-thrones-characters-and-relationships/    game of thrones characters relationships 权利的游戏人物关系图
http://www.cnblogs.com/gaizai/p/3644510.html MSSQL负载均衡


site:115.com |site:pan.baidu.com |site:dbank.com |site:vdisk.weibo.com |site:weiyun.com |site:yunpan.360.cn |site:yun.baidu.com
https://www.sslforfree.com/ 免费ssl
https://my.freenom.com/clientarea.php 免费域名管理
http://www.dot.tk/en/index.html?lang=en 免费域名注册
https://www.songsan.tk 免费域名
https://www.namecheap.com/support/knowledgebase/article.aspx/795/69/how-to-install-ssl-certificates 各平台安装ssl
site:115.com |site:pan.baidu.com |site:dbank.com |site:vdisk.weibo.com |site:weiyun.com |site:yunpan.360.cn |site:yun.baidu.com
https://www.sslforfree.com/ 免费ssl
https://my.freenom.com/clientarea.php 免费域名管理
http://www.dot.tk/en/index.html?lang=en 免费域名注册
https://www.songsan.tk 免费域名
https://www.namecheap.com/support/knowledgebase/article.aspx/795/69/how-to-install-ssl-certificates 各平台安装ssl
https://www.leakedsource.com/ 检查网络帐号是否泄漏
http://meldmerge.org/features.html   melt 文档差异比较 用于代码编辑 跨平台
https://www.debuggex.com/ 正则测试
https://jex.im/regulex 正则测试
https://twofactorauth.org/ 检查是否支持多因子验证
https://github.com/koalaman/shellcheck脚本测试
powershell  http://www.pstips.net/powershell-online-tutorials/   
http://docs.ansible.com/ansible/ 
https://github.com/AnthoneyMichale
http://www.chartgeek.com/wp-content/uploads/2015/04/Game-of-Thrones-Character-Relationships.png
http://gameofthrones-gotseries.rhcloud.com/game-of-thrones-characters-and-relationships/    game of thrones characters relationships 权利的游戏人物关系图
http://www.cnblogs.com/gaizai/p/3644510.html MSSQL负载均衡

######End favourite.memo #######
######Endmemoof favourite.memo #######
######Startmemoof autoInstallMysql57.sh #######
######Start autoInstallMysql57.sh #######
#!/bin/bash
PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/root/bin:/usr/local/mysq/bin
export PATH
#srvIP="192.168.1.13"  ####ftp server,comment
ftpUser="username"
ftpPwd="dangerous"
mysqlPkg="mysql-5.7.17.tar.gz" ##需要boost版本
ftpPath="ftp://$srvIP/$mysqlPkg"
srcPath="/usr/local/src"
installPath="/usr/local/mysql"
dataPath="/data/mysql"
mysqlConf="/etc/my.cnf"
vmCpuCores=$(cat /proc/cpuinfo |grep processor |wc -l)
mv /tmp/$mysqlPkg $srcPath
cd $srcPath
##wget --user=$ftpUser --password=$ftpPwd $ftpPath  ####ftp wget comment 

#add mysql user
if [ `cat /etc/passwd|grep 'mysql' |wc -l` -eq 0 ];then
        groupadd -r mysql
        useradd -g mysql -s /sbin/nologin -g mysql -M mysql 
fi
yum install -y gcc-c++ ncurses-devel gcc gcc++ gcc-g77 openssl-devel cmake
tar zxf $mysqlPkg

cd $srcPath/mysql-5.7.17
cmake -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 \
 -DWITH_MEMORY_STORAGE_ENGINE=1 -DWITH_READLINE=1 \
 -DMYSQL_UNIX_ADDR=$installPath/mysql.sock -DMYSQL_TCP_PORT=3306 \
 -DENABLED_LOCAL_INFILE=1 -DWITH_PARTITION_STORAGE_ENGINE=1 -DEXTRA_CHARSETS=all \
 -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DMYSQL_USER=mysql -DWITH_DEBUG=0 -DWITH_SSL=system \
 -DWITH_BOOST=/usr/local/src/mysql-5.7.17/boost/boost_1_59_0
if [ $? -eq 0 ];then
      make -j $vmCpuCores
fi

if [ $? -eq 0 ];then
      make install
fi
mkdir -p $dataPath
chmod +w $installPath
chown -R mysql.mysql $installPath
chown -R mysql.mysql $dataPath
cd $srcPath/mysql-5.7.17/support-files/


###cp $srcPath my.cnf to /etc/my.cn
###MUST include Correct datadir and basedir in my.cnf
###First touch my.cnf in $srcPath 
cp  $srcPath/my.cnf $mysqlConf

chown -R mysql.mysql $installPath  #basedir and data dir need exactly path 

####if $dataPath not EMPTY ,get error,rm everything in $dataPath
$installPath/bin/mysqld --initialize --basedir=$installPath --datadir=$dataPath --user=mysql

cp $srcPath/mysql-5.7.17/support-files/mysql.server /etc/init.d/mysqld

chmod +x /etc/init.d/mysqld

systemctl enable mysqld
systemctl start mysqld
ln -s $installPath/bin/* /bin/

echo "Install mysqld successful"
######End autoInstallMysql57.sh #######
######Endmemoof autoInstallMysql57.sh #######
######Startmemoof readfilelinebyline.py #######
######Start readfilelinebyline.py #######
##refer to
##http://cmdlinetips.com/2011/08/three-ways-to-read-a-text-file-line-by-line-in-python/
# -*- coding: utf-8 -*-
import os

def main():
    file_hander = open('your_file_here','r+')
    for line in iter(file_hander):
        print line
    file_hander.close()
if __name__ == '__main__':
    main()
######End readfilelinebyline.py #######
######Endmemoof readfilelinebyline.py #######
######Startmemoof sniffer.memo #######
######Start sniffer.memo #######
Tcpdump usage examples from https://www.rationallyparanoid.com/articles/tcpdump.html

#############get sniffer packages and use string read it
tcpdump -nNxXi eth0 -s 0 proto TCP and port 25 -w mail.txt
strings mail.txt
#############get sniffer packages and use string read it


October 1, 2014
In most cases you will need root permission to be able to capture packets on an interface. Using tcpdump (with root) to capture the packets and saving them to a file to analyze with Wireshark (using a regular account) is recommended over using Wireshark with a root account to capture packets on an "untrusted" interface. See the Wireshark security advisories for reasons why.

See the list of interfaces on which tcpdump can listen:

tcpdump -D
Listen on interface eth0:

tcpdump -i eth0
Listen on any available interface (cannot be done in promiscuous mode. Requires Linux kernel 2.2 or greater):

tcpdump -i any
Be verbose while capturing packets:

tcpdump -v
Be more verbose while capturing packets:

tcpdump -vv
Be very verbose while capturing packets:

tcpdump -vvv
Be verbose and print the data of each packet in both hex and ASCII, excluding the link level header:

tcpdump -v -X
Be verbose and print the data of each packet in both hex and ASCII, also including the link level header:

tcpdump -v -XX
Be less verbose (than the default) while capturing packets:

tcpdump -q
Limit the capture to 100 packets:

tcpdump -c 100
Record the packet capture to a file called capture.cap:

tcpdump -w capture.cap
Record the packet capture to a file called capture.cap but display on-screen how many packets have been captured in real-time:

tcpdump -v -w capture.cap
Display the packets of a file called capture.cap:

tcpdump -r capture.cap
Display the packets using maximum detail of a file called capture.cap:

tcpdump -vvv -r capture.cap
Display IP addresses and port numbers instead of domain and service names when capturing packets (note: on some systems you need to specify -nn to display port numbers):

tcpdump -n
Capture any packets where the destination host is 192.168.1.1. Display IP addresses and port numbers:

tcpdump -n dst host 192.168.1.1
Capture any packets where the source host is 192.168.1.1. Display IP addresses and port numbers:

tcpdump -n src host 192.168.1.1
Capture any packets where the source or destination host is 192.168.1.1. Display IP addresses and port numbers:

tcpdump -n host 192.168.1.1
Capture any packets where the destination network is 192.168.1.0/24. Display IP addresses and port numbers:

tcpdump -n dst net 192.168.1.0/24
Capture any packets where the source network is 192.168.1.0/24. Display IP addresses and port numbers:

tcpdump -n src net 192.168.1.0/24
Capture any packets where the source or destination network is 192.168.1.0/24. Display IP addresses and port numbers:

tcpdump -n net 192.168.1.0/24
Capture any packets where the destination port is 23. Display IP addresses and port numbers:

tcpdump -n dst port 23
Capture any packets where the destination port is is between 1 and 1023 inclusive. Display IP addresses and port numbers:

tcpdump -n dst portrange 1-1023
Capture only TCP packets where the destination port is is between 1 and 1023 inclusive. Display IP addresses and port numbers:

tcpdump -n tcp dst portrange 1-1023
Capture only UDP packets where the destination port is is between 1 and 1023 inclusive. Display IP addresses and port numbers:

tcpdump -n udp dst portrange 1-1023
Capture any packets with destination IP 192.168.1.1 and destination port 23. Display IP addresses and port numbers:

tcpdump -n "dst host 192.168.1.1 and dst port 23"
Capture any packets with destination IP 192.168.1.1 and destination port 80 or 443. Display IP addresses and port numbers:

tcpdump -n "dst host 192.168.1.1 and (dst port 80 or dst port 443)"
Capture any ICMP packets:

tcpdump -v icmp
Capture any ARP packets:

tcpdump -v arp
Capture either ICMP or ARP packets:

tcpdump -v "icmp or arp"
Capture any packets that are broadcast or multicast:

tcpdump -n "broadcast or multicast"
Capture 500 bytes of data for each packet rather than the default of 68 bytes:

tcpdump -s 500
Capture all bytes of data within the packet:

tcpdump -s 0

Article first published March 13, 2010. Last updated October 1, 2014.
######End sniffer.memo #######
######Endmemoof sniffer.memo #######
######Startmemoof nfs.memo #######
######Start nfs.memo #######
####link https://www.howtoforge.com/nfs-server-and-client-on-centos-7

如果stale之类的错误，使用umount解除已经mount的文件系统；
如果umount失败，client使用lsof(or ss -tlnp|grep rpc and kill pid)查看正在打开文件系统的进程，kill相关进程，再umount。
============Server config:
yum install nfs-utils

Now the configuration part will include as:mkdir /var/nfsshare
Change the permissions of the folder as follows:chmod -R 777 /var/nfsshare/
We have used /var/nfsshare as, if we uses any other drive such as any /home directory then it will cause a massive permissions problem and ruin the whole hierarchy. If in case we want to share the /home directory then permissions must not be changed.

Next we need to start the services and add them to the boot menu.systemctl enable rpcbind
systemctl enable nfs-server
systemctl enable nfs-lock
systemctl enable nfs-idmap
systemctl restart rpcbind
systemctl restart nfs-server
systemctl restart nfs-lock
systemctl restart nfs-idmap

Now we will share the NFS directory over the network a follows:
nano /etc/exports
We will make two sharing points  /home and /var/nfs. Edit it as follows:

/var/nfsshare    192.168.0.101(rw,sync,no_root_squash,no_all_squash)
or
/var/nfsshare    192.168.*.*(rw,sync,no_root_squash,no_all_squash)
/home            192.168.0.101(rw,sync,no_root_squash,no_all_squash)
Note 192.168.0.101 is the IP of client machine, if you wish that any other client should access it you need to add the it IP wise other wise you can add "*" instead of IP for all IP access.
Condition is that it must be pingable at both ends.

Finally start the NFS service as follows:
systemctl restart nfs-server

Again we need to add the NFS service override in CentOS 7.0 firewall-cmd public zone service as:
firewall-cmd --permanent --zone=public --add-service=nfs
firewall-cmd --add-port 111/tcp --perm
firewall-cmd --add-port 2049/tcp --perm ###optional ?
firewall-cmd --reload
Note: If it will be not done, then it will give error for Connection Time Out at client side.
Now we are ready with the NFS server part.





===========Client config
3 NFS client endIn my case I have the client as CentOS 7.0 desktop. Other CentOS versions will also work for the same. Install the packages as follows:
yum install nfs-utils

Now create the NFS directory mount point as follows:
mkdir -p /mnt/nfs/home
mkdir -p /mnt/nfs/var/nfsshare

Start the services and add them to boot menu.
systemctl enable rpcbind
systemctl enable nfs-server
systemctl enable nfs-lock
systemctl enable nfs-idmap

systemctl start rpcbind
systemctl start nfs-server
systemctl start nfs-lock
systemctl start nfs-idmap



Next we will mount the NFS shared content in the client machine as shown below:
mount -t nfs 192.168.0.100:/home /mnt/nfs/home/


Your can use rpcinfo -p server view rpc info
# rpcinfo -p server

   program vers proto   port  service
    100000    4   tcp    111  portmapper
    100000    3   tcp    111  portmapper
    100000    2   tcp    111  portmapper
    100000    4   udp    111  portmapper
    100000    3   udp    111  portmapper
    100000    2   udp    111  portmapper
    100005    1   udp  20048  mountd
    100005    1   tcp  20048  mountd
    100024    1   udp  34057  status
    100024    1   tcp  37592  status
    100005    2   udp  20048  mountd
    100005    2   tcp  20048  mountd
    100005    3   udp  20048  mountd
    100005    3   tcp  20048  mountd
    100003    3   tcp   2049  nfs
    100003    4   tcp   2049  nfs
    100227    3   tcp   2049  nfs_acl
    100003    3   udp   2049  nfs
    100003    4   udp   2049  nfs
    100227    3   udp   2049  nfs_acl
    100021    1   udp  39854  nlockmgr
    100021    3   udp  39854  nlockmgr
    100021    4   udp  39854  nlockmgr
    100021    1   tcp  40054  nlockmgr
    100021    3   tcp  40054  nlockmgr
    100021    4   tcp  40054  nlockmgr

####display export list
showmount -e
Export list for nfs-server:
/data/d2 172.16.1.*
/data/d1 172.16.1.*

It will mount /home of NFS server. Next we will /var/nfsshare mount as follows:
=====this config add to /etc/crontab seem is a intellget way ?? 
mount -t nfs 192.168.0.100:/var/nfsshare /mnt/nfs/var/nfsshare/

Now we are connected with the NFS share, we will crosscheck it as follows:
df -kh

[root@client1 ~]# df -kh
Filesystem                    Size  Used Avail Use% Mounted on
/dev/mapper/centos-root        39G  1.1G   38G   3% /
devtmpfs                      488M     0  488M   0% /dev
tmpfs                         494M     0  494M   0% /dev/shm
tmpfs                         494M  6.7M  487M   2% /run
tmpfs                         494M     0  494M   0% /sys/fs/cgroup
/dev/mapper/centos-home        19G   33M   19G   1% /home
/dev/sda1                     497M  126M  372M  26% /boot
192.168.0.100:/var/nfsshare   39G  980M   38G   3% /mnt/nfs/var/nfsshare
192.168.0.100:/home           19G   33M   19G   1% /mnt/nfs/home
[root@client1 ~]#
So we are connected with NFS share.

Now we will check the read/write permissions in the shared path. At client enter the command:
touch /mnt/nfs/var/nfsshare/test_nfs
So successfull NFS-share done.

4 Permanent NFS mountingWe need to mount the NFS share at client end permanent that it must be mounted even after reboot. So we need to add the NFS-share in /etc/fstab file of client machine as follows:
nano /etc/fstab

Add the entries like this:
[...]
192.168.0.100:/home    /mnt/nfs/home   nfs defaults 0 0
192.168.0.100:/var/nfsshare    /mnt/nfs/var/nfsshare   nfs defaults 0 0

Note 192.168.0.100 is the server NFS-share  IP address, it will vary in your case.
This will make the permanent mount of the NFS-share. Now you can reboot the machine and mount points will be permanent even after the reboot.

Cheers now we have a successfully configured NFS-server over CentOS 7.0 :)

######End nfs.memo #######
######Endmemoof nfs.memo #######
