dashboard
https://github.com/kubernetes/dashboard/wiki/Installation
https://github.com/kubernetes/dashboard/wiki/Creating-sample-user


###faq
per component must integrety
docker image pull fail must pull from mirror and docker tag on node (use docker hub?)
\
  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.200.213:6443 --token o7uwd6.7z8y5z3h3ht1e11y \
    --discovery-token-ca-cert-hash sha256:07e59210ce5d6cf38ad31a449440b09778a17779f18e804a397ac99e6ebf58ce 


https://yq.aliyun.com/articles/702158

yum -y install tmux vim wget  
## RHEL/CentOS 7 64-Bit ##
# wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
# rpm -ivh epel-release-latest-7.noarch.rpm

yum update kernel -y
systemctl	stop	dnsmasq
 systemctl	disable	dnsmasq



--10 master and node
hostnamectl set-hostname master

 cat /etc/hosts
192.168.200.211 app-k8s-w02
192.168.200.213 app-k8s-m02



cat preENV.sh
#!/bin/bash
# 关闭防火墙
systemctl stop firewalld && systemctl disable firewalld
# 关闭SELINUX
setenforce 0 && sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config
# 关闭Swap
swapoff -a && sed -i "s/\/dev\/mapper\/centos-swap/\#\/dev\/mapper\/centos-swap/g" /etc/fstab


[root@master-and-slave ~]# cat /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1


[root@master-and-slave ~]# modprobe br_netfilter
[root@master-and-slave ~]# sysctl -p /etc/sysctl.d/k8s.conf

[root@master-and-slave ~]# cat > /etc/sysconfig/modules/ipvs.modules <<EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF
[root@master-and-slave ~]# chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack_ipv4


[root@master-and-slave ~]# yum install -y yum-utils device-mapper-persistent-data lvm2
[root@master-and-slave ~]# wget -O /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
[root@master-and-slave ~]# yum makecache fast
[root@master-and-slave ~]# yum install -y docker-ce
[root@master-and-slave ~]# systemctl start docker
[root@master-and-slave ~]# systemctl enable docker

[root@master-and-slave ~]# cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
[root@master-and-slave ~]# yum makecache fast
[root@master-and-slave ~]# yum install -y kubelet kubeadm kubectl
[root@master-and-slave ~]# systemctl enable kubelet 



20 master

# vim k8sMasterImages.sh
#!/bin/bash

set -e

KUBE_VERSION=v1.15.0
KUBE_PAUSE_VERSION=3.1
ETCD_VERSION=3.3.10
CORE_DNS_VERSION=1.3.1

GCR_URL=k8s.gcr.io
ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers

images=(kube-proxy:${KUBE_VERSION}
kube-scheduler:${KUBE_VERSION}
kube-controller-manager:${KUBE_VERSION}
kube-apiserver:${KUBE_VERSION}
pause:${KUBE_PAUSE_VERSION}
etcd:${ETCD_VERSION}
coredns:${CORE_DNS_VERSION})


for imageName in ${images[@]} ; do
  docker pull $ALIYUN_URL/$imageName
  docker tag  $ALIYUN_URL/$imageName $GCR_URL/$imageName
  docker rmi $ALIYUN_URL/$imageName
done
[root@master ~]# chmod +x k8sMasterImages.sh
[root@master ~]# ./k8sMasterImages.sh

[root@master ~]# kubeadm init --kubernetes-version=v1.15.0 --apiserver-advertise-address=192.168.200.213 --pod-network-cidr=10.244.0.0/16
USER=ubuntu # customizable
CONTROL_PLANE_IPS="10.0.0.7 10.0.0.8"
for host in ${CONTROL_PLANE_IPS}; do
    scp /etc/kubernetes/pki/ca.crt "${USER}"@$host:
    scp /etc/kubernetes/pki/ca.key "${USER}"@$host:
    scp /etc/kubernetes/pki/sa.key "${USER}"@$host:
    scp /etc/kubernetes/pki/sa.pub "${USER}"@$host:
    scp /etc/kubernetes/pki/front-proxy-ca.crt "${USER}"@$host:
    scp /etc/kubernetes/pki/front-proxy-ca.key "${USER}"@$host:
    scp /etc/kubernetes/pki/etcd/ca.crt "${USER}"@$host:etcd-ca.crt
    scp /etc/kubernetes/pki/etcd/ca.key "${USER}"@$host:etcd-ca.key
done


说明

    --kubernetes-version=v1.15.0 : 指定K8S版本
    --apiserver-advertise-address=192.168.33.10 : 指定apiserver 的地址，一般为主节点的地址，也就是虚拟机的地址
    --pod-network-cidr=10.244.0.0/16 : Pod的地址范围，其值为CIDR格式的网络地址；计划使用flannel网络插件；使用flannel网络插件时，其默认地址为10.244.0.0/16.


[root@master ~]# mkdir -p $HOME/.kube
[root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
[root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config


[root@master ~]# kubectl get cs
NAME                 STATUS    MESSAGE             ERROR
scheduler            Healthy   ok
controller-manager   Healthy   ok
etcd-0               Healthy   {"health":"true"}



[root@master ~]# kubectl get pod -A -o wide
NAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE     IP              NODE     NOMINATED NODE   READINESS GATES
kube-system   coredns-fb8b8dccf-88hfr          0/1     Pending   0          6m33s   <none>          <none>   <none>           <none>
kube-system   coredns-fb8b8dccf-jmw7m          0/1     Pending   0          6m33s   <none>          <none>   <none>           <none>
kube-system   etcd-master                      1/1     Running   0          5m42s   192.168.33.10   master   <none>           <none>
kube-system   kube-apiserver-master            1/1     Running   0          5m46s   192.168.33.10   master   <none>           <none>
kube-system   kube-controller-manager-master   1/1     Running   0          5m47s   192.168.33.10   master   <none>           <none>
kube-system   kube-proxy-46wth                 1/1     Running   0          6m32s   192.168.33.10   master   <none>           <none>
kube-system   kube-scheduler-master            1/1     Running   0          5m40s


[root@master ~]# kubectl describe node master | grep Taint
Taints:             node-role.kubernetes.io/master:NoSchedule
[root@master ~]# kubectl taint nodes master node-role.kubernetes.io/master-
node "master" untainted







30 node1


[vagrant@node1 ~]$ cat k8sNodeImages.sh
#!/bin/bash

set -e

KUBE_VERSION=v1.15.0
KUBE_PAUSE_VERSION=3.1

GCR_URL=k8s.gcr.io
ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers

images=(kube-proxy-amd64:${KUBE_VERSION}
pause:${KUBE_PAUSE_VERSION})


for imageName in ${images[@]} ; do
  docker pull $ALIYUN_URL/$imageName
  docker tag  $ALIYUN_URL/$imageName $GCR_URL/$imageName
  docker rmi $ALIYUN_URL/$imageName
done
[root@node1 ~]# chmod +x k8sNodeImages.sh
[root@node1 ~]# ./k8sNodeImages.sh


[root@node1 ~]#  kubeadm join 192.168.200.213:6443 --token o7uwd6.7z8y5z3h3ht1e11y \
    --discovery-token-ca-cert-hash sha256:07e59210ce5d6cf38ad31a449440b09778a17779f18e804a397ac99e6ebf58ce


--discovery-token-ca-cert-hash sha256:07e59210ce5d6cf38ad31a449440b09778a17779f18e804a397ac99e6ebf58ce
40 master flannel

[root@master ~]# cat processFlannelImage.sh
#!/bin/bash
docker pull quay-mirror.qiniu.com/coreos/flannel:v0.11.0-amd64
docker tag quay-mirror.qiniu.com/coreos/flannel:v0.11.0-amd64 quay.io/coreos/flannel:v0.11.0-amd64
[root@master ~]# chmod +x processFlannelImage.sh
[root@master ~]# ./processFlannelImage.sh


kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

[root@master ~]# kubectl get pod -A -o wide
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE    IP              NODE     NOMINATED NODE   READINESS GATES
kube-system   coredns-fb8b8dccf-88hfr            1/1     Running   0          12h    10.244.0.3      master   <none>           <none>
kstoube-system   coredns-fb8b8dccf-jmw7m            1/1     Running   0          12h    10.244.0.2      master   <none>           <none>
kube-system   etcd-master                        1/1     Running   0          12h



50 master set nginx


[root@master ~]# cat nginx-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
[root@master ~]# kubectl apply -f nginx-deployment.yaml
deployment.apps/nginx-deployment created
[root@master ~]# kubectl get pods
NAME                               READY   STATUS              RESTARTS   AGE
nginx-deployment-6dd86d77d-fb9bp   0/1     ContainerCreating   0          101s
nginx-deployment-6dd86d77d-lzc56   1/1     Running             0          101s
nginx-deployment-6dd86d77d-p7pd8   1/1     Running             0          101s



[root@master ~]# cat nginx-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
  labels:
    app: nginx
spec:
  ports:
  - port: 88
    targetPort: 80
  selector:
    app: nginx
  type: NodePort
[root@master ~]# kubectl create -f nginx-service.yaml
service/nginx-service created
[root@master ~]# kubectl get service/nginx-service
NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
nginx-service   NodePort   10.99.114.248   <none>        88:31345/TCP   14s



访问地址格式为 MasterIP:NodePort, NodePort 为kubectl get service/nginx-servic 后 88:31345/TCP中 31345这个端口；本次为http://192.168.33.10:31345/
